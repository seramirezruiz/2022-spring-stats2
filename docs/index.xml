<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>| Tutorials - Spring 2022 |</title>
    <link>https://seramirezruiz.github.io/2022-spring-stats2/</link>
      <atom:link href="https://seramirezruiz.github.io/2022-spring-stats2/index.xml" rel="self" type="application/rss+xml" />
    <description>| Tutorials - Spring 2022 |</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 19 Apr 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://seramirezruiz.github.io/2022-spring-stats2/images/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>| Tutorials - Spring 2022 |</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/</link>
    </image>
    
    <item>
      <title>10 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-10/slides/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-10/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w10-moderation.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>08 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-9/slides/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-9/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w9_panel.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>08 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-8/slides/</link>
      <pubDate>Mon, 05 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-8/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w8_DiD.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>07 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-7/slides/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-7/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w7_RDD.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>05 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-6/slides/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-6/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w6_instruments.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>05 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-5/slides/</link>
      <pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-5/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w5_matching.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>04 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-4/slides/</link>
      <pubDate>Sun, 28 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-4/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w4_regression.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>03 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-3/slides/</link>
      <pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-3/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w3_causal_graphs.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>02 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-2/slides/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-2/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w2_foundations.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>01 - Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-1/slides/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-1/slides/</guid>
      <description>&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;iframe src=&#34;../w1-intro.pdf#view=fit&#34; width=&#34;100%&#34; height=&#34;500px&#34;&gt;
    &lt;/iframe&gt;
&lt;!--
## Courses in this program























&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.jpg&#34; &gt;


  &lt;img src=&#34;featured.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>R and RStudio basics</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-1/foundations/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-1/foundations/</guid>
      <description>&lt;h2 id=&#34;welcome&#34;&gt;Welcome!&lt;/h2&gt;
&lt;p&gt;The practical component of the &lt;strong&gt;Statistics II: Statistical Modeling and Causal Inference&lt;/strong&gt; course relies largely in &lt;em&gt;R&lt;/em&gt; programming. Today we will center on some of the necessary skills to perform the assignments for the course.&lt;/p&gt;
&lt;p&gt;In this tutorial, you will learn to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;identify the some of the basic functionalities of &lt;em&gt;R&lt;/em&gt; and &lt;em&gt;RStudio&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;import data sets into your &lt;em&gt;R&lt;/em&gt; environment&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;r-and-rstudio-basics&#34;&gt;R and RStudio: Basics&lt;/h2&gt;
&lt;h3 id=&#34;the-rstudio-layout&#34;&gt;The RStudio layout&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;RStudio&lt;/em&gt; is an integrated development environment (IDE) for R. Think of &lt;em&gt;RStudio&lt;/em&gt; as a front that allows us to interact, compile, and render R code in a more instinctive way. The following image shows what the standard RStudio interface looks like:&lt;/p&gt;


















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://user-images.githubusercontent.com/54796579/92997228-088e9580-f512-11ea-9dad-556438c91f86.png&#34; &gt;


  &lt;img src=&#34;https://user-images.githubusercontent.com/54796579/92997228-088e9580-f512-11ea-9dad-556438c91f86.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Console&lt;/strong&gt;: The &lt;em&gt;console&lt;/em&gt; provides a means to interact directly with &lt;em&gt;R&lt;/em&gt;. You can type some code at the &lt;em&gt;console&lt;/em&gt; and when you press ENTER, R will run that code. Depending on what you type, you may see some output in the &lt;em&gt;console&lt;/em&gt; or if you make a mistake, you may get a warning or an error message.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Script editor&lt;/strong&gt;: You will utilize the &lt;em&gt;script editor&lt;/em&gt; to complete your assignments. The &lt;em&gt;script editor&lt;/em&gt; will be the space where files will be displayed. For example, once you download and open the bi-weekly assignment .Rmd template, it will appear here. The editor is a where you should place code you care about, since the code from the console cannot be saved into a script.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt;: This area holds the abstractions you have created with your code. If you run &lt;code&gt;myresult &amp;lt;- 5+3+2&lt;/code&gt;, the &lt;code&gt;myresult&lt;/code&gt; object will appear there.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Plots and files&lt;/strong&gt;: This area will be where graphic output will be generated. Additionally, if you write a question mark before any function, (i.e. &lt;code&gt;?mean&lt;/code&gt;) the online documentation will be displayed here.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;r-packages&#34;&gt;R Packages&lt;/h3&gt;
&lt;p&gt;For the most part, &lt;em&gt;R Packages&lt;/em&gt; are collections of code and functions that leverage R programming to expand on the basic functionalities. Last week we met &lt;code&gt;dplyr&lt;/code&gt; that aids R programmers in the process of data cleaning and manipulation. There are a plethora of packages in &lt;em&gt;R&lt;/em&gt; designed to facilite the completion of tasks. In fact, this website is built with the &lt;code&gt;blogdown&lt;/code&gt; package that lets you create websites using &lt;code&gt;RMarkdown&lt;/code&gt; and Hugo&lt;/p&gt;
&lt;p&gt;Unlike other programming languages, in &lt;em&gt;R&lt;/em&gt; you only need to install a package once. The following times you will only need to &amp;ldquo;require&amp;rdquo; the package. &lt;strong&gt;As a good practice I recommend running the code to install packages only in your R console, not in the code editor.&lt;/strong&gt; You can install a package with the following syntax&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;name_of_your_package&amp;quot;) #note that the quotation marks are mandatory at this stage
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the package has been installed, you just need to &amp;ldquo;call it&amp;rdquo; every time you want to use it in a file by running:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;name_of_your_package&amp;quot;) #either of this lines will require the package
library(name_of_your_package) #library understands the code with, or without, quotation marks
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;It is extremely important that you do not have any lines installing packages for your assignments because the file will fail to knit&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;hr&gt;
&lt;h3 id=&#34;working-directory&#34;&gt;Working directory&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;working directory&lt;/em&gt; is just a file path on your computer that sets the default location of any files you read into R, or save out of R. Normally, when you open &lt;em&gt;RStudio&lt;/em&gt; it will have a default directory (a folder in your computer). You can check you directory by running &lt;code&gt;getwd()&lt;/code&gt; in your console:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#this is the default in my case
getwd()
#[1] &amp;quot;/Users/sebastianramirezruiz&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;When your RStudio is closed and you open a file from your finder in MacOS or file explorer in Windows, the default working directory will be the folder where the file is hosted&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;setting-your-working-directory&#34;&gt;Setting your working directory&lt;/h3&gt;
&lt;p&gt;You can set you directory manually from RStudio: use the menu to change your working directory under Session &amp;gt; Set Working Directory &amp;gt; Choose Directory.&lt;/p&gt;


















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://www.sthda.com/sthda/RDoc/images/rstudio-change-working-directory.png&#34; &gt;


  &lt;img src=&#34;http://www.sthda.com/sthda/RDoc/images/rstudio-change-working-directory.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;You can also use the &lt;code&gt;setwd()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;setwd(&amp;quot;/path/to/your/directory&amp;quot;) #in macOS
setwd(&amp;quot;c:/path/to/your/directory&amp;quot;) #in windows
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;recommended-folder-structure-for-the-class&#34;&gt;Recommended folder structure for the class&lt;/h3&gt;


















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://user-images.githubusercontent.com/54796579/92937233-5ee4d100-f44b-11ea-9ee7-cc7209b80562.png&#34; &gt;


  &lt;img src=&#34;https://user-images.githubusercontent.com/54796579/92937233-5ee4d100-f44b-11ea-9ee7-cc7209b80562.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;We recommend you pay close attention to your folder structure. You will receive a new folder for each assignment. Make the folder your working directory when working on the assignment. This folder will be populated with the template .Rmd and the data for the week. When you knit the file, the &lt;strong&gt;.html&lt;/strong&gt; will be created in this folder.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;We will learn more about the assignment submission workflow next week. Still, avoid changing the name of the files you receive in Github since it will create issues.&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;hr&gt;
&lt;h3 id=&#34;dealing-with-errors-in-r&#34;&gt;Dealing with errors in R&lt;/h3&gt;
&lt;p&gt;Errors in R occur when code is used in a way that it is not intended. For example when you try to add two character strings, you will get the following error:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;quot;hello&amp;quot; + &amp;quot;world&amp;quot;
Error in &amp;quot;hello&amp;quot; + &amp;quot;world&amp;quot;: non-numeric argument to binary operator
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Normally, when something has gone wrong with your program, &lt;em&gt;R&lt;/em&gt; will notify you of an error in the &lt;strong&gt;console&lt;/strong&gt;. There are errors that will prevent the code from running, while others will only produce &lt;strong&gt;warning&lt;/strong&gt; messages. In the following case, the code will run, but you will notice that the string &lt;strong&gt;&amp;ldquo;three&amp;rdquo;&lt;/strong&gt; is turned into a NA.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;as.numeric(c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;three&amp;quot;))
Warning: NAs introduced by coercion
[1]  1  2 NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we will be utilizing widely used packages and functions in the course of the semester, the errors that you may come across in the process of completing your assignments will be common for other R users. Most errors occur because of typos. A Google search of the error message can take you a long way as well. Most of the times the first entry on &lt;strong&gt;stackoverflow.com&lt;/strong&gt; will solve the problem.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;importing-data&#34;&gt;Importing data&lt;/h2&gt;
&lt;p&gt;Next we will work with data provided by the &lt;code&gt;palmerpenguins&lt;/code&gt; package; however, most practical applications will require you to work with your own data. In fact, for most assignments, you will be given a data set to work with. As we will see in the coming weeks, data are messy. You know what else is messy? Data formats. You may be acquainted with a couple of them &lt;em&gt;(.csv, .tsv, .xlsx)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Fortunately for us, the &lt;code&gt;tidyverse&lt;/code&gt; has two packages that make the process of loading data sets from different formats very easy.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;readr&lt;/code&gt;: The goal of &lt;code&gt;readr&lt;/code&gt; is to provide a fast and friendly way to read rectangular data (like &lt;strong&gt;csv, tsv, rds, and fwf&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;haven&lt;/code&gt;: The goal of &lt;code&gt;haven&lt;/code&gt; is to enable R to read and write various data formats used by other statistical packages (like &lt;strong&gt;dta, sas, and sav&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can read more about how to load different types of data in the respective documentations of the packages — &lt;a href=&#34;https://readr.tidyverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;readr&lt;/a&gt; and &lt;a href=&#34;https://haven.tidyverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;haven&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;For the assignments you will be required to load datasets. You can do that by installing the &lt;code&gt;readr&lt;/code&gt; package and utilizing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#with readr
your_data_frame &amp;lt;- readr::read_rds(&amp;quot;path_for_the_file&amp;quot;)

#you can alternatively use a base R option
your_data_frame &amp;lt;- base::readRDS(&amp;quot;path_for_the_file&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This week&amp;rsquo;s mock assignment will feature a &lt;strong&gt;.tsv&lt;/strong&gt; file. When in doubt just Google &lt;strong&gt;&amp;ldquo;How to load x_format data in R?&amp;quot;&lt;/strong&gt; That will do the trick!&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;the-double-colon-operator-&#34;&gt;The double colon operator ::&lt;/h3&gt;
&lt;p&gt;You may have noted in the previous section that the functions were preceded by their package name and two colons, for example: &lt;code&gt;readr::read_rds()&lt;/code&gt;. The double colon operator &lt;code&gt;::&lt;/code&gt; helps us ensure that we select functions from a particular package. We utilize the operator to explicitly state where the function is coming. This may become even more important when you are doing data analysis as part of a team further in your careers. Though it is likely that this will not be a problem during the course, we can try to employ the following convention &lt;code&gt;package_name::function()&lt;/code&gt; to ensure that we will not encounter errors in our knitting process:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dplyr::select()
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Let&amp;rsquo;s look at what happens when we load &lt;code&gt;tidyverse&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)

#── Attaching packages ──────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 #──
#✓ ggplot2 3.3.2     ✓ purrr   0.3.4
#✓ tibble  3.0.3     ✓ dplyr   1.0.2
#✓ tidyr   1.1.2     ✓ stringr 1.4.0
#✓ readr   1.3.1     ✓ forcats 0.5.0
#── Conflicts ─────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() #──
#x dplyr::filter() masks stats::filter()
#x dplyr::lag()    masks stats::lag()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may notice that &lt;em&gt;R&lt;/em&gt; points out some conflicts where some functions are being masked. The default in this machine will become the &lt;code&gt;filter()&lt;/code&gt; from the &lt;code&gt;dplyr&lt;/code&gt; package during this session. If you were to run some code that is based on the &lt;code&gt;filter()&lt;/code&gt; from the &lt;code&gt;stats&lt;/code&gt; package, your code will probably result in errors.&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Data Manipulation</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-2/data-manipulation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-2/data-manipulation/</guid>
      <description>&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;h1 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h1&gt;
&lt;h2 id=&#34;welcome&#34;&gt;Welcome!&lt;/h2&gt;
&lt;p&gt;Welcome to our second tutorial for the Statistics II: Statistical Modeling &amp;amp; Causal Inference (with R) course.&lt;/p&gt;
&lt;p&gt;The labs are designed to reinforce the material covered during the lectures by introducing you to hands-on applications.&lt;/p&gt;
&lt;p&gt;The practical nature of our class means that our labs will be data-centered. Throughout our class, we will get acquinted with multiple packages of the &lt;code&gt;tidyverse&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Though we expect that some of you may already know them, the &lt;code&gt;tidyverse&lt;/code&gt; is a collection of R packages that share an underlying design, syntax, and structure. They will definitely make your life easier!!&lt;/p&gt;
&lt;p&gt;Today, we will start with a brief introduction to data manipulation through the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;In this tutorial, you will learn to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;identify the purpose of a set of &lt;code&gt;dplyr&lt;/code&gt; verbs&lt;/li&gt;
&lt;li&gt;write statements in &lt;strong&gt;tidy&lt;/strong&gt; syntax&lt;/li&gt;
&lt;li&gt;apply &lt;code&gt;dplyr&lt;/code&gt; verbs to solve your data manipulation challenges&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial is partly based on &lt;a href=&#34;http://r4ds.had.co.nz/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;R for Data Science&lt;/em&gt;&lt;/a&gt;, section 5.2, and &lt;a href=&#34;http://qpolr.com/data.html/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Quantitative Politics with R&lt;/em&gt;&lt;/a&gt;, chapter 3.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-we-will-need-today&#34;&gt;What we will need today&lt;/h2&gt;
&lt;p&gt;We’ll practice some wrangling in &lt;code&gt;dplyr&lt;/code&gt; using data for penguin sizes recorded by Dr. Kristen Gorman and others at several islands in the Palmer Archipelago, Antarctica. Data are originally published in: Gorman KB, Williams TD, Fraser WR (2014) PLoS ONE 9(3): e90081. doi:10.1371/journal.pone.0090081&lt;/p&gt;
&lt;p&gt;You do &lt;strong&gt;not&lt;/strong&gt; need to import the data to work through this tutorial - the data are already here waiting behind the scenes.&lt;/p&gt;
&lt;p&gt;But if you &lt;em&gt;do&lt;/em&gt; ever want to use the penguins data outside of this tutorial, they now exist in the &lt;a href=&#34;https://github.com/allisonhorst/palmerpenguins&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;palmerpenguins&lt;/strong&gt;&lt;/a&gt; package in &lt;em&gt;R&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Let’s begin!&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;2-data-structure&#34;&gt;2. Data Structure&lt;/h1&gt;
&lt;h2 id=&#34;tidy-data&#34;&gt;Tidy data&lt;/h2&gt;
&lt;p&gt;Generally, we will encounter data in a tidy format. Tidy data refers to a way of mapping the structure of a data set. In a tidy data set:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Each variable forms a column.&lt;/li&gt;
&lt;li&gt;Each observation forms a row.&lt;/li&gt;
&lt;li&gt;Each type of observational unit forms a table&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/seramirezruiz/hertiestats2/master/inst/tutorials/basics/images/tidy_data.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-penguins-data-set&#34;&gt;The &lt;code&gt;penguins&lt;/code&gt; data set&lt;/h2&gt;
&lt;p&gt;The 3 species of penguins in this data set are Adelie, Chinstrap and Gentoo. The data set contains 8 variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;species:&lt;/strong&gt; a factor denoting the penguin species (Adelie, Chinstrap, or Gentoo)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;island:&lt;/strong&gt; a factor denoting the island (in Palmer Archipelago, Antarctica) where observed&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;culmen_length_mm:&lt;/strong&gt; a number denoting length of the dorsal ridge of penguin bill (millimeters)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;culmen_depth_mm:&lt;/strong&gt; a number denoting the depth of the penguin bill (millimeters)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;flipper_length_mm:&lt;/strong&gt; an integer denoting penguin flipper length (millimeters)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;body_mass_g:&lt;/strong&gt; an integer denoting penguin body mass (grams)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sex:&lt;/strong&gt; a factor denoting penguin sex (MALE, FEMALE)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;year&lt;/strong&gt; an integer denoting the year of the record&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/seramirezruiz/hertiestats2/master/inst/tutorials/basics/images/penguins.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p style=&#34;text-align:right;&#34;&gt;
*Illustration by @allisonhorst*
&lt;/p&gt;
&lt;h2 id=&#34;lets-explore-the-data-set&#34;&gt;Let’s explore the data set.&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;head()&lt;/code&gt; is a function that returns the first couple rows from a data frame. Write the R code required to explore the first observations of the &lt;code&gt;penguins&lt;/code&gt; data set:&lt;/p&gt;
&lt;p&gt;Notice that when you press ‘Run,’ the &lt;strong&gt;output&lt;/strong&gt; of the code is returned below it! So by pressing ‘Run,’ you’ve run your first &lt;em&gt;R&lt;/em&gt; code of the class!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(penguins)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
species
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
island
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
bill\_length\_mm
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
bill\_depth\_mm
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
flipper\_length\_mm
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
body\_mass\_g
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
sex
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
year
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adelie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Torgersen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39.1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
181
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3750
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2007
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adelie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Torgersen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39.5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17.4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
186
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3800
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2007
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adelie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Torgersen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
40.3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
195
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3250
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2007
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adelie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Torgersen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2007
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adelie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Torgersen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19.3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
193
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3450
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2007
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adelie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Torgersen
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39.3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
190
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3650
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2007
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h1 id=&#34;3-manipulating-data-with-dplyr&#34;&gt;3. Manipulating data with &lt;code&gt;dplyr&lt;/code&gt;&lt;/h1&gt;
&lt;h2 id=&#34;what-we-will-learn-today&#34;&gt;What we will learn today&lt;/h2&gt;
&lt;p&gt;In this tutorial, you’ll learn and practice examples using some functions in &lt;code&gt;dplyr&lt;/code&gt; to work with data. Those are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;select()&lt;/code&gt;: keep or exclude some columns&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filter()&lt;/code&gt;: keep rows that satisfy your conditions&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mutate()&lt;/code&gt;: add columns from existing data or edit existing columns&lt;/li&gt;
&lt;li&gt;&lt;code&gt;group_by()&lt;/code&gt;: lets you define groups within your data set&lt;/li&gt;
&lt;li&gt;&lt;code&gt;summarize()&lt;/code&gt;: get summary statistics&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrange()&lt;/code&gt;: reorders the rows according to single or multiple variables&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s get to work.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;31-select&#34;&gt;3.1. &lt;code&gt;select()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The first verb (function) we will utilize is &lt;code&gt;select()&lt;/code&gt;. We can employ it to manipulate our data based on columns. If you recall from our initial exploration of the data set there were eight variables attached to every observation. Do you recall them? If you do not, there is no problem. You can utilize &lt;code&gt;names()&lt;/code&gt; to retrieve the names of the variables in a data frame.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;names(penguins)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;species&amp;quot;           &amp;quot;island&amp;quot;            &amp;quot;bill_length_mm&amp;quot;   
## [4] &amp;quot;bill_depth_mm&amp;quot;     &amp;quot;flipper_length_mm&amp;quot; &amp;quot;body_mass_g&amp;quot;      
## [7] &amp;quot;sex&amp;quot;               &amp;quot;year&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Say we are only interested in the species, island, and year variables of these data, we can utilize the following syntax:&lt;/p&gt;
&lt;center&gt;
select(data, columns)
&lt;/center&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;
&lt;em&gt;The following code chunk would select the species, island, and year variables. What should we do to keep the body_mass_g and sex variables as well?&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dplyr::select(penguins, species, island, year)
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid1.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# you just need to type the names of the columns
dplyr::select(penguins, species, island, year, body_mass_g, sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid2.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;To drop variables, use - before the variable name.&lt;/p&gt;
&lt;p&gt;For example, &lt;code&gt;select(penguins, -year)&lt;/code&gt; will drop the year column.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;32-filter&#34;&gt;3.2. &lt;code&gt;filter()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The second verb (function) we will employ is &lt;code&gt;filter()&lt;/code&gt;. &lt;code&gt;filter()&lt;/code&gt; lets you use a logical test to extract specific rows from a data frame. To use &lt;code&gt;filter()&lt;/code&gt;, pass it the data frame followed by one or more logical tests. &lt;code&gt;filter()&lt;/code&gt; will return every row that passes each logical test.&lt;/p&gt;
&lt;p&gt;The more commonly used logical operators are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;==&lt;/code&gt;: Equal to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;!=&lt;/code&gt;: Not equal to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;: Greater than, greater than or equal to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;: Less than, less than or equal to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;amp;&lt;/code&gt;, &lt;code&gt;|&lt;/code&gt;: And, or&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Say we are interested in retrieving the observations from the year 2007. We would do:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dplyr::filter(penguins, year == 2007)
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid3.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;
&lt;em&gt;Can you adapt the code to retrieve all the observations of Chinstrap penguins from 2007 (remember that species contains character units)&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# you just need to utilize &amp;amp; and type the logical operator for the species
dplyr::filter(penguins, year == 2007 &amp;amp; species == &amp;quot;Chinstrap&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid4.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;33-the-pipe-operator-&#34;&gt;3.3. The Pipe Operator: &lt;code&gt;%&amp;gt;%&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The pipe, &lt;code&gt;%&amp;gt;%&lt;/code&gt;, comes from the &lt;code&gt;magrittr&lt;/code&gt; package by Stefan Milton Bache. Packages in the &lt;code&gt;tidyverse&lt;/code&gt; load &lt;code&gt;%&amp;gt;%&lt;/code&gt; for you automatically, so you don’t usually load &lt;code&gt;magrittr&lt;/code&gt; explicitly. This will be one of your best friends in &lt;em&gt;R&lt;/em&gt;.
&amp;gt;&lt;strong&gt;Pipes are a powerful tool for clearly expressing a sequence of multiple operations. Let’s think about baking for a second.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/92409417-d3b0c600-f140-11ea-8596-561a05586988.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;
&lt;em&gt;We can leverage the pipe operator to sequence our code in a logical manner. Can you adapt the following code chunk with the pipe and conditional logical operators we discussed?&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;only_2009 &amp;lt;- dplyr::filter(penguins, year == 2009)
only_2009_chinstraps &amp;lt;- dplyr::filter(only_2009, species == &amp;quot;Chinstrap&amp;quot;)
only_2009_chinstraps_species_sex_year &amp;lt;- dplyr::select(only_2009_chinstraps, species, sex, year)
final_df &amp;lt;- only_2009_chinstraps_species_sex_year
final_df #to print it in our console
&lt;/code&gt;&lt;/pre&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;% #we start off with out df
  dplyr::filter(year == 2009 &amp;amp; species == &amp;quot;Chinstrap&amp;quot;) %&amp;gt;% #filter
  dplyr::select(species, sex, year) #select
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid5.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;34-mutate&#34;&gt;3.4. &lt;code&gt;mutate()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;mutate()&lt;/code&gt; lets us create, modify, and delete columns. The most common use for now will be to create new variables based on existing ones. Say we are working with a U.S. American client and they feel more confortable with assessing the weight of the penguins in pounds. We would utilize &lt;code&gt;mutate()&lt;/code&gt; as such:&lt;/p&gt;
&lt;p&gt;
&lt;center&gt;
mutate(new\_var\_name = conditions)
&lt;/center&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;
&lt;em&gt;Can you edit the following code chunk to render a new variable body_mass_kg?&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::mutate(body_mass_lbs = body_mass_g/453.6)
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid6.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::mutate(body_mass_kg = body_mass_g/1000) #grams divided by 1000 
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid7.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;35-group_by-and-summarize&#34;&gt;3.5. &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;summarize()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;These two verbs &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;summarize()&lt;/code&gt; tend to go together. When combined , ’summarize()` will create a new data frame. It will have one (or more) rows for each combination of grouping variables; if there are no grouping variables, the output will have a single row summarising all observations in the input. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;summarize()&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::summarize(heaviest_penguin = max(body_mass_g, na.rm = T)) #max() does not know how to deal with NAs very well
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
heaviest\_penguin
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6300
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;group_by()&lt;/code&gt; + &lt;code&gt;summarize()&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::group_by(species) %&amp;gt;%
  dplyr::summarize(heaviest_penguin = max(body_mass_g, na.rm = T))
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
species
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
heaviest\_penguin
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adelie
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4775
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chinstrap
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4800
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gentoo
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6300
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;
&lt;em&gt;Can you get the weight of the lightest penguin of each species? You can use &lt;code&gt;min()&lt;/code&gt;. What happens when in addition to species you also group by year &lt;code&gt;group_by(species, year)&lt;/code&gt;?&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answers&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::group_by(species) %&amp;gt;%
  dplyr::summarize(lightest_penguin = min(body_mass_g, na.rm = T))
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
species
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
lightest\_penguin
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adelie
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2850
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chinstrap
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2700
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Gentoo
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3950
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::group_by(species, year) %&amp;gt;%
  dplyr::summarize(lightest_penguin = max(body_mass_g, na.rm = T)) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &#39;species&#39;. You can override using the `.groups` argument.
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;36-arrange&#34;&gt;3.6. &lt;code&gt;arrange()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;arrange()&lt;/code&gt; verb is pretty self-explanatory. &lt;code&gt;arrange()&lt;/code&gt; orders the rows of a data frame by the values of selected columns in ascending order. You can use the &lt;code&gt;desc()&lt;/code&gt; argument inside to arrange in descending order. The following chunk arranges the data frame based on the length of the penguins’ bill. You hint tab contains the code for the descending order alternative.&lt;/p&gt;
&lt;center&gt;
arrange(variable\_of\_interest)
&lt;/center&gt;
&lt;br&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::arrange(bill_length_mm)
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid12.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::arrange(desc(bill_length_mm))
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid13.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;
&lt;em&gt;Can you create a data frame arranged by body_mass_g of the penguins observed in the “Dream” island?&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;penguins %&amp;gt;%
  dplyr::filter(island == &amp;quot;Dream&amp;quot;) %&amp;gt;%
  dplyr::arrange(desc(body_mass_g)) 
&lt;/code&gt;&lt;/pre&gt;
&lt;iframe src=&#34;../wid14.html&#34; width=&#34;100%&#34; height=&#34;500&#34;&gt;
&lt;/iframe&gt;
&lt;/p&gt;
&lt;/details&gt;
</description>
    </item>
    
    <item>
      <title>Basics of Data Visualization and DAGs in R</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-3/03-online-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-3/03-online-tutorial/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load packages. Install them first, in case you don&amp;#39;t have them yet.

library(palmerpenguins) # To get our example&amp;#39;s dataset
library(tidyverse) # To use dplyr functions and the pipe operator when needed
library(ggplot2) # To visualize data (this package is also loaded by library(tidyverse))
library(ggdag) # To create our DAGs&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;div id=&#34;welcome&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Welcome&lt;/h1&gt;
&lt;p&gt;This week&#39;s tutorial will be divided in two broader camps.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, we will learn some basics of data visualization with &lt;code&gt;ggplot&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Second, we will start our exploration of &lt;strong&gt;directed acyclic graphs (DAGs)&lt;/strong&gt; for causal inference.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction-to-ggplot2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction to &lt;code&gt;ggplot2&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;ggplot2&lt;/code&gt; is by far the most popular visualization package in &lt;strong&gt;R&lt;/strong&gt;. &lt;code&gt;ggplot2&lt;/code&gt; implements the &lt;strong&gt;grammar of graphics&lt;/strong&gt; to render a versatile syntax of creating visuals. The underlying logic of the package relies on deconstructing the structure of graphs (if you are interested in this you can read this &lt;a href=&#34;http://vita.had.co.nz/papers/layered-grammar.pdf&#34;&gt;article&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;For the purposes of this introduction to visualization with ggplot, we care about the layered nature of visualizing with &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/94537983-b94fa100-0243-11eb-8d12-c2e685141092.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;*&lt;em&gt;This tutorial is based largely on chapters 7 to 10 from the &lt;a href=&#34;http://qpolr.com/dataviz.html&#34;&gt;QPOLR book&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;our-building-blocks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Our building blocks&lt;/h2&gt;
&lt;p&gt;During this week, we will learn about the following building blocks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: the data frame, or data frames, we will use to plot&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Aesthetics&lt;/strong&gt;: the variables we will be working with&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Geometric objects&lt;/strong&gt;: the type of visualization&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theme adjustments&lt;/strong&gt;: size, text, colors etc&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data&lt;/h3&gt;
&lt;p&gt;The first building block for our plots are the data we intend to map. In &lt;code&gt;ggplot2&lt;/code&gt;, we always have to specify the object where our data lives. In other words, you will always have to specify a data frame, as such:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(name_of_your_df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the future, we will see how to combine multiple data sources to build a single plot. For now, we will work under the assumption that all your data live in the same object.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;aesthetics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Aesthetics&lt;/h3&gt;
&lt;p&gt;The second building block for our plots are the aesthetics. We need to specify the variables in the data frame we will be using and what role they play.&lt;/p&gt;
&lt;p&gt;To do this we will use the function &lt;code&gt;aes()&lt;/code&gt; within the &lt;code&gt;ggplot()&lt;/code&gt; function after the data frame &lt;strong&gt;(remember to add a comma after the data frame)&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(name_of_your_df, aes(x = your_x_axis_variable, y = your_y_axis_variable))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Beyond your axis, you can add more aesthetics representing further dimensions of the data in the two dimensional graphic plane, such as: size, color, fill, to name but a few.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;geometric-objects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Geometric objects&lt;/h3&gt;
&lt;p&gt;The third layer to render our graph is a geomethic object. To add one, we need to add a plus (&lt;strong&gt;+&lt;/strong&gt;) at the end of the initial line and state the type of geometric object we want to add, for example, &lt;code&gt;geom_point()&lt;/code&gt; for a scatter plot, or &lt;code&gt;geom_bar()&lt;/code&gt; for barplots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(name_of_your_df, aes(x = your_x_axis_variable, y = your_y_axis_variable)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;theme&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Theme&lt;/h3&gt;
&lt;p&gt;At this point our plot may just need some final thouches. We may want to fix the axes names or get rid of the default gray background. To do so, we need to add an additional layer preceded by a plus sign (+).&lt;/p&gt;
&lt;p&gt;If we want to change the names in our axes, we can utilize the &lt;code&gt;labs()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;We can also employ some of the pre-loaded themes, for example, &lt;code&gt;theme_minimal()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(name_of_your_df, aes(x = your_x_axis_variable, y = your_y_axis_variable)) +
  geom_point() +
  theme_minimal() +
  labs(x = &amp;quot;Name you want displayed&amp;quot;,
       y = &amp;quot;Name you want displayed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;our-first-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Our first plot&lt;/h3&gt;
&lt;p&gt;For our very first plot using &lt;code&gt;ggplot2&lt;/code&gt;, we will use the &lt;code&gt;penguins&lt;/code&gt; data from last week.&lt;/p&gt;
&lt;p&gt;We would like to create a scatterplot that illustrates the relationship between the length of a penguin&#39;s flipper and their weight.&lt;/p&gt;
&lt;p&gt;To do so, we need three of our building blocks: a) data, b) aesthetics, and c) a geometric object (&lt;code&gt;geom_point()&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = flipper_length_mm, y=body_mass_g)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834786-e1fb7d00-75ce-11eb-8a23-81414b76c484.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;b&gt;
&lt;p style= &#34;color: #9F24FF&#34;&gt;
EXERCISE:
&lt;p&gt;
&lt;p&gt;&lt;/b&gt; Once we have our scatterplot. Can you think of a way to adapt the code to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;convey another dimension through color, the species of penguin&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;change the axes names&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;render the graph with &lt;code&gt;theme_minimal()&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = flipper_length_mm, y=body_mass_g, color=species)) +
  geom_point() +
  theme_minimal() +
  labs(x = &amp;quot;Flipper Length (mm)&amp;quot;,
       y = &amp;quot;Body mass (g)&amp;quot;,
       color = &amp;quot;Species&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834863-f770a700-75ce-11eb-8fb4-b410dcd830f9.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-effectively&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualizing effectively&lt;/h1&gt;
&lt;div id=&#34;plotting-distributions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting distributions&lt;/h2&gt;
&lt;p&gt;If we are interested in plotting distributions of our data, we can leverage geometric objects, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;geom_histogram()&lt;/code&gt;: visualizes the distribution of a single continuous variable by dividing the x axis into bins and counting the number of observations in each bin (the default is 30 bins).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;geom_density()&lt;/code&gt;: computes and draws kernel density estimate, which is a smoothed version of the histogram.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;geom_bar()&lt;/code&gt;: renders barplots and in plotting distributions behaves in a very similar way from &lt;code&gt;geom_histogram()&lt;/code&gt; (can also be used with two dimensions)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a histogram presenting the weight distribution of penguins in our sample. .&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = body_mass_g)) +
  geom_histogram()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834871-f93a6a80-75ce-11eb-9a05-2161f6bad744.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;b&gt;
&lt;p style= &#34;color: #9F24FF&#34;&gt;
EXERCISE:
&lt;p&gt;
&lt;p&gt;&lt;/b&gt; Let&#39;s adapt the code of our histogram:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;add &lt;code&gt;bins = 15&lt;/code&gt; argument (type different numbers)&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;add &lt;code&gt;fill = &amp;quot;#FF6666&amp;quot;&lt;/code&gt; (type &amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;, instead of #FF6666)&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;change the geom to &lt;code&gt;_density&lt;/code&gt; and &lt;code&gt;_bar&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;ul&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Histogram with bins argument&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = body_mass_g)) +
  geom_histogram(bins = 15)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834874-f9d30100-75ce-11eb-869e-d25423127afe.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Histogram with bins and fill arguments&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = body_mass_g)) +
  geom_histogram(bins = 25, fill = &amp;quot;#FF6666&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834878-fa6b9780-75ce-11eb-833d-8675c65c2d34.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;geom_density()&lt;/code&gt; and &lt;code&gt;geom_bar()&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = body_mass_g)) +
  geom_density(alpha = 0.5, fill = &amp;quot;#FF6666&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834879-fa6b9780-75ce-11eb-8b54-e73421f810fb.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = body_mass_g)) +
  geom_bar(fill = &amp;quot;#FF6666&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834882-fb042e00-75ce-11eb-8fd0-e309766734c0.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr /&gt;
&lt;div id=&#34;plotting-relationships&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Plotting relationships&lt;/h3&gt;
&lt;p&gt;We can utilize graphs to explore how different variables are related. In fact, we did so before in our scatterplot. We can also use box plots and lines to show some of these relationships.&lt;/p&gt;
&lt;p&gt;For example, this boxplot showcasing the distribution of weight by species:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = species, y = body_mass_g)) +
  geom_boxplot() +
  theme_minimal() +
  labs(x = &amp;quot;Species&amp;quot;,
       y = &amp;quot;Body mass (g)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834883-fb042e00-75ce-11eb-9081-f0fe68593721.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Or this adaptation of our initial plot with a line of best fit for the observed data by each species:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x= flipper_length_mm, y = body_mass_g, color = species)) +
  geom_point() + 
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = F) +
  theme_minimal() +
  labs(x = &amp;quot;Length of the flipper&amp;quot;,
       y = &amp;quot;Body mass (g)&amp;quot;,
       color = &amp;quot;Species&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834884-fb042e00-75ce-11eb-8a4a-e10efcd16bd5.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Next steps&lt;/h3&gt;
&lt;p&gt;Now that you have been introduced to some of the basics of &lt;code&gt;ggplot2&lt;/code&gt;, &lt;strong&gt;the best way to move forward is to experiment&lt;/strong&gt;. As we have discussed before, the &lt;strong&gt;R&lt;/strong&gt; community is very open. Perhaps, you can gather some inspiration from the Tidy Tuesday social data project in R where users explore a new dataset each week and share their visualizations and code on Twitter under #TidyTuesday. You can explore some of the previous visualizations &lt;a href=&#34;https://shiny.rstudio.com/gallery/tidy-tuesday.html&#34;&gt;here&lt;/a&gt; and try to replicate their code.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://github.com/erikgahner/awesome-ggplot2&#34;&gt;Here is a curated list&lt;/a&gt; of awesome &lt;code&gt;ggplot2&lt;/code&gt; resources.&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;directed-acyclic-graphs-dags&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Directed Acyclic Graphs (DAGs)&lt;/h2&gt;
&lt;p&gt;This week we learned that &lt;strong&gt;directed acyclic graphs (DAGs)&lt;/strong&gt; are very useful to express our beliefs about relationships among variables.&lt;/p&gt;
&lt;p&gt;DAGs are compatible with the potential outcomes framework. They give us a more convinient and intuitive way of laying out causal models. Next week we will learn how they can help us develop a modeling strategy.&lt;/p&gt;
&lt;p&gt;Today, we will focus on their structure and some DAG basics with the &lt;code&gt;ggdag&lt;/code&gt; package.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;creating-dags-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating DAGs in R&lt;/h3&gt;
&lt;p&gt;To create our DAGs in &lt;strong&gt;R&lt;/strong&gt; we will use the &lt;code&gt;ggdag&lt;/code&gt; packages.&lt;/p&gt;
&lt;p&gt;The first thing we will need to do is to create a &lt;strong&gt;dagified&lt;/strong&gt; object. That is an object where we state our variables and the relationships they have to each other. Once we have our &lt;strong&gt;dag object&lt;/strong&gt; we just need to plot with the &lt;code&gt;ggdag()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Let&#39;s say we want to re-create this DAG:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108728442-e4f06200-7529-11eb-90a9-90ae6bff6f06.png&#34; width=&#34;50%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We would like to express the following links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P -&amp;gt; D&lt;/li&gt;
&lt;li&gt;D -&amp;gt; M&lt;/li&gt;
&lt;li&gt;D -&amp;gt; Y&lt;/li&gt;
&lt;li&gt;M -&amp;gt; Y&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To do so in &lt;strong&gt;R&lt;/strong&gt; with &lt;code&gt;ggdag&lt;/code&gt;, we would use the following syntax:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dag_object &amp;lt;- ggdag::dagify(variable_being_pointed_at ~ variable_pointing,
                            variable_being_pointed_at ~ variable_pointing,
                            variable_being_pointed_at ~ variable_pointing)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After this we would just:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggdag::ggdag(dag_object)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Let&#39;s plot this DAG&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;our_dag &amp;lt;- ggdag::dagify(d ~ p,
                         m ~ d,
                         y ~ d,
                         y ~ m)

ggdag::ggdag(our_dag)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834887-fb9cc480-75ce-11eb-8ec0-a2c28143612e.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;b&gt;
&lt;p style= &#34;color: #9F24FF&#34;&gt;
EXERCISE:
&lt;p&gt;
&lt;p&gt;&lt;/b&gt; See what happens when you add &lt;code&gt;+ theme_minimal()&lt;/code&gt;, &lt;code&gt;+ theme_void()&lt;/code&gt;, or &lt;code&gt;+ theme_dag() to the DAG. What package do you think is laying behind the mappings of&lt;/code&gt;ggdag`?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;our_dag &amp;lt;- ggdag::dagify(d ~ p,
                         m ~ d,
                         y ~ d,
                         y ~ m)

ggdag::ggdag(our_dag) +
  theme_minimal()

ggdag::ggdag(our_dag) +
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834889-fb9cc480-75ce-11eb-9365-bb22788e4a10.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834890-fc355b00-75ce-11eb-95bc-76a89d88095f.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;polishing-our-dags-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Polishing our DAGs in R&lt;/h3&gt;
&lt;p&gt;As you may have seen, the DAG is not rendered with the nodes in the positions we want.&lt;/p&gt;
&lt;p&gt;If you ever want to explicitly tell &lt;code&gt;ggdag&lt;/code&gt; where to position each node, you can tell it in a Cartesian coordinate plane.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108733908-30f1d580-752f-11eb-8588-241acb7e3dd6.png&#34; width=&#34;35%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let&#39;s take &lt;strong&gt;P&lt;/strong&gt; as the point (0,0):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108735739-2fc1a800-7531-11eb-8764-5e881b120615.png&#34; width=&#34;50%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coord_dag &amp;lt;- list(
  x = c(p = 0, d = 1, m = 2, y = 3),
  y = c(p = 0, d = 0, m = 1, y = 0)
)

our_dag &amp;lt;- ggdag::dagify(d ~ p,
                         m ~ d,
                         y ~ d,
                         y ~ m,
                         coords = coord_dag)

ggdag::ggdag(our_dag) + theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834892-fc355b00-75ce-11eb-8a50-054ed9c5fffb.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;more-complex-example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;More complex example:&lt;/h3&gt;
&lt;p&gt;Let&#39;s say we&#39;re looking at the relationship between smoking and cardiac arrest. We might assume that smoking causes changes in cholesterol, which causes cardiac arrest:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;smoking_ca_dag &amp;lt;- ggdag::dagify(cardiacarrest ~ cholesterol,
                                cholesterol ~ smoking + weight,
                                smoking ~ unhealthy,
                                weight ~ unhealthy,
                                labels = c(&amp;quot;cardiacarrest&amp;quot; = &amp;quot;Cardiac\n Arrest&amp;quot;, 
                                           &amp;quot;smoking&amp;quot; = &amp;quot;Smoking&amp;quot;,
                                           &amp;quot;cholesterol&amp;quot; = &amp;quot;Cholesterol&amp;quot;,
                                           &amp;quot;unhealthy&amp;quot; = &amp;quot;Unhealthy\n Lifestyle&amp;quot;,
                                           &amp;quot;weight&amp;quot; = &amp;quot;Weight&amp;quot;)
                                )

ggdag::ggdag(smoking_ca_dag, # the dag object we created
             text = FALSE, # this means the original names won&amp;#39;t be shown
             use_labels = &amp;quot;label&amp;quot;) + # instead use the new names
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834893-fccdf180-75ce-11eb-8494-937fd8b8da95.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this example, we:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Used more meaningful variable names&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Created a variable that was the result of two variables vs. just one (cholesterol)&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Used the &amp;quot;labels&amp;quot; argument to rename our variables (this is useful if your desired final variable name is more than one word)&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;common-dag-path-structures&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Common DAG path structures&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/94547573-b8bd0780-024f-11eb-9565-03b1d1109c3b.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coord_dag &amp;lt;- list(
  x = c(d = 0, x = 1, y = 2),
  y = c(d = 0, x = 1, y = 0)
)

our_dag &amp;lt;- ggdag::dagify(x ~ d,
                         y ~ d,
                         y ~ x,
                         coords = coord_dag)

ggdag::ggdag(our_dag) + theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;section&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834894-fccdf180-75ce-11eb-89ef-d0e7ecf2719f.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/h2&gt;
&lt;b&gt;
&lt;p style= &#34;color: #9F24FF&#34;&gt;
EXERCISE:
&lt;p&gt;
&lt;p&gt;&lt;/b&gt; Let&#39;s adapt the code to make &lt;strong&gt;X&lt;/strong&gt; a &lt;strong&gt;confounder&lt;/strong&gt; and a &lt;strong&gt;collider&lt;/strong&gt;.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;ul&gt;
&lt;li&gt;&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;X as a confounder&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coord_dag &amp;lt;- list(
  x = c(d = 0, x = 1, y = 2),
  y = c(d = 0, x = 1, y = 0)
)
&lt;p&gt;our_dag &amp;lt;- ggdag::dagify(d ~ x, #line from x to d
y ~ d, #line from d to y
y ~ x, #line from x to y
coords = coord_dag)&lt;/p&gt;
&lt;p&gt;ggdag::ggdag(our_dag) + theme_void()&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834897-fd668800-75ce-11eb-8ce1-771415724e13.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;X as a collider&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coord_dag &amp;lt;- list(
  x = c(d = 0, x = 1, y = 2),
  y = c(d = 0, x = 1, y = 0)
)
&lt;p&gt;our_dag &amp;lt;- ggdag::dagify(x ~ d, #line from d to x
y ~ d, #line from d to y
x ~ y, #line from y to x
coords = coord_dag)&lt;/p&gt;
&lt;p&gt;ggdag::ggdag(our_dag) + theme_void()&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/108834900-fd668800-75ce-11eb-9a0c-e9de3be4fd93.png&#34; width=&#34;70%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Difference in Differences</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-8/08-online-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-8/08-online-tutorial/</guid>
      <description>
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;welcome&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Welcome&lt;/h2&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction!&lt;/h3&gt;
&lt;p&gt;Welcome to our eighth tutorial for the Statistics II: Statistical Modeling &amp;amp; Causal Inference (with R) course.&lt;/p&gt;
&lt;p&gt;During this week’s lecture you were introduced to Difference in Differences (DiD).&lt;/p&gt;
&lt;p&gt;In this lab session we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learn how to transform our dataframes from wide to long format with &lt;code&gt;tidyr:pivot_longer()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Leverage visualizations with &lt;code&gt;ggplot2&lt;/code&gt; to explore changes between groups and across time&lt;/li&gt;
&lt;li&gt;Learn how to extract our DiD estimates through manual calculation, first differences, and the regression formulation of the DiD model&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wide-and-long-data-formats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Wide and long data formats&lt;/h2&gt;
&lt;p&gt;As we have seen throughout the semester, there are multiple ways to store our data. This week, we will look at the difference between &lt;strong&gt;wide&lt;/strong&gt; and &lt;strong&gt;long&lt;/strong&gt; format data.&lt;/p&gt;
&lt;p&gt;We will illustrate this with a brief example. The two datasets we will load —&lt;code&gt;city_wide_df&lt;/code&gt; and &lt;code&gt;city_long_df&lt;/code&gt;— &lt;strong&gt;contain the same information&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;wide&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Wide&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wide data frame
city_wide_df %&amp;gt;% knitr::kable() %&amp;gt;% kableExtra::kable_styling()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
city
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pop_2000
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pop_2010
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pop_2020
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berlin
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.56
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rome
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.26
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paris
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
London
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.30
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;long&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Long&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# long data frame
city_long_df %&amp;gt;% knitr::kable() %&amp;gt;% kableExtra::kable_styling()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
city
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pop
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berlin
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.38
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berlin
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.45
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Berlin
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.56
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rome
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.70
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rome
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.96
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rome
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.26
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paris
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.74
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paris
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.46
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Paris
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
London
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.27
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
London
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2010
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.04
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
London
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.30
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As we can see, the long dataset separates the unit of analysis (city-year) into two separate columns. On the other hand, the wide dataset combines one of the keys (year) with the value variable (population).&lt;/p&gt;
&lt;hr /&gt;
&lt;h5 style=&#34;color:#cc0055;&#34;&gt;
Why do we care about the data format
&lt;/h5&gt;
&lt;p&gt;In some instances, long format datasets are required for advanced statistical analysis and graphing. For example, if we wanted to run the regression formulation of the difference in differences model, we would need to input our data in long format. Furthermore, having our data in long format is very useful when plotting. Packages such as &lt;code&gt;ggplot2&lt;/code&gt;, expect that your data will be in long form for the most part.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;converting-from-wide-to-long-format&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Converting from wide to long format&lt;/h3&gt;
&lt;p&gt;We will learn how to pivot our wide format data to long format with the &lt;code&gt;tidyr&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;We will use the &lt;code&gt;tidyr::pivot_longer()&lt;/code&gt; function, which “lengthens” data, increasing the number of rows and decreasing the number of columns. The inverse transformation is &lt;code&gt;tidyr::pivot_wider()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can read the vignette &lt;a href=&#34;https://tidyr.tidyverse.org/articles/pivot.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h5 style=&#34;color:#cc0055;&#34;&gt;
How to use &lt;code&gt;tidyr::pivot_longer()&lt;/code&gt;
&lt;/h5&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;your_new_long_df &amp;lt;- 
  tidyr::pivot_longer(
    your_wide_df,
    cols,
    names_to = &amp;quot;name&amp;quot;,
    values_to = &amp;quot;value&amp;quot;  
    ...
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s turn the &lt;code&gt;city_wide_df&lt;/code&gt; into a long format dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;city_wide_df %&amp;gt;%
  tidyr::pivot_longer(
    cols = c(pop_2000, pop_2010, pop_2020), # -city, !city, dplyr::starts_with(&amp;quot;pop_&amp;quot;), etc... would also work
    names_to = &amp;quot;year&amp;quot;, # where do we want the names of the columns to go? (year)
    names_prefix = &amp;quot;pop_&amp;quot;, # names_prefix removes matching text from the start of each variable name (not always necessary)
    values_to = &amp;quot;pop&amp;quot; # where do we want the values in the columns to go? (pop)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 × 3
##    city   year    pop
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Berlin 2000   3.38
##  2 Berlin 2010   3.45
##  3 Berlin 2020   3.56
##  4 Rome   2000   3.7 
##  5 Rome   2010   3.96
##  6 Rome   2020   4.26
##  7 Paris  2000   9.74
##  8 Paris  2010  10.5 
##  9 Paris  2020  11.0 
## 10 London 2000   7.27
## 11 London 2010   8.04
## 12 London 2020   9.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try to delete the &lt;code&gt;names_prefix = &#34;pop_&#34;&lt;/code&gt; argument to see what happens.&lt;/p&gt;
&lt;p&gt;Let’s move to our practical example to see how we can use &lt;strong&gt;R&lt;/strong&gt; for DiD estimation.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;measuring-the-effect-of-a-soda-tax-on-sugar-added-drink-consumption&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Measuring the effect of a soda tax on sugar-added drink consumption&lt;/h2&gt;
&lt;p&gt;After the very successful impact evaluations you have performed in the past weeks, you are contacted by the local government of Pawnee, Indiana. The city is interested in your advice to assess a policy intervention passed with the support of councilwoman Leslie Knope.&lt;/p&gt;
&lt;p&gt;The city of Pawnee has been at the spotlight recently, as it has come to be known as the child obesity and diabetes capital of the state of Indiana. Some of the constituents of the city point at the fast food culture and soda sizes across the restaurants in town as a source of the problem. The largest food chain in Pawnee, Paunch Burger, offers its smallest soda size at a whopping 64oz (about 1.9 liters).&lt;/p&gt;
&lt;p&gt;The “soda tax”, as it came to be known, came to effect initially at a couple of districts. Fortunately for you, based on an archaic law, residents of Indiana have to demonstrate their residence in the district they intend to dine before being served at any of the restaurants. The latter fact means that Pawnee inhabitants can only buy sugar-added drinks in their respective home district.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/CAXFvut1tBBf2/giphy.gif&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Packages&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# These are the libraries we will use today. Make sure to install them in your console in case you have not done so previously.

set.seed(42) #for consistent results

library(dplyr) # to wrangle our data
library(tidyr) # to wrangle our data - pivot_longer()
library(ggplot2) # to render our graphs
library(readr) # for loading the .csv data
library(kableExtra) # to render better formatted tables
library(stargazer) # for formatting your model output

library(estimatr) # to employ lm_robust()

soda_tax_df &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/seramirezruiz/hertiestats2/master/data/soda_tax_df.csv&amp;quot;) # simulated data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our dataset &lt;em&gt;soda_tax_df&lt;/em&gt;, contains the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ìd&lt;/code&gt;: A unique number identifier for each of the 7,500 inhabitants of Pawnee&lt;/li&gt;
&lt;li&gt;&lt;code&gt;district&lt;/code&gt;: The name of the district in which the corresponding unit lives&lt;/li&gt;
&lt;li&gt;&lt;code&gt;treatment&lt;/code&gt;: A binary variable that signals whether the subject lived in a district where the tax was implemented&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pre_tax&lt;/code&gt;: The weekly sugar-added drink consumption in ounces before the tax was imposed&lt;/li&gt;
&lt;li&gt;&lt;code&gt;post_tax&lt;/code&gt;: The weekly sugar-added drink consumption in ounces after the tax was imposed&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 style=&#34;color:#cc0055;&#34;&gt;
Are these wide or long format data?
&lt;/h5&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;soda_tax_df %&amp;gt;% head(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 × 5
##       id district     treatment pre_tax post_tax
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1     1 Snake Lounge         0   1688.    1706.
##  2     2 Snake Lounge         0    427.     438.
##  3     3 Snake Lounge         0    566.     560.
##  4     4 Snake Lounge         0    607.     624.
##  5     5 Snake Lounge         0    573.     607.
##  6     6 Snake Lounge         0    496.     502.
##  7     7 Snake Lounge         0    659.     670.
##  8     8 Snake Lounge         0    498.     522.
##  9     9 Snake Lounge         0    815.     846.
## 10    10 Snake Lounge         0    503.     510.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our &lt;code&gt;soda_tax_df&lt;/code&gt; is in wide format. We can convert our data to a long format to render the time and treatment dummy variables and save is to the &lt;code&gt;soda_tax_df_long&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We will utilize the &lt;em&gt;pivot_longer()&lt;/em&gt; function from &lt;code&gt;tidyr&lt;/code&gt; to format our data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;soda_tax_df_long &amp;lt;- 
  soda_tax_df %&amp;gt;% # the wide format df
  tidyr::pivot_longer(cols = c(pre_tax, post_tax), # both contain information about soda drank at two points in time
                      names_to = &amp;quot;period&amp;quot;, # grab the names of pre and post and save them to period
                      values_to = &amp;quot;soda_drank&amp;quot;) %&amp;gt;% # grab values from pre and post and put them in soda_drank
  dplyr::mutate(after_tax = ifelse(period == &amp;quot;post_tax&amp;quot;, 1, 0)) # create dummy for period

head(soda_tax_df_long, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 × 6
##       id district     treatment period   soda_drank after_tax
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1     1 Snake Lounge         0 pre_tax       1688.         0
##  2     1 Snake Lounge         0 post_tax      1706.         1
##  3     2 Snake Lounge         0 pre_tax        427.         0
##  4     2 Snake Lounge         0 post_tax       438.         1
##  5     3 Snake Lounge         0 pre_tax        566.         0
##  6     3 Snake Lounge         0 post_tax       560.         1
##  7     4 Snake Lounge         0 pre_tax        607.         0
##  8     4 Snake Lounge         0 post_tax       624.         1
##  9     5 Snake Lounge         0 pre_tax        573.         0
## 10     5 Snake Lounge         0 post_tax       607.         1&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-our-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring our data&lt;/h2&gt;
&lt;p&gt;We can use our &lt;code&gt;soda_tax_df&lt;/code&gt; to explore the distribution of soda consumption at different points in time.&lt;/p&gt;
&lt;p&gt;Let’s try first to look at the differences in the distribution only at the &lt;strong&gt;pre-tax time period:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(soda_tax_df, aes(x = pre_tax, fill = factor(treatment))) + 
  geom_density(alpha = 0.5) + # density plot with transparency (alpha = 0.5)
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(title = &amp;quot;Distribution of soda consumption before the tax was imposed&amp;quot;,
       x = &amp;quot;Soda consumtion (oz)&amp;quot;,
       y = &amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113713122-3ffba400-96e7-11eb-9c81-a9dafb160e0b.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s look at the &lt;strong&gt;post-tax period:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(soda_tax_df, aes(x = post_tax, fill = factor(treatment))) + 
  geom_density(alpha = 0.5) + # density plot with transparency (alpha = 0.5)
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(title = &amp;quot;Distribution of soda consumption after the tax was imposed&amp;quot;,
       x = &amp;quot;Soda consumtion (oz)&amp;quot;,
       y = &amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113713140-4427c180-96e7-11eb-938e-88fc7b1eda5f.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Since in our &lt;code&gt;soda_tax_df_long&lt;/code&gt; we represent the time and soda consumption dimensions under the same columns, we can create even more complex graphs.&lt;/p&gt;
&lt;p&gt;Let’s leverage a new layer of our grammar of graphs: &lt;strong&gt;Facets&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We will use &lt;code&gt;facet_grid()&lt;/code&gt; which forms a matrix of panels defined by row and column faceting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;soda_tax_df_long %&amp;gt;% 
  dplyr::mutate(period = ifelse(period == &amp;quot;post_tax&amp;quot;, &amp;quot;T1 - Post-tax&amp;quot;, &amp;quot;T0 - Pre-tax&amp;quot;), # create more meaningful labels
                treatment = ifelse(treatment == 1, &amp;quot;Treated (D=1)&amp;quot;, &amp;quot;Untreated (D=0)&amp;quot;)) %&amp;gt;%
  dplyr::group_by(period, treatment) %&amp;gt;% # group to extract means of each group at each time
  dplyr::mutate(group_mean = mean(soda_drank)) %&amp;gt;% # extract means of each group at each time
ggplot(., aes(x = soda_drank, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#cc0055&amp;quot;, &amp;quot;#a7a8aa&amp;quot;),
                     labels = c(&amp;quot;Treatment&amp;quot;, &amp;quot;Control&amp;quot;)) +
  facet_grid(treatment~period) + # we specify the matrix (treatment and period)
  geom_vline(aes(xintercept = group_mean), linetype = &amp;quot;longdash&amp;quot;) + # add vertical line with the mean
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  labs(x = &amp;quot;Soda consumed (oz)&amp;quot;,
       y = &amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113713145-45f18500-96e7-11eb-962e-4e4af95c834f.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-and-estimating&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling and estimating&lt;/h2&gt;
&lt;p&gt;So far we have ignored time in our estimations. Up until this point, most of the tools we have learned produce estimates of the counterfactual through explicit assignment rules that work randomly or as-if-randomly (e.g. randomized experimental, regression discontinuity, and instrumental variable set-ups).&lt;/p&gt;
&lt;p&gt;Difference-in-differences compares the changes in outcomes over time between units under different treatment states. This allows us to correct for any differences between the treatment and comparison groups that are constant over time assuming that the trends in time are parallel.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;a.-calculating-without-time&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;a. Calculating without time&lt;/h3&gt;
&lt;p&gt;If we did not have the &lt;code&gt;pre_tax&lt;/code&gt; baseline measure, we would likely utilize the &lt;code&gt;post_tax&lt;/code&gt; to explore the average effect on the treated. In this case, we would model this as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;after_model &amp;lt;- lm(post_tax ~ treatment, data = soda_tax_df)
modelsummary::modelsummary(after_model, 
                           statistic = &amp;quot;conf.int&amp;quot;,
                           gof_omit=&amp;quot;AIC|BIC|Log.Lik.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
523.273
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[518.008, 528.537]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-146.918
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[-154.363, -139.472]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7500
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.166
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.166
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1496.245
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We could read this result substantively as: those who lived in districts were the tax was implemented consumed on average 146.9 ounces less of sugar-added drinks per week compared to those who lived in districts were the tax was not put in place. &lt;strong&gt;This calculation would give us a comparison of the treatment and control groups after treatment.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To believe the results of our &lt;code&gt;after_model&lt;/code&gt;, we would need to believe that the mean ignorability of treatment assignment assumption is fulfilled. We would have to think carefully about possible factors that could differentiate our treatment and control groups. We use a treatment indicator based on the districts where the measure was able to be implemented. Treatment was not fully randomly assigned, so there may be lots of potential confounders that create baseline differences in the scores for those living in Old Eagleton compared to those in Snake Lounge, which also affect the after-treatment comparisons.&lt;/p&gt;
&lt;p&gt;If we think about the mechanics behind this naive calculation, we are just comparing the average observed outcomes for those treated and not treated after the tax was imposed:&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Average after tax
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
523.27
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
376.35
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(soda_tax_df, aes(x = post_tax, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  geom_vline(xintercept = 523.27, linetype = &amp;quot;longdash&amp;quot;, color = &amp;quot;#a7a8aa&amp;quot;) + #avg for the untreated
  geom_vline(xintercept = 376.35, linetype = &amp;quot;longdash&amp;quot;, color = &amp;quot;#cc0055&amp;quot;) + #avg for the treated
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(title = &amp;quot;Distribution of soda consumption after the tax was imposed&amp;quot;,
       x = &amp;quot;Soda consumtion (oz)&amp;quot;,
       y = &amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113713161-4853df00-96e7-11eb-9ece-d8bc24d1db0f.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;b.-including-the-time-dimension-manual-extraction-of-the-did-estimate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;b. Including the time dimension (Manual extraction of the DiD estimate)&lt;/h3&gt;
&lt;p&gt;During the lecture component of the class, we learned that the &lt;span class=&#34;math inline&#34;&gt;\(\beta_{DD}\)&lt;/span&gt; is the difference in the differences. You can see it illustrated in the table. We can extract the observed values at each iteration of the treatment and time matrix and then manually subtract the differences.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113552797-f469cd00-95f6-11eb-9366-9163342f00fc.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Period
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Pre-tax
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Post-tax
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Difference
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
511.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
376.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-134.78
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
508.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
523.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.97
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code&gt;## [1] -149.74&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -149.75&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can just manually subtract.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\beta_{DD} = -134.79 - 14.97 = -149.76\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;c.-including-the-time-dimension-first-differences-on-treatment-indicator&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;c. Including the time dimension (First differences on treatment indicator)&lt;/h3&gt;
&lt;p&gt;We can introduce the time component to our calculation by incorporating the pre-treatment levels of sugar-added drink consumption, which gives us the diff-in-diff estimate. We could calculate this in a fairly straightforward manner by creating a variable assessing the change in our wide format data frame:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;change&lt;/code&gt;: The difference in sugar-added drink consumption between post- and pre-tax&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;soda_tax_df &amp;lt;- soda_tax_df %&amp;gt;%
  dplyr::mutate(change = post_tax - pre_tax) #simple subtraction

did_model &amp;lt;- lm(change ~ treatment, data = soda_tax_df)
modelsummary::modelsummary(did_model,
                           statistic = &amp;quot;conf.int&amp;quot;,
                           gof_omit=&amp;quot;AIC|BIC|Log.Lik.&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14.967
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[14.625, 15.308]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-149.744
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[-150.228, -149.261]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7500
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.980
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.980
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
369242.378
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We could read this result substantively as: those who lived in districts were the tax was implemented consumed on average 149.7 ounces less of sugar-added drinks per week compared to those who lived in districts were the tax was not put in place. &lt;strong&gt;This calculation would give us the change, or difference, in sugar-added drink consumption for treatment and control groups.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To believe the results of our &lt;code&gt;did_model&lt;/code&gt;, we would need to believe that there are parallel trends between the two groups.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: when simulating the data the &lt;code&gt;post_tax&lt;/code&gt; was defined as:&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(post\_tax = 15 + pre\_tax - 150(treatment) + error\)&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;d.-including-the-time-dimension-regression-formulation-of-the-did-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;d. Including the time dimension (Regression formulation of the DiD model)&lt;/h3&gt;
&lt;p&gt;Remember the formula from the lecture where we estimate the diff-in-diff effect with time and treatment dummies? We can re-format our data to gather our diff-in-diff estimate.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{it} = β_0 + β_1D^*_i + β_2P_t + β_{DD}D^∗_i × P_t + q_{it} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(D^*_i\)&lt;/span&gt; tell us if subject &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is in the treatment group and &lt;span class=&#34;math inline&#34;&gt;\(P_t\)&lt;/span&gt;
indicates the point in time (1 for post)&lt;/p&gt;
&lt;p&gt;For this calculation we need our data in long format to use the time and treatment dummy variables.&lt;/p&gt;
&lt;p&gt;We can see that under our long format, we have two entries for every individual. We have our variable &lt;code&gt;after_tax&lt;/code&gt;, which represents &lt;span class=&#34;math inline&#34;&gt;\(P_t\)&lt;/span&gt;, where 0 and 1 are pre- and post-tax periods respectively. We can now render our regression based on the formula:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{it} = β_0 + β_1D^*_i + β_2P_t + β_{DD}D^∗_i × P_t + q_{it}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;did_long_clustered_se &amp;lt;- estimatr::lm_robust(soda_drank ~ treatment + after_tax + treatment*after_tax, 
                                                       clusters = district,
                                                       se_type = &amp;quot;stata&amp;quot;,
                                                       data = soda_tax_df_long)

modelsummary::modelsummary(list(did_long_clustered_se), 
                           statistic = &amp;quot;conf.int&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
508.306
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[508.077, 508.535]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.827
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-1.827, 7.480]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
after_tax
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14.967
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[14.890, 15.043]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment × after_tax
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-149.744
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[-150.049, -149.440]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
15000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.117
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
se_type
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
stata
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;h5 style=&#34;color:#cc0055;&#34;&gt;
If we apply the switch logic to the results, we would get the same values from the table and plots
&lt;/h5&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Period
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Pre-tax
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Post-tax
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Difference
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
511.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
376.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-134.78
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
508.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
523.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.97
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;soda_tax_df_long %&amp;gt;% 
  dplyr::mutate(period = ifelse(period == &amp;quot;post_tax&amp;quot;, &amp;quot;T1 - Post-tax&amp;quot;, &amp;quot;T0 - Pre-tax&amp;quot;), # create more meaningful labels
                treatment = ifelse(treatment == 1, &amp;quot;Treated (D=1)&amp;quot;, &amp;quot;Untreated (D=0)&amp;quot;)) %&amp;gt;%
  dplyr::group_by(period, treatment) %&amp;gt;% # group to extract means of each group at each time
  dplyr::mutate(group_mean = mean(soda_drank)) %&amp;gt;% # extract means of each group at each time
ggplot(., aes(x = soda_drank, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#cc0055&amp;quot;, &amp;quot;#a7a8aa&amp;quot;),
                     labels = c(&amp;quot;Treatment&amp;quot;, &amp;quot;Control&amp;quot;)) +
  facet_grid(treatment~period) + # we specify the matrix (treatment and period)
  geom_vline(aes(xintercept = group_mean), linetype = &amp;quot;longdash&amp;quot;) + # add vertical line with the mean
  theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  labs(x = &amp;quot;Soda consumed (oz)&amp;quot;,
       y = &amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113713172-4b4ecf80-96e7-11eb-91ae-7db9d9958665.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;soda_tax_df_long %&amp;gt;%
  dplyr::group_by(period, treatment) %&amp;gt;% # group to extract means of each group at each time
  dplyr::mutate(group_mean = mean(soda_drank)) %&amp;gt;%
  ggplot(aes(x = after_tax, y = group_mean, color = factor(treatment))) +
  geom_point() +
  geom_line(aes(x = after_tax, y = group_mean)) +
  scale_x_continuous(breaks = c(0,1)) +
  scale_color_manual(name = &amp;quot; &amp;quot;, # changes to color dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  labs(x = &amp;quot;Time periods&amp;quot;, y = &amp;quot;Ounces of soda drank per week&amp;quot;, color = &amp;quot;Treatment group&amp;quot;)+
  theme_minimal() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113713182-4db12980-96e7-11eb-90e7-5b7846940246.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;the-mechanics-behind-did&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The mechanics behind DiD&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://nickchk.com/anim/Animation%20of%20DID.gif&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;drafting-some-brief-recommedations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Drafting some brief recommedations&lt;/h2&gt;
&lt;p&gt;Based on your analysis of the data at hand, you decide to recommend that the tax measure should move forward in the rest of Pawnee. You state that it is a very good example of a pigouvian tax, which captures the negative externalizes not included in the market price of sugar-added drinks. The findings suggest that the tax reduced the weekly sugar-added drink consumption by about 150 liquid ounces (almost 4.5 liters).&lt;/p&gt;
&lt;p&gt;Your evaluation report is so convincing that the Director of the Parks Department, Ron Swanson, is even doubting libertarianism.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/vV7enqX.gif&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Instrumental Variables</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-6/06-online-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-6/06-online-tutorial/</guid>
      <description>
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2021-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2021-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;welcome&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Welcome&lt;/h2&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction!&lt;/h3&gt;
&lt;p&gt;Welcome to our sixth tutorial for the Statistics II: Statistical Modeling &amp;amp; Causal Inference (with R) course.&lt;/p&gt;
&lt;p&gt;During this week&#39;s lecture you reviewed what happens when experiments break due to non-compliance. You were also introduced to &lt;strong&gt;encouragement experimental setups&lt;/strong&gt;, and their the observational analogue, &lt;strong&gt;instrumental variables&lt;/strong&gt;. Finally, you learned how you can estimate local average treatment effects by breaking out the variation in &lt;strong&gt;D&lt;/strong&gt; into two parts.&lt;/p&gt;
&lt;p&gt;In this lab session we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Review how to manually extract the LATE through the &lt;strong&gt;wald estimator&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Learn how to perform Two-stage Least Squares regression (2SLS) with &lt;code&gt;ivreg()&lt;/code&gt; from the &lt;code&gt;AER&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Illustrate the mechanics of Two-stage Least Squares regression (2SLS) with &lt;code&gt;lm()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Packages&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# These are the libraries we will use today. Make sure to install them in your console in case you have not done so previously.

library(tidyverse) # To load the collection of packages in the tidyverse
library(dplyr) # To wrangle our data (this package is also loaded by library(tidyverse))
library(readr) # To load the .csv data (this package is also loaded by library(tidyverse))
library(ggplot2) # To create plots (this package is also loaded by library(tidyverse))
library(tidyr) # To use pivot_wider() (this package is also loaded by library(tidyverse))
library(ggdag) # To dagify and plot our DAG objects in R
#library(summarytools) # for ctable()
library(broom) # To format regression output
library(janitor) # To examine our data with tabyl()
library(stargazer) # To format model output
library(knitr) # To create HTML tables with kable()
library(kableExtra) # To format the HTML tables
library(AER) # To run 2SLS with ivreg()&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;measuring-the-effect-of-mosquito-net-use-on-malaria-infections&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Measuring the effect of mosquito net use on malaria infections&lt;/h2&gt;
&lt;p&gt;Imagine that the organization you work for is laying out a project to distribute mosquito nets to help combat malaria transmitions.&lt;/p&gt;
&lt;p&gt;The funding agency requires a impact evaluation report from your organization. You are in charge of running the evaluation of this program.&lt;/p&gt;
&lt;p&gt;You realize that there are potential &lt;span style=&#34;color:#6600cc;&#34;&gt;unobserved counfounders&lt;/span&gt; that could bias the observed differences in malaria risk for mosquito net users and non-users. You also think about the ethical considerations of fully randomizing who receives the nets, so you remember your Statistics II lecture on IVs and set up an &lt;strong&gt;encouragement design&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Your benificiaries are scattered across ten villages. You decide to randomly select five villages to &lt;span style=&#34;color:#cc0055;&#34;&gt;send SMS reminders every night encouraging them to use the mosquito nets&lt;/span&gt;. (This example is using simulated data) &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/110632472-f2535080-81a7-11eb-9143-60ab36ecff07.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Assumptions&lt;/h3&gt;
&lt;p&gt;To render credible results for the evaluation of this program, we need to fulfill a certain set of assumtions:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;a) Relevance:&lt;/strong&gt; Also known as non-zero average encouragement effect. Does our &lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt; create variation in our &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;? In other words, is the mosquito net use different under the encouragement group? (Statistically testable)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;b) Exogeneity/Ignorability of the instrument:&lt;/strong&gt; Potential outcomes and treatments are independent of &lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt;. In this case given by out randomization of encouragement by villages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;c) Exclusion restriction:&lt;/strong&gt; The instrument only affects the outcome via the treatment. In other words, there are no alternative paths through which our SMS can have an effect on malaria infections other that the use of the mosquito nets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;d) Monotonicity:&lt;/strong&gt; No defiers. We assume that non-compliers fall in the camp of always- and never-takers. We would not expect subjects who when encouraged would not use the nets, but would use them if they did not recieve the SMS reminder.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-our-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring our data&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;evaluation_df &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/seramirezruiz/stats-ii-lab/master/Session%205/data/evaluation_data.csv&amp;quot;) # loading simulated data frame of the intervention&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You receive the results of your intervention from the M&amp;amp;E officers. There are 1000 inhabitants across the ten villages. This is what the data look like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;village_name&lt;/code&gt;: A character string with the name of the village&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sms&lt;/code&gt;: A binary marker for the SMS encouragement&lt;/li&gt;
&lt;li&gt;&lt;code&gt;net_use&lt;/code&gt;: A binary marker for mosquito net use&lt;/li&gt;
&lt;li&gt;&lt;code&gt;malaria&lt;/code&gt;: A binary marker for malaria infection&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#cc0055;&#34;&gt;
Compliance types
&lt;/h4&gt;
&lt;p&gt;You may remember, this table from the lecture:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/seramirezruiz/stats-ii-lab/master/Session%205/data/compliance.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;We can crosstabulate our data with &lt;code&gt;janitor::tabyl()&lt;/code&gt; and the additional features of the &lt;code&gt;janitor::adorn_*&lt;/code&gt; functions.&lt;/p&gt;
&lt;p&gt;Why &lt;code&gt;janitor::tabyl()&lt;/code&gt;? Because as prospective policy analysts we will do a lot of counting.&lt;/p&gt;
&lt;p&gt;As the &lt;a href=&#34;https://cran.r-project.org/web/packages/janitor/vignettes/tabyls.html&#34;&gt;vignette&lt;/a&gt; of the package even puts it:&lt;/p&gt;
&lt;p&gt;Analysts do a lot of counting. Indeed, it’s been said that &#39;data science is mostly counting things.&#39; But the base R function for counting, &lt;code&gt;table()&lt;/code&gt;, leaves much to be desired:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It doesn’t accept data.frame inputs (and thus doesn’t play nicely with the %&amp;gt;% pipe)&lt;/li&gt;
&lt;li&gt;It doesn’t output data.frames&lt;/li&gt;
&lt;li&gt;Its results are hard to format. Compare the look and formatting choices of an R table to a Microsoft Excel PivotTable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is how it works. Say we are interested in exploring the number of persons in each of the observed strata, we would do:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;evaluation_df %&amp;gt;% # your data frame
  janitor::tabyl(net_use, sms) %&amp;gt;% # the two dimensions for the table (D, Z)
  janitor::adorn_totals(c(&amp;quot;row&amp;quot;, &amp;quot;col&amp;quot;)) %&amp;gt;% # add totals for rows and cols
  knitr::kable() %&amp;gt;% # turn into a kable table for nice rendering in HTML
  kableExtra::kable_styling() %&amp;gt;% 
  kableExtra::add_header_above(c(&amp;quot;&amp;quot;, &amp;quot;sms&amp;quot; = 2, &amp;quot;&amp;quot;)) #add header for sms&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
sms
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
net_use
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Total
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
335
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
110
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
445
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
165
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
390
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
555
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Total
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;If you want to learn more about the syntax of &lt;code&gt;tabyl()&lt;/code&gt;, make sure to check the&lt;/em&gt; &lt;a href=&#34;https://cran.r-project.org/web/packages/janitor/vignettes/tabyls.html&#34;&gt;vignette&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#6600cc;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;h5&#34;&gt;Let&#39;s explore the compliance types from this table
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Where are our compliers and non-compliers?&lt;/li&gt;
&lt;li&gt;How many people were encouraged via SMS, but did not use the net?&lt;/li&gt;
&lt;li&gt;How many people were not encouraged via SMS, yet they utilized the net?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#cc0055;&#34;&gt;
Average malaria infections across strata
&lt;/h4&gt;
&lt;p&gt;We can utilize the &lt;code&gt;tabyl()&lt;/code&gt; syntax and our knowledge from the grammar of graphics to table and visualize the distribution of malaria on each stratum:&lt;/p&gt;
&lt;h5 style = &#34;color:#cc0055;&#34;&gt;
Table: Count of malaria infections across strata (Y,Z)
&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;evaluation_df %&amp;gt;% # your data frame
  janitor::tabyl(malaria, sms) %&amp;gt;% # the two dimensions for the table (Y, Z)
  janitor::adorn_totals(c(&amp;quot;row&amp;quot;, &amp;quot;col&amp;quot;)) %&amp;gt;% # add totals for rows and cols
  knitr::kable() %&amp;gt;% # turn into a kable table for nice rendering in HTML
  kableExtra::kable_styling() %&amp;gt;% 
  kableExtra::add_header_above(c(&amp;quot;&amp;quot;, &amp;quot;sms&amp;quot; = 2, &amp;quot;&amp;quot;)) #add header for sms&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
sms
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
malaria
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Total
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
248
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
410
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
658
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
252
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
342
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Total
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5 style = &#34;color:#cc0055;&#34;&gt;
Plot: Distribution of malaria infections across strata
&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(evaluation_df, aes(x = factor(sms), 
                          y = factor(net_use), 
                          color = factor(malaria))) +
  geom_jitter() +
  theme_minimal() +
  scale_x_discrete(labels = c(&amp;quot;SMS = 0&amp;quot;, &amp;quot;SMS = 1&amp;quot;)) +
  scale_y_discrete(limits = c(&amp;quot;1&amp;quot;,&amp;quot;0&amp;quot;), labels = c(&amp;quot;NET = 1&amp;quot;, &amp;quot;NET = 0&amp;quot;)) +
  scale_color_manual(values = c(&amp;quot;#CDCDCD&amp;quot;, &amp;quot;#CC0055&amp;quot;),
                       labels = c(&amp;quot;Not infected&amp;quot;, &amp;quot;Infected&amp;quot;)) +
  labs(x = &amp;quot;Encouragement&amp;quot;,
       y = &amp;quot;Treatment&amp;quot;,
       color = &amp;quot;&amp;quot;) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/111189828-c3c5e300-85b6-11eb-8a6e-cb958c5fa0bf.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#6600cc;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;What insights can we gather from the table and plot?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-our-set-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring our set-up&lt;/h2&gt;
&lt;div id=&#34;lets-check-whether-sms-encouragement-is-a-strong-instrument&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let&#39;s check whether SMS encouragement is a strong instrument&lt;/h4&gt;
&lt;p&gt;In other words, we are looking at the relevance assumption. Does our SMS encouragement create changes in our mosquito net use?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm(net_use ~ sms, data = evaluation_df) %&amp;gt;%
  stargazer::stargazer(type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                               net_use          
## -----------------------------------------------
## sms                          0.450***          
##                               (0.028)          
##                                                
## Constant                     0.330***          
##                               (0.020)          
##                                                
## -----------------------------------------------
## Observations                   1,000           
## R2                             0.205           
## Adjusted R2                    0.204           
## Residual Std. Error      0.444 (df = 998)      
## F Statistic          257.315*** (df = 1; 998)  
## ===============================================
## Note:               *p&amp;lt;0.1; **p&amp;lt;0.05; ***p&amp;lt;0.01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Economists have established as a &amp;quot;rule-of-thumb&amp;quot; for the case of a single endogenous regressor to be considered a strong instrument should have a &lt;strong&gt;F-statistic&lt;/strong&gt; &lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; greater than 10. From this regression, we can see that SMS encouragement is a strong instrument.&lt;/p&gt;
&lt;p&gt;Additionally, the substantive read in this case is that only 33% of those who did not receive the SMS utilized the mosquito nets, where as 78% of those who got the SMS encouragement did. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-gather-a-naïve-estimate-of-mosquito-net-use-and-malaria-infection.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let&#39;s gather a naïve estimate of mosquito net use and malaria infection.&lt;/h4&gt;
&lt;p&gt;Why do you think we call this a naïve estimate?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;naive_model &amp;lt;- lm(malaria ~ net_use, data = evaluation_df)
stargazer::stargazer(naive_model, type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                               malaria          
## -----------------------------------------------
## net_use                      -0.615***         
##                               (0.023)          
##                                                
## Constant                     0.683***          
##                               (0.017)          
##                                                
## -----------------------------------------------
## Observations                   1,000           
## R2                             0.415           
## Adjusted R2                    0.414           
## Residual Std. Error      0.363 (df = 998)      
## F Statistic          707.002*** (df = 1; 998)  
## ===============================================
## Note:               *p&amp;lt;0.1; **p&amp;lt;0.05; ***p&amp;lt;0.01&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#6600cc;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;What would our expectations be under the naïve model?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-gather-our-intent-to-treat-effect-itt&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let&#39;s gather our intent-to-treat effect (ITT)&lt;/h4&gt;
&lt;p&gt;This is the effect that our SMS encouragement had on malaria infections. &lt;span class=&#34;math display&#34;&gt;\[ITT = E(Malaria_i|SMS=1) - E(Malaria_i|SMS=0)\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;itt_model &amp;lt;- lm(malaria ~ sms, data = evaluation_df)
stargazer::stargazer(itt_model, type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                               malaria          
## -----------------------------------------------
## sms                          -0.324***         
##                               (0.028)          
##                                                
## Constant                     0.504***          
##                               (0.020)          
##                                                
## -----------------------------------------------
## Observations                   1,000           
## R2                             0.117           
## Adjusted R2                    0.116           
## Residual Std. Error      0.446 (df = 998)      
## F Statistic          131.753*** (df = 1; 998)  
## ===============================================
## Note:               *p&amp;lt;0.1; **p&amp;lt;0.05; ***p&amp;lt;0.01&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#6600cc;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;What does this tell us?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-gather-out-local-average-treatment-effect-late&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let&#39;s gather out local average treatment effect (LATE)&lt;/h2&gt;
&lt;p&gt;We have several options for this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Wald Estimator&lt;/strong&gt; We can calculate this by hand. Let&#39;s try that now using the values from the table we created earlier. We can also calculate the average malaria rates among those who did and did not receive an SMS (no SMS = 0.504, yes SMS = 0.18).&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 style = &#34;color:#cc0055;&#34;&gt;
Table: Observations across strata (D,Z)
&lt;/h4&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
sms
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
net_use
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Total
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
335
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
110
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
445
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
165
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
390
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
555
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Total
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5 style = &#34;color:#cc0055;&#34;&gt;
Table: Count of malaria infections across strata (Y,Z)
&lt;/h4&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
sms
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
malaria
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Total
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
248
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
410
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
658
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
252
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
342
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Total
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;h4&gt;
Local Average Treatment Effect (LATE) manually
&lt;/h4&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[LATE = \frac{cov(Y_i,Z_i)}{cov(D_i,Z_i)}\]&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Let&#39;s take a look at our numerator&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(cov(Y_i,Z_i)\)&lt;/span&gt;, also &lt;span class=&#34;math inline&#34;&gt;\(ITT\)&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(E(Y|Z = 1) = \frac{90}{(410+90)} = 0.18\)&lt;/span&gt; &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(E(Y|Z = 0) = \frac{252}{(252+248)} = 0.504\)&lt;/span&gt; &lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Let&#39;s take a look at our denominator&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(cov(D_i,Z_i)\)&lt;/span&gt; &lt;br&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(E(D∣Z = 1) = \frac{390}{(390 + 110)} = 0.78\)&lt;/span&gt; &lt;br&gt; &lt;span class=&#34;math inline&#34;&gt;\(E(D∣Z = 0) = \frac{165}{(165 + 335)} = 0.33\)&lt;/span&gt; &lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;We can calculate our LATE&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[LATE =  \frac{(0.18 - 0.504)}{(0.78 - 0.33)} = -0.72\]&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Two-stage Least Squares (2SLS)&lt;/strong&gt;. We will learn how to do this with &lt;code&gt;ivreg()&lt;/code&gt;, which is part of the &lt;code&gt;AER&lt;/code&gt; package. It fits instrumental-variable regression through two-stage least squares. The syntax is the following:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ivreg(outcome ~ treatment | instrument, data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our case:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;late_model &amp;lt;- AER::ivreg(malaria ~ net_use | sms, data = evaluation_df)
summary(late_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## AER::ivreg(formula = malaria ~ net_use | sms, data = evaluation_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.7416 -0.0216 -0.0216  0.2584  0.9784 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  0.74160    0.03089   24.00   &amp;lt;2e-16 ***
## net_use     -0.72000    0.05159  -13.96   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.3671 on 998 degrees of freedom
## Multiple R-Squared: 0.4025,  Adjusted R-squared: 0.4019 
## Wald test: 194.8 on 1 and 998 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#6600cc;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;What is the substantive reading of these results?&lt;/li&gt;
&lt;li&gt;What would you tell the funding partner in your evaluation report?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;mechanics-behind-two-stage-least-squares-2sls&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mechanics behind two-stage least squares (2SLS)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/seramirezruiz/stats-ii-lab/master/Session%205/data/instrumental-variables.gif&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What ivreg() is doing in the background is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;net_use_hat &amp;lt;- lm(net_use ~ sms, evaluation_df)$fitted.values # get fitted values from first stage (the part of x that is exogenously driven by z)
summary(lm(evaluation_df$malaria ~ net_use_hat)) # run second stage with instrumented x (careful, the standard errors are wrong; better use ivreg() from AER instead)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = evaluation_df$malaria ~ net_use_hat)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.504 -0.180 -0.180  0.496  0.820 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  0.74160    0.03757   19.74   &amp;lt;2e-16 ***
## net_use_hat -0.72000    0.06273  -11.48   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.4463 on 998 degrees of freedom
## Multiple R-squared:  0.1166, Adjusted R-squared:  0.1157 
## F-statistic: 131.8 on 1 and 998 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;thinking-about-the-validity-of-instruments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Thinking about the validity of instruments&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/seramirezruiz/stats-ii-lab/master/Session%205/data/validity_ivs.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We can also adapt the &lt;code&gt;ivreg()&lt;/code&gt; syntax to accomodate valid conditional instruments:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AER::ivreg(Y ~ D + W | Z + W, data = your_df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;An F statistic is a value you get when you run an ANOVA test or a regression analysis to find out if the means between two populations are significantly different. It’s similar to a t-statistic from a t-test; A-T test will tell you if a single variable is statistically significant and an F test will tell you if a group of variables are jointly significant.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Matching in R</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-5/05-online-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-5/05-online-tutorial/</guid>
      <description>
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;welcome&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Welcome&lt;/h2&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction!&lt;/h3&gt;
&lt;p&gt;Welcome to our fifth tutorial for the Statistics II: Statistical Modeling &amp;amp; Causal Inference (with R) course.&lt;/p&gt;
&lt;p&gt;During this week’s lecture you reviewed randomization in experimental setups. You also learned how &lt;strong&gt;matching&lt;/strong&gt; can be leveraged to gather causal estimates.&lt;/p&gt;
&lt;p&gt;In this lab session we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take a step back to review how to compare the means of two groups in &lt;strong&gt;R&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Learn how to perform matching with the &lt;code&gt;MatchIt&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Illustrate the mechanics of propensity score matching with &lt;code&gt;gml()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Packages&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# These are the libraries we will use today. Make sure to install them in your console in case you have not done so previously.

library(tidyverse) # To use dplyr functions and the pipe operator when needed
library(ggplot2) # To create plots (this package is also loaded by library(tidyverse))
library(purrr) # To repeat code across our list in the balance table purrr::map() (this package is also loaded by library(tidyverse))
library(broom) # To format regression output
library(stargazer) # To format model output
library(knitr) # To create HTML tables with kable()
library(kableExtra) # To format the HTML tables
library(MatchIt) # To match&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;our-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Our data&lt;/h2&gt;
&lt;p&gt;Today we will work with data from the Early Childhood Longitudinal Study (ECLS).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ecls_df &amp;lt;- 
  readr::read_csv(&amp;quot;https://raw.githubusercontent.com/seramirezruiz/stats-ii-lab/master/Session%204/data/ecls.csv&amp;quot;) %&amp;gt;% 
  dplyr::select(-childid, -race, -w3daded,
                -w3momed, -w3inccat) #drop these columns (-)

names(ecls_df) #checking the names of the variables in the data frame&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;catholic&amp;quot;      &amp;quot;race_white&amp;quot;    &amp;quot;race_black&amp;quot;    &amp;quot;race_hispanic&amp;quot;
##  [5] &amp;quot;race_asian&amp;quot;    &amp;quot;p5numpla&amp;quot;      &amp;quot;p5hmage&amp;quot;       &amp;quot;p5hdage&amp;quot;      
##  [9] &amp;quot;w3daded_hsb&amp;quot;   &amp;quot;w3momed_hsb&amp;quot;   &amp;quot;w3momscr&amp;quot;      &amp;quot;w3dadscr&amp;quot;     
## [13] &amp;quot;w3income&amp;quot;      &amp;quot;w3povrty&amp;quot;      &amp;quot;p5fstamp&amp;quot;      &amp;quot;c5r2mtsc&amp;quot;     
## [17] &amp;quot;c5r2mtsc_std&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(Example inspired by Simon Ejdemyr: &lt;a href=&#34;https://sejdemyr.github.io/r-tutorials/statistics/tutorial8.html&#34; class=&#34;uri&#34;&gt;https://sejdemyr.github.io/r-tutorials/statistics/tutorial8.html&lt;/a&gt;)&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;reference-links&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Reference links:&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;MatchIt&lt;/code&gt;: &lt;a href=&#34;https://cran.r-project.org/web/packages/MatchIt/vignettes/matchit.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/MatchIt/vignettes/matchit.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cobalt&lt;/code&gt;: (optional library for matching plots and extra features): &lt;a href=&#34;https://cran.r-project.org/web/packages/cobalt/vignettes/cobalt_A0_basic_use.html&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/cobalt/vignettes/cobalt_A0_basic_use.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kableExtra&lt;/code&gt;: (for formatting tables): &lt;a href=&#34;https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Stargazer&lt;/code&gt;: (for formatting model output): &lt;a href=&#34;https://www.jakeruss.com/cheatsheets/stargazer/&#34; class=&#34;uri&#34;&gt;https://www.jakeruss.com/cheatsheets/stargazer/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Video overview of matching concepts: &lt;a href=&#34;https://fr.coursera.org/lecture/crash-course-in-causality/overview-of-matching-JQfPC&#34; class=&#34;uri&#34;&gt;https://fr.coursera.org/lecture/crash-course-in-causality/overview-of-matching-JQfPC&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;comparing-differences-in-means-and-balance-tables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparing Differences in Means and Balance Tables&lt;/h2&gt;
&lt;p&gt;As you may have seen in this week’s application paper, balance tables feature prominently in work that utilizes matching.&lt;/p&gt;
&lt;p&gt;In binary treatment setups, &lt;strong&gt;balance tables&lt;/strong&gt; present an overview of the difference in means for the groups accross covariates.&lt;/p&gt;
&lt;p&gt;Let’s take the dataset as an example to review how to compare differences in means and build balance tables in &lt;strong&gt;R&lt;/strong&gt;. There are multiple ways to explore these kinds of questions. In this lab we will leverage t-tests to check the statistical significance of the difference in means.&lt;/p&gt;
&lt;p&gt;In other words, we want to know whether the observed differences in average value of a variable between the two groups or samples can be due to random chance (our null hypothesis).&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;t-tests-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;T-tests in R&lt;/h3&gt;
&lt;p&gt;In this case, let’s imagine we want to check the statistical significance of the differences in the composition of the catholic and public school samples in the &lt;code&gt;w3povrty&lt;/code&gt; (under the poverty line) variable.&lt;/p&gt;
&lt;p&gt;The general syntax for a t-test is simply as follows. The vectors refer to the variables whose mean you want to compare.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(y ~ x, data = your_data)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#CC0055;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(w3povrty ~ catholic, data = ecls_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  w3povrty by catholic
## t = 26.495, df = 4034.6, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0
## 95 percent confidence interval:
##  0.1678107 0.1946307
## sample estimates:
## mean in group 0 mean in group 1 
##      0.21918633      0.03796562&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;What does the &lt;em&gt;group 0&lt;/em&gt; mean tell us?&lt;/li&gt;
&lt;li&gt;What does the &lt;em&gt;group 1&lt;/em&gt; mean tell us?&lt;/li&gt;
&lt;li&gt;Is the difference between catholic school and public school students statistically significant?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;balance-tables-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Balance tables in R&lt;/h3&gt;
&lt;p&gt;Now let’s take a look at how can we create a simple and good looking balance table. The idea here is to compare the mean values of different variables across populations or groups. In our case, let’s see whether the catholic and public school groups differ across the covariates in the dataset:&lt;/p&gt;
&lt;p&gt;Here is one way to create the table &lt;span style=&#34;color:#CC0055;&#34;&gt;&lt;strong&gt;(you can adapt this code for the assignment)&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a list with the covariates
list_cov &amp;lt;- c(&amp;quot;race_white&amp;quot;, &amp;quot;race_black&amp;quot;, &amp;quot;race_hispanic&amp;quot;, &amp;quot;race_asian&amp;quot;, &amp;quot;p5numpla&amp;quot;,
              &amp;quot;p5hmage&amp;quot;, &amp;quot;p5hdage&amp;quot;, &amp;quot;w3daded_hsb&amp;quot;, &amp;quot;w3momed_hsb&amp;quot;, &amp;quot;w3momscr&amp;quot;, &amp;quot;w3dadscr&amp;quot;,
              &amp;quot;w3income&amp;quot;, &amp;quot;w3povrty&amp;quot;, &amp;quot;p5fstamp&amp;quot;, &amp;quot;c5r2mtsc&amp;quot;, &amp;quot;c5r2mtsc_std&amp;quot;) 


ecls_df %&amp;gt;% # our data frame
  dplyr::summarize_at(list_cov, funs(list(broom::tidy(t.test(. ~ catholic))))) %&amp;gt;% # sequentially run t-tests across all the covariates in the list_cov (note that you have to change the &amp;quot;treatment&amp;quot;)
  purrr::map(1) %&amp;gt;% # maps into a list
  dplyr::bind_rows(.id=&amp;#39;variables&amp;#39;) %&amp;gt;% # binds list into a single data frame and names the id column &amp;quot;variables&amp;quot; 
  dplyr::select(variables, estimate1, estimate2, p.value) %&amp;gt;% # select only the names, group means, and p-values
  dplyr::mutate_if(is.numeric, round, 3) %&amp;gt;% # round numeric variables to three places
  knitr::kable(col.names = c(&amp;quot;Variable&amp;quot;, &amp;quot;(Catholic = 0)&amp;quot;, &amp;quot;(Catholic = 1)&amp;quot;, &amp;quot;P value&amp;quot;)) %&amp;gt;% # create kable table and remane headings
  kableExtra::kable_styling() # style kable table for our knitted document&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Variable
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
(Catholic = 0)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
(Catholic = 1)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
P value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
race_white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.556
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.725
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
race_black
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.136
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.054
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
race_hispanic
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.181
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.131
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
race_asian
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.066
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.052
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.025
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p5numpla
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.133
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.093
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p5hmage
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37.561
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39.575
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p5hdage
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
40.392
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
41.988
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
w3daded_hsb
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.488
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.259
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
w3momed_hsb
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.464
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.227
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
w3momscr
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
43.114
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
47.492
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
w3dadscr
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
42.713
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46.356
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
w3income
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54889.159
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
82074.301
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
w3povrty
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.219
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.038
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p5fstamp
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.129
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
c5r2mtsc
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50.209
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52.389
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
c5r2mtsc_std
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.031
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.194
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#CC0055;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Are the differences in means significant at conventional levels?&lt;/li&gt;
&lt;li&gt;What differences strike you from the composition of the two samples?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-effect-of-catholic-school-on-student-achievement&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Effect of Catholic School on Student Achievement&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In this tutorial we’ll analyze the effect of going to Catholic school, as opposed to public school, on student achievement. Because students who attend Catholic school on average are different from students who attend public school, we will use matching to get more credible causal estimates of Catholic schooling.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;div id=&#34;exploration-of-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exploration of the data&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ecls_df %&amp;gt;%
  dplyr::group_by(catholic) %&amp;gt;%
  dplyr::summarize(n_students = n(),
            avg_math = mean(c5r2mtsc_std),
            std_error = sd(c5r2mtsc_std) / sqrt(n_students)) %&amp;gt;% 
  round(3) %&amp;gt;% # round the results
  knitr::kable() %&amp;gt;% # create kable table
  kableExtra::kable_styling() # view kable table&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
catholic
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
n_students
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
avg_math
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
std_error
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9568
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.031
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.010
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1510
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.194
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.022
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can see that we have many more students that did not attend Catholic school than those who did. Also, the Catholic school students have a higher average math score.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;naive-average-treatment-effect-nate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Naive Average Treatment Effect (NATE)&lt;/h3&gt;
&lt;p&gt;We can naively compare the students on their standardized math scores (c5r2mtsc_std). As you remember, the Naive Average Treatment Effect (NATE) is the difference in the means of the observed outcomes of the two groups:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[NATE = E(y^1 | D = 1) -  E(y^0 | D = 0)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In this case, the NATE would be difference between the average math scores.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;nate-manually&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;NATE manually&lt;/h4&gt;
&lt;p&gt;Do you remember what we did in the last section?&lt;/p&gt;
&lt;p&gt;We could substract the &lt;code&gt;avg_math&lt;/code&gt; for the &lt;em&gt;catholic = 1&lt;/em&gt; and the &lt;code&gt;avg_math&lt;/code&gt; for the &lt;em&gt;catholic = 0&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[NATE = 0.194 - (-0.031)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[NATE = 0.194 + 0.031 = 0.225\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;nate-with-t.test&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;NATE with &lt;code&gt;t.test()&lt;/code&gt;&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(c5r2mtsc_std ~ catholic, data = ecls_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  c5r2mtsc_std by catholic
## t = -9.1069, df = 2214.5, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0
## 95 percent confidence interval:
##  -0.2727988 -0.1761292
## sample estimates:
## mean in group 0 mean in group 1 
##     -0.03059583      0.19386817&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;nate-with-lm&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;NATE with &lt;code&gt;lm()&lt;/code&gt;&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm(c5r2mtsc_std ~ catholic, data = ecls_df) %&amp;gt;% 
  stargazer::stargazer(.,type = &amp;quot;html&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table style=&#34;text-align:center&#34;&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;Dependent variable:&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td colspan=&#34;1&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
c5r2mtsc_std
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
catholic
&lt;/td&gt;
&lt;td&gt;
0.224&lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.028)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Constant
&lt;/td&gt;
&lt;td&gt;
-0.031&lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.010)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Observations
&lt;/td&gt;
&lt;td&gt;
11,078
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
R&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
&lt;td&gt;
0.006
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Adjusted R&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
&lt;td&gt;
0.006
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Residual Std. Error
&lt;/td&gt;
&lt;td&gt;
0.997 (df = 11076)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
F Statistic
&lt;/td&gt;
&lt;td&gt;
66.096&lt;sup&gt;***&lt;/sup&gt; (df = 1; 11076)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;em&gt;Note:&lt;/em&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;
&lt;sup&gt;&lt;em&gt;&lt;/sup&gt;p&amp;lt;0.1; &lt;sup&gt;&lt;strong&gt;&lt;/sup&gt;p&amp;lt;0.05; &lt;sup&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/sup&gt;p&amp;lt;0.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#CC0055;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;What parallels do you find between substracting the manually extracted means, the t-test, and the linear regression?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;matching-with-matchit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matching with &lt;code&gt;MatchIt&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;MatchIt&lt;/code&gt; is designed for causal inference with a dichotomous treatment variable and a set of pretreatment control variables. Any number or type of dependent variables can be used.&lt;/p&gt;
&lt;p&gt;We have three steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Perform the match with &lt;code&gt;MatchIt::matchit()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create a new data frame with the matched data with &lt;code&gt;MatchIt::match.data()&lt;/code&gt; or &lt;code&gt;MatchIt::get_matches()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The basic syntax is as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;match_process &amp;lt;- MatchIt::matchit(treatment ~ x1 + x2, data = mydata) # NOTE. We include treatment ~ covariates
matched_df &amp;lt;- MatchIt::get_matches(match_process) #when matching with replacement
matched_df &amp;lt;- MatchIt::match.data(match_process) #for other cases
matched_model &amp;lt;- lm(outcome ~ trearment, data = matched_df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where treat is the dichotomous treatment variable, and x1 and x2 are pre-treatment co-variates, all of which are contained in the data frame &lt;em&gt;mydata&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;As you can see, the outcome variable is not included in the matching procedure.&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;code&gt;MatchIt&lt;/code&gt; is capable of using several matching &lt;em&gt;methods&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Exact (&lt;em&gt;method = “exact”&lt;/em&gt;): The simplest version of matching is exact. This technique matches each treated unit to all possible control units with exactly the same values on all the covariates, forming subclasses such that within each subclass all units (treatment and control) have the same covariate values.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Subclassification (&lt;em&gt;method = “subclass”&lt;/em&gt;): When there are many covariates (or some covariates can take a large number of values),
finding sufficient exact matches will often be impossible. The goal of subclassification is to form subclasses, such that in each of them the distribution (rather than the exact values) of covariates for the treated and control groups are as similar as possible.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Nearest Neighbor (&lt;em&gt;method = “nearest”&lt;/em&gt;): Nearest neighbor matching selects the best control matches for each individual
in the treatment group. Matching is done using a distance measure (propensity score) specified by the distance option (default = logit).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;As well as optimal matching, full matching, genetic matching, and coarsened exact matching, all of which are detailed in the documentation.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A few additional arguments are important to know about:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;distance&lt;/em&gt;: this refers to propensity scores. There are many options for how to calculate these within MatchIt.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;discard&lt;/em&gt;: specifies whether to discard units that fall outside some measure of support of the distance measure (default is “none”, discard no units). For example, if some treated units have extremely high propensity scores that are higher than any control units, we could drop those.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;replace&lt;/em&gt;: a logical value indicating whether each control unit can be matched to more than one treated unit (default is &lt;em&gt;replace = FALSE&lt;/em&gt;, each control unit is used at most once).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;ratio&lt;/em&gt;: the number of control units to match to each treated unit (default is &lt;em&gt;ratio = 1&lt;/em&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There are also some optional arguments for most of the matching methods, which you can read about in the documentation if you are interested.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;exact-matching&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exact Matching&lt;/h3&gt;
&lt;p&gt;We can use a combination of the results from our balance table and theory to identify which variables to use for matching. Let’s perform an exact match with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;race_white: Is the student white (1) or not (0)?&lt;/li&gt;
&lt;li&gt;p5hmage: Mother’s age&lt;/li&gt;
&lt;li&gt;w3income: Family income&lt;/li&gt;
&lt;li&gt;p5numpla: Number of places the student has lived for at least 4 months&lt;/li&gt;
&lt;li&gt;w3momed_hsb: Is the mother’s education level high-school or below (1) or some college or more (0)?&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# first we must omit missing values (MatchIt does not allow missings)
match_data &amp;lt;- ecls_df %&amp;gt;% 
  dplyr::select(catholic, c5r2mtsc_std, race_white, p5hmage, 
                w3income, p5numpla, w3momed_hsb) %&amp;gt;% 
  na.omit() 


# perform exact match
exact_match &amp;lt;- MatchIt::matchit(catholic ~ race_white + p5hmage + w3income +
                                p5numpla + w3momed_hsb, 
                                method = &amp;quot;exact&amp;quot;, 
                                data = match_data)

# Try seeing the output in the console with summary(exact_match)

# grab the matched data into a new data frame
data_exact_match &amp;lt;- MatchIt::match.data(exact_match)

# estimate effect again with new data frame
exact_match_model &amp;lt;- lm(c5r2mtsc_std ~ catholic, data = data_exact_match)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stargazer::stargazer(exact_match_model, type = &amp;quot;html&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table style=&#34;text-align:center&#34;&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;Dependent variable:&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td colspan=&#34;1&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
c5r2mtsc_std
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
catholic
&lt;/td&gt;
&lt;td&gt;
-0.101&lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.030)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Constant
&lt;/td&gt;
&lt;td&gt;
0.319&lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.015)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Observations
&lt;/td&gt;
&lt;td&gt;
5,405
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
R&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
&lt;td&gt;
0.002
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Adjusted R&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
&lt;td&gt;
0.002
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Residual Std. Error
&lt;/td&gt;
&lt;td&gt;
0.934 (df = 5403)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
F Statistic
&lt;/td&gt;
&lt;td&gt;
11.340&lt;sup&gt;***&lt;/sup&gt; (df = 1; 5403)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;em&gt;Note:&lt;/em&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;
&lt;sup&gt;&lt;em&gt;&lt;/sup&gt;p&amp;lt;0.1; &lt;sup&gt;&lt;strong&gt;&lt;/sup&gt;p&amp;lt;0.05; &lt;sup&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/sup&gt;p&amp;lt;0.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;Now we can see that the mean in the group that did not attend Catholic school is actually about 0.10 higher than the mean for those who did. The results are statistically significant given that the confidence interval does not contain zero, and we have a fairly small p-value.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;propensity-scores&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Propensity Scores&lt;/h3&gt;
&lt;p&gt;If we want to perform non-exact matching, we can use &lt;strong&gt;propensity scores&lt;/strong&gt;. We can generate these manually using a logit model on the unmatched data set.&lt;/p&gt;
&lt;p&gt;When we extract &lt;strong&gt;propensity scores&lt;/strong&gt;, we model the propensity of each unit of falling under the treatment group based on their values on a set of covariates. This is how we would do this manually:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a new column with income by the thousands for more interpretable output
ecls_df &amp;lt;- ecls_df %&amp;gt;% 
  dplyr::mutate(w3income_1k = w3income / 1000) 

# estimate logit model
m_ps &amp;lt;- glm(catholic ~ race_white + w3income_1k + 
            p5hmage + p5numpla + w3momed_hsb,
            family = binomial(link = &amp;quot;logit&amp;quot;), # you can also use a probit link here
            data = ecls_df)

# extract predicted probabilities
# type = &amp;quot;response&amp;quot; option tells R to output probabilities of the form P(Y = 1|X)
prs_df &amp;lt;- dplyr::tibble(pr_score = predict(m_ps, type = &amp;quot;response&amp;quot;),
                     catholic = m_ps$model$catholic) # the actual values&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s plot the propensity scores by treatment group to explore common support:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Histogram
ggplot(prs_df, aes(x = pr_score, fill = factor(catholic))) +
  geom_histogram(alpha = 0.5) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(title = &amp;quot;Propensity Score Distribution: Treatment and Control Groups&amp;quot;,
       x = &amp;quot;Propensity Score&amp;quot;,
       y = &amp;quot;Count&amp;quot;,
       fill = &amp;quot;Catholic School Attendance&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/110490691-de004c80-80f0-11eb-9c52-6b036f0c4efb.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Density plot
ggplot(prs_df, aes(x = pr_score, fill = factor(catholic))) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(title = &amp;quot;Propensity Score Distribution: Treatment and Control Groups&amp;quot;,
       x = &amp;quot;Propensity Score&amp;quot;,
       y = &amp;quot;Density&amp;quot;,
       fill = &amp;quot;Catholic School Attendance&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/110490704-df317980-80f0-11eb-85d6-e5a1e7d4dc55.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Jittered point plot
ggplot(prs_df, aes(x = pr_score, y = factor(catholic), color = factor(catholic))) +
  geom_jitter() +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(title = &amp;quot;Propensity Score Distribution: Treatment and Control Groups&amp;quot;,
       x = &amp;quot;Propensity Score&amp;quot;,
       y = &amp;quot;Group&amp;quot;,
       color = &amp;quot;Catholic School Attendance&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/110490710-e062a680-80f0-11eb-94bb-c080d19296ea.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#CC0055;&#34;&gt;
Exercise
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;What do these plots tell us?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;non-exact-matching&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Non-Exact Matching&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;MatchIt&lt;/code&gt; can generate propensity scores itself, so we don’t need to manually go through the process above. Let’s try putting together a non-exact matching formula yourself! Try:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nearest neighbor matching&lt;/li&gt;
&lt;li&gt;with replacement&lt;/li&gt;
&lt;li&gt;with a one-to-one ratio&lt;/li&gt;
&lt;li&gt;on the &lt;em&gt;match_data&lt;/em&gt; dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_match &amp;lt;- MatchIt::matchit(catholic ~ race_white + w3income + p5hmage +
                              p5numpla + w3momed_hsb,
                              method = &amp;quot;nearest&amp;quot;, 
                              ratio = 1, 
                              replace = TRUE,
                              data = match_data)

summary(one_match)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## MatchIt::matchit(formula = catholic ~ race_white + w3income + 
##     p5hmage + p5numpla + w3momed_hsb, data = match_data, method = &amp;quot;nearest&amp;quot;, 
##     replace = TRUE, ratio = 1)
## 
## Summary of Balance for All Data:
##             Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean
## distance           0.1927        0.1379          0.6486     1.0007    0.2086
## race_white         0.7411        0.5914          0.3418          .    0.1497
## w3income       82568.9357    55485.0210          0.5777     1.1373    0.1565
## p5hmage           39.5932       37.5658          0.3874     0.6383    0.0408
## p5numpla           1.0917        1.1298         -0.1242     0.6132    0.0076
## w3momed_hsb        0.2234        0.4609         -0.5703          .    0.2375
##             eCDF Max
## distance      0.3109
## race_white    0.1497
## w3income      0.3062
## p5hmage       0.1893
## p5numpla      0.0277
## w3momed_hsb   0.2375
## 
## 
## Summary of Balance for Matched Data:
##             Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean
## distance           0.1927        0.1927          0.0000     0.9954    0.0000
## race_white         0.7411        0.7493         -0.0186          .    0.0081
## w3income       82568.9357    81775.6653          0.0169     1.0052    0.0036
## p5hmage           39.5932       39.6169         -0.0045     1.0179    0.0015
## p5numpla           1.0917        1.0777          0.0459     1.1580    0.0031
## w3momed_hsb        0.2234        0.2226          0.0018          .    0.0007
##             eCDF Max Std. Pair Dist.
## distance      0.0030          0.0001
## race_white    0.0081          0.0625
## w3income      0.0081          0.0396
## p5hmage       0.0074          0.1131
## p5numpla      0.0126          0.0846
## w3momed_hsb   0.0007          0.0586
## 
## Percent Balance Improvement:
##             Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max
## distance              100.0     -552.2     100.0     99.0
## race_white             94.6          .      94.6     94.6
## w3income               97.1       95.9      97.7     97.3
## p5hmage                98.8       96.0      96.2     96.1
## p5numpla               63.1       70.0      59.2     54.6
## w3momed_hsb            99.7          .      99.7     99.7
## 
## Sample Sizes:
##               Control Treated
## All           7915.      1352
## Matched (ESS)  187.29    1352
## Matched        510.      1352
## Unmatched     7405.         0
## Discarded        0.         0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can interpret the resulting output as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Summary of balance for all data: Comparison of the means for all the data without matching&lt;/li&gt;
&lt;li&gt;Summary of balance for matched data: Comparison of means for matched data. Looking for them to become similar.&lt;/li&gt;
&lt;li&gt;Percent balance improvement: Higher is better, close to 100 is ideal.&lt;/li&gt;
&lt;li&gt;Sample sizes: How many units were matched in the control/treatment groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, let’s plot the propensity scores for the treated and untreated units.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# simple plot - check out the cobalt package for nicer options, or use ggplot2 to create your own!
plot(one_match, type = &amp;quot;hist&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/110490714-e193d380-80f0-11eb-88ca-b5f8fee948af.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s extract the data from &lt;em&gt;one_match&lt;/em&gt; and creating a balance table like the one we did before, just this time using the new data. Scroll down for the answer when you’re ready.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# grab data set
data_prop_match &amp;lt;- MatchIt::get_matches(one_match)

# create list of covariates for the table
list_cov &amp;lt;- c(&amp;quot;race_white&amp;quot;, &amp;quot;p5hmage&amp;quot;, &amp;quot;w3income&amp;quot;, &amp;quot;p5numpla&amp;quot;, &amp;quot;w3momed_hsb&amp;quot;)

data_prop_match %&amp;gt;% # our data frame
  dplyr::summarize_at(list_cov, funs(list(broom::tidy(t.test(. ~ catholic))))) %&amp;gt;% # sequentially run t-tests across all the covariates in the list_cov (note that you have to change the &amp;quot;treatment&amp;quot;)
  purrr::map(1) %&amp;gt;% # maps into a list
  dplyr::bind_rows(.id=&amp;#39;variables&amp;#39;) %&amp;gt;% # binds list into a single data frame and names the id column &amp;quot;variables&amp;quot; 
  dplyr::select(variables, estimate1, estimate2, p.value) %&amp;gt;% # select only the names, group means, and p-values
  dplyr::mutate_if(is.numeric, round, 3) %&amp;gt;% # round numeric variables to three places
  knitr::kable(col.names = c(&amp;quot;Variable&amp;quot;, &amp;quot;Control (Catholic = 0)&amp;quot;, &amp;quot;Treat (Catholic = 1)&amp;quot;, &amp;quot;P value&amp;quot;)) %&amp;gt;% # create kable table and rename headings
  kableExtra::kable_styling() # style kable table for our knitted document&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Variable
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Control (Catholic = 0)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Treat (Catholic = 1)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
P value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
race_white
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.749
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.741
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.628
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p5hmage
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39.617
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39.593
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.906
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
w3income
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81775.665
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
82568.936
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.659
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
p5numpla
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.078
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.092
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.216
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
w3momed_hsb
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.223
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.223
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.963
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Those means look very close. Hooray.&lt;/p&gt;
&lt;p&gt;Finally, let’s estimate on the matched data set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop_match_model &amp;lt;- lm(c5r2mtsc_std ~ catholic, data = data_prop_match)
stargazer::stargazer(prop_match_model, type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                            c5r2mtsc_std        
## -----------------------------------------------
## catholic                      -0.038           
##                               (0.037)          
##                                                
## Constant                     0.248***          
##                               (0.026)          
##                                                
## -----------------------------------------------
## Observations                   2,704           
## R2                            0.0004           
## Adjusted R2                   0.00003          
## Residual Std. Error      0.955 (df = 2702)     
## F Statistic            1.068 (df = 1; 2702)    
## ===============================================
## Note:               *p&amp;lt;0.1; **p&amp;lt;0.05; ***p&amp;lt;0.01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with the exact matching, we can see that those that did not attend Catholic school performed better on the test than those who did. Still, we see that our results in this instance are not statistically significant.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Moderation and Heterogeneous Effects</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-10/10-online-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-10/10-online-tutorial/</guid>
      <description>
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;welcome&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Welcome&lt;/h2&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction!&lt;/h3&gt;
&lt;p&gt;Welcome to our tenth tutorial for the Statistics II: Statistical Modeling &amp;amp; Causal Inference (with R) course.&lt;/p&gt;
&lt;p&gt;During this week’s lecture you were introduced to Moderation and Heterogeneous Effects.&lt;/p&gt;
&lt;p&gt;In this lab session we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learn how to perform interaction models with &lt;code&gt;lm()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Learn how to extract marginal/partial effects with &lt;code&gt;margins::margins()&lt;/code&gt; and predictive margins with &lt;code&gt;ggeffects::::ggeffect()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Learn how to vectorize multiple ifelse() statements with &lt;code&gt;dplyr::case_when()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;measuring-the-effect-of-an-information-intervention-on-peace-agreement-support&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Measuring the effect of an information intervention on peace agreement support&lt;/h2&gt;
&lt;p&gt;The country of Absurdistan has had an ongoing civil conflict for the past 60 years. The fighting between national government forces and guerrilla members from the National Revolutionary Army (NRA) has lead to more than 200,000 deaths, 8 million internally displaced persons, and countless victims between 1960 to 2020.&lt;/p&gt;
&lt;p&gt;The civil war in Absurdistan has been a low-intensity asymmetric war. The legacies of the conflict have been bore largely by regions in the periphery of the country. Large cities and industrial regions have been spared from most of the fighting.&lt;/p&gt;
&lt;p&gt;The government and the leadership of the NRA reached a peace agreement a couple of months ago; however, the agreement has been received poorly by the general population of Absurdistan. The opposition party the Undemocratic Center (UC) has allegedly ran campaigns misrepresenting the contents of the agreement in partisan media outlets and social media.&lt;/p&gt;
&lt;p&gt;The Special Envoy for Peace has established a taskforce to design a strategy to increase support for the peace agreement. Many in the taskforce suspect that if the public were properly informed about the agreement reached, the levels of support would be higher.&lt;/p&gt;
&lt;p&gt;You are hired as a scientific consultant for the taskforce. You run a survey experiment on a sample of 1000 respondents. You randomly assign respondents to watch an educational 2 minute video about the peace agreement.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/d/d6/Flag_of_Peace_%28Proposal%29.PNG&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Packages&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42) #for consistent results

library(dplyr) # to wrangle our data
library(tidyr) # to wrangle our data - pivot_longer()
library(ggplot2) # to render our graphs
library(readr) # for loading the .csv data
library(janitor) # for data management and tabyl()
library(kableExtra) # to render better formatted tables
library(modelsummary) # to format your model output

library(margins) #for calculating MARGINAL/PARTIAL EFFECT
library(ggeffects) # easily calculating PREDICTIVE MARGINS&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;moderation_df &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/seramirezruiz/hertiestats2/master/data/moderation_df.csv&amp;quot;) # simulated data
names(moderation_df) # to check the names of the variables in our data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;subject_id&amp;quot;          &amp;quot;treatment&amp;quot;           &amp;quot;victim_verbose&amp;quot;     
## [4] &amp;quot;victim&amp;quot;              &amp;quot;female&amp;quot;              &amp;quot;female_verbose&amp;quot;     
## [7] &amp;quot;support_thermometer&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our dataset &lt;em&gt;moderation_df&lt;/em&gt;, contains the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;subject_id&lt;/code&gt;: A unique numeric identification for each respondent&lt;/li&gt;
&lt;li&gt;&lt;code&gt;treatment&lt;/code&gt;: A binary marker for treatment&lt;/li&gt;
&lt;li&gt;&lt;code&gt;victim_verbose&lt;/code&gt;: A verbose binary marker of the respondents’ victimhood status (Not a Victim-Victim)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;victim&lt;/code&gt;: A numeric binary marker of the respondents’ victimhood status (0-1)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;female&lt;/code&gt;: A numeric binary marker of the respondents’ sex (0-1)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;female_verbose&lt;/code&gt;: A verbose binary marker of the respondents’ sex (Male-Female)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;support_thermometer&lt;/code&gt;: A continuous measure of support for the agreement (0-100)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;lets-explore-who-is-in-our-sample&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let’s explore who is in our sample&lt;/h4&gt;
&lt;p&gt;We can use what we have learned about the &lt;em&gt;janitor::tabyl()&lt;/em&gt; function, to check who was in our sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;moderation_df %&amp;gt;% 
  janitor::tabyl(treatment) %&amp;gt;% 
  knitr::kable(col.names = c(&amp;quot;Treatment&amp;quot;, &amp;quot;N&amp;quot;, &amp;quot;Percent, %&amp;quot;)) %&amp;gt;% # create kable table
  kableExtra::kable_styling() # view kable table&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
N
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Percent, %
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;moderation_df %&amp;gt;% 
  janitor::tabyl(treatment, victim_verbose) %&amp;gt;% 
  janitor::adorn_totals(c(&amp;quot;row&amp;quot;, &amp;quot;col&amp;quot;)) %&amp;gt;%
  knitr::kable(col.names = c(&amp;quot;Treatment&amp;quot;, &amp;quot;Not a victim&amp;quot;, &amp;quot;Victim&amp;quot;, &amp;quot;Total&amp;quot;)) %&amp;gt;% # create kable table
  kableExtra::kable_styling() %&amp;gt;% # view kable table
  kableExtra::add_header_above(c(&amp;quot;&amp;quot;, &amp;quot;Victimization status&amp;quot; = 2, &amp;quot;&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;2&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Victimization status
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Not a victim
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Victim
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Total
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Total
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
500
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-explore-visually-the-observed-levels-of-public-support-for-the-agreement&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let’s explore visually the observed levels of public support for the agreement&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(moderation_df, aes(x = support_thermometer)) +
  geom_density(fill = &amp;quot;#af8dc3&amp;quot;, alpha = 0.5) +
  theme_minimal() +
  labs(x = &amp;quot;Support thermometer&amp;quot;,
       y = &amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/115588495-1ccc1980-a2cf-11eb-958a-214b2ba1e233.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What do we see in this graph?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-explore-visually-the-observed-levels-of-public-support-for-the-agreement-conditional-on-the-treatment-status&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let’s explore visually the observed levels of public support for the agreement conditional on the treatment status&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(moderation_df, aes(x = support_thermometer, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  labs(x = &amp;quot;Support thermometer&amp;quot;,
       y = &amp;quot;Density&amp;quot;,
       fill = &amp;quot;Treatment&amp;quot;) +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/115588502-1dfd4680-a2cf-11eb-9ed1-31e0945508d2.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What do we see through these distributions?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-explore-visually-the-observed-levels-of-public-support-for-the-agreement-conditional-on-the-treatment-and-victimhood-status&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let’s explore visually the observed levels of public support for the agreement conditional on the treatment and victimhood status&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(moderation_df, aes(x = support_thermometer, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  facet_grid(treatment~victim_verbose) +
  theme_bw() +
  labs(x = &amp;quot;Support thermometer&amp;quot;,
       y = &amp;quot;Density&amp;quot;,
       fill = &amp;quot;Treatment&amp;quot;) +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/115588507-1f2e7380-a2cf-11eb-8ab6-adc5066fa4f1.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What patterns do we see here?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-and-estimating&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling and estimating&lt;/h2&gt;
&lt;p&gt;During this week’s lecture, we learned that we can explicitly model heterogeneity in treatment effects for subgroups. Thus, we can address the tension between having to do inference at the group level, and the recognition of individual differences.&lt;/p&gt;
&lt;p&gt;The analysis of heterogeneity can be very important for the design of our strategy. There are competing theories about the effects of conflict victimization on political behavior and attitudes. Some of the literature points to victims developing pro-social attitudes, while others suggest that victims become intransigent towards out-groups.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Could factual information about the peace agreement be received differently by victims and non-victims?&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;how-to-estimate-heterogenous-treatment-effects&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;How to estimate heterogenous treatment effects&lt;/h4&gt;
&lt;p&gt;Heterogeneous treatment effects are usually estimated with regression models that include an interaction between the treatment and the moderator. In our case, the formula would look like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{i} = β_0 + β_1D_{i} + β_2Victim_{i} + β_3D_i * Victim_{i}+ ϵ_i\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(β_0\)&lt;/span&gt;: Constant&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(β_1\)&lt;/span&gt;: Effect of &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt; if &lt;span class=&#34;math inline&#34;&gt;\(Victim_i\)&lt;/span&gt; is zero&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(β_2\)&lt;/span&gt;: Effect of &lt;span class=&#34;math inline&#34;&gt;\(Victim_i\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt; if &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; is zero&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(β_3\)&lt;/span&gt;: Difference in treatment effects of &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; depending on &lt;span class=&#34;math inline&#34;&gt;\(Victim_i\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;or in &lt;code&gt;lm()&lt;/code&gt; terms (same result):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm(outcome ~ treatment + moderator + (treatment*moderator))
lm(outcome ~ treatment + moderator + treatment:moderator)
lm(outcome ~ treatment * moderator)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Think of the&lt;/em&gt; &lt;strong&gt;switch logic&lt;/strong&gt; &lt;em&gt;posed by Prof. Munzert&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-model-our-results&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Let’s model our results&lt;/h3&gt;
&lt;p&gt;We will move forward by creating two models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;naive model&lt;/strong&gt;, where we will regress &lt;code&gt;support_thermometer&lt;/code&gt; on &lt;code&gt;treatment&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;An &lt;strong&gt;interaction model&lt;/strong&gt;, where we will add an interaction between &lt;code&gt;treatment&lt;/code&gt; and &lt;code&gt;victim&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;naive-modeling&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Naive modeling&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;naive_model &amp;lt;- lm(support_thermometer ~ treatment, data = moderation_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelsummary::modelsummary(naive_model, 
                           fmt = 2,
                           gof_omit = &amp;quot;AIC|BIC|Log.Lik.&amp;quot;,
                           statistic = &amp;quot;conf.int&amp;quot;,
                           stars = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
35.05***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[33.63, 36.48]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
18.90***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[16.88, 20.91]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.254
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.253
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
339.360
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border:0;&#34; colspan=&#34;100%&#34;&gt;
&lt;sup&gt;&lt;/sup&gt; + p &amp;lt; 0.1, * p &amp;lt; 0.05, ** p &amp;lt; 0.01, *** p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What does this model tell us?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The naive model suggests that the subjects that the support for the peace agreement is about 18.9 percentage points higher on average for the subjects that watched the educational video. We suspect, however, that the video may affect differently victims from non-victims of the conflict.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;here-is-a-visual-illustration-of-the-values-rendered-by-the-naive-regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Here is a visual illustration of the values rendered by the naive regression&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(moderation_df, aes(x = support_thermometer, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  geom_vline(xintercept = 35.055, linetype = &amp;quot;longdash&amp;quot;, color = &amp;quot;#a7a8aa&amp;quot;) + #D=0 (just beta0)
  geom_vline(xintercept = 35.055 + 18.898, linetype = &amp;quot;longdash&amp;quot;, color = &amp;quot;#cc0055&amp;quot;) + #D=1 (beta0+beta1) +
  geom_text(aes(label = &amp;quot;ß0&amp;quot;, x = 35.055 + 3, y = 0.04), color = &amp;quot;#a7a8aa&amp;quot;) + # we add the 3 to repel from the line
  geom_text(aes(label = &amp;quot;ß0 + ß1&amp;quot;, x = 35.055 + 18.898 + 6, y = 0.04 ), color = &amp;quot;#cc0055&amp;quot;) + # we add the 6 to repel from the line
  labs(x = &amp;quot;Support thermometer&amp;quot;,
       y = &amp;quot;Density&amp;quot;,
       fill = &amp;quot;Treatment&amp;quot;) +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/115588509-1f2e7380-a2cf-11eb-810f-355b34f64639.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;interaction-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Interaction model&lt;/h3&gt;
&lt;p&gt;Following any of the different formats renders the same results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interaction_model &amp;lt;- lm(support_thermometer ~ treatment + victim + (treatment*victim), data = moderation_df)
interaction_model_2 &amp;lt;- lm(support_thermometer ~ treatment + victim + treatment:victim, data = moderation_df)
interaction_model_3 &amp;lt;- lm(support_thermometer ~ treatment*victim, data = moderation_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelsummary::modelsummary(list(interaction_model, interaction_model_2, interaction_model_3), 
                           fmt = 2,
                           gof_omit = &amp;quot;AIC|BIC|Log.Lik.&amp;quot;,
                           statistic = &amp;quot;conf.int&amp;quot;,
                           stars = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 2
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 3
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
27.93***
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
27.93***
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
27.93***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[26.85, 29.00]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[26.85, 29.00]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[26.85, 29.00]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8.01***
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8.01***
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8.01***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[6.49, 9.53]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[6.49, 9.53]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[6.49, 9.53]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
victim
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14.26***
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14.26***
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14.26***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[12.73, 15.78]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[12.73, 15.78]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[12.73, 15.78]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment × victim
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
21.77***
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
21.77***
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
21.77***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[19.62, 23.92]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[19.62, 23.92]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[19.62, 23.92]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.787
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.787
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.787
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.786
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.786
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.786
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1227.193
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1227.193
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1227.193
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border:0;&#34; colspan=&#34;100%&#34;&gt;
&lt;sup&gt;&lt;/sup&gt; + p &amp;lt; 0.1, * p &amp;lt; 0.05, ** p &amp;lt; 0.01, *** p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What does this model tell us?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(β_0\)&lt;/span&gt;: Constant = The average support for non-victims who were not exposed to the video was 27.92&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(β_1\)&lt;/span&gt;: Effect of &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt; if &lt;span class=&#34;math inline&#34;&gt;\(Victim_i\)&lt;/span&gt; is zero = The educational video results in an increase of about 8 percentage points of the peace agreement for the non-victims&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(β_2\)&lt;/span&gt;: Effect of &lt;span class=&#34;math inline&#34;&gt;\(Victim_i\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt; if &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; is zero = On average, victims’ support for the peace agreement is 14.3 percentage points higher than that of the non-victims in the control group&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(β_3\)&lt;/span&gt;: Difference in treatment effects of &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; depending on &lt;span class=&#34;math inline&#34;&gt;\(Victim_i\)&lt;/span&gt; = The educational video results in an additional increase for victims of about 21.8 percentage points, compared to the effect for non-victims&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;here-is-a-visual-illustration-of-the-values-rendered-by-the-model-with-interaction-terms&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Here is a visual illustration of the values rendered by the model with interaction terms&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;moderation_df %&amp;gt;%
  dplyr::group_by(treatment,victim_verbose) %&amp;gt;%
  dplyr::mutate(avg_support = mean(support_thermometer)) %&amp;gt;%
ggplot(., aes(x = support_thermometer, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  geom_vline(aes(xintercept = avg_support), linetype = &amp;quot;longdash&amp;quot;) +
  facet_grid(treatment~victim_verbose) +
  theme_bw() +
  labs(x = &amp;quot;Support thermometer&amp;quot;,
       y = &amp;quot;Density&amp;quot;,
       fill = &amp;quot;Treatment&amp;quot;) +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  scale_fill_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/115588510-1fc70a00-a2cf-11eb-8583-4d4e52576709.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;extracting-marginalpartial-effects-from-our-interaction-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extracting marginal/partial effects from our interaction models&lt;/h2&gt;
&lt;p&gt;For this portion, we are interested in &lt;strong&gt;marginal/partial effects&lt;/strong&gt;, which we will extract through the &lt;code&gt;margins()&lt;/code&gt; function from the &lt;code&gt;margins&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Some packages in &lt;strong&gt;R&lt;/strong&gt; aimed at rendering &lt;strong&gt;marginal effects&lt;/strong&gt; do render the &lt;strong&gt;predictive margins&lt;/strong&gt; instead. For the purposes of the class, when asked to render marginal or partial effects you are expected to render them as introduced in the lecture (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial Y_i}{\partial {D}_i}\)&lt;/span&gt;). When asked for this, you will utilize &lt;code&gt;margins::margins()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can check the documentation &lt;a href=&#34;http://cran.uni-muenster.de/web/packages/margins/vignettes/Introduction.html&#34;&gt;here&lt;/a&gt;. The syntax for the &lt;code&gt;margins()&lt;/code&gt; function for extracting partial effects of the treatment at different levels of the moderator is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;margins::margins(name_of_your_model, variables = &amp;quot;treatment_var&amp;quot;, at = list(moderator_variable = c(&amp;quot;value1&amp;quot;, &amp;quot;value2&amp;quot;, &amp;quot;value3&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s say we are interested in the &lt;strong&gt;marginal/partial effect&lt;/strong&gt; of our video treatment for victims and non-victims. We would do:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(margins::margins(interaction_model, variables = &amp;quot;treatment&amp;quot;, at = list(victim = c(0,1))))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     factor victim     AME     SE       z      p   lower   upper
##  treatment 0.0000  8.0125 0.7757 10.3288 0.0000  6.4921  9.5330
##  treatment 1.0000 29.7831 0.7758 38.3895 0.0000 28.2626 31.3037&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;div id=&#34;lets-plot-the-marginalpartial-effect-of-the-treatment-for-victims-and-non-victims&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let’s plot the marginal/partial effect of the treatment for victims and non-victims&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pe_margins &amp;lt;- margins::margins(interaction_model, variables = &amp;quot;treatment&amp;quot;, at = list(victim = c(0,1)))

pe_plotting &amp;lt;- summary(pe_margins) %&amp;gt;% #NOTE we use the summary output, instead of the margins object
  dplyr::select(victim, AME, lower, upper) %&amp;gt;% # you will need to adapt this based your moderator
  dplyr::mutate(victim_labels = ifelse(victim == 1, &amp;quot;Victim&amp;quot;, &amp;quot;No Victim&amp;quot;)) # you may not need this to create labels for the assignment

ggplot(pe_plotting, aes(x = victim_labels,
                        y = AME)) +
  geom_point(size = 1.5) +
  geom_segment(aes(x = victim_labels, xend = victim_labels, y = lower, yend = upper), size = 0.5) + # render whiskers from confidence intervals
  theme_minimal() +
  scale_y_continuous(limits = c(0,45)) + # you may need to change the limits for your plots based on the specific effects of your application
  labs(x = &amp;quot;Respondent status\n&amp;quot;,
       y = &amp;quot;\nPartial effect of educational video&amp;quot;, 
       caption = &amp;quot;Note: You can utilize it to describe what the plot illustrates during your assignment.&amp;quot;) + 
  coord_flip() # to flip the plot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/115588511-1fc70a00-a2cf-11eb-8fc5-bf545210cb2c.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;extracting-predictive-margins-from-our-interaction-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extracting predictive margins from our interaction models&lt;/h2&gt;
&lt;p&gt;For this portion, we are interested in &lt;strong&gt;predictive margins&lt;/strong&gt;. In here, our interest is to return the expectation for each level of a predictor. We will extract this through the &lt;code&gt;ggeffects()&lt;/code&gt; function from the &lt;code&gt;ggeffects&lt;/code&gt; package. You can check the documentation &lt;a href=&#34;https://strengejacke.github.io/ggeffects/index.html&#34;&gt;here&lt;/a&gt;. The syntax is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggeffects::ggeffect(name_of_your_model, terms = c(&amp;quot;termA&amp;quot;, &amp;quot;termB&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s say we are interested in the &lt;strong&gt;predictive margins&lt;/strong&gt; for all out victim and treatment permutations. We would do:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggeffects::ggeffect(interaction_model, terms = c(&amp;quot;victim&amp;quot;,&amp;quot;treatment&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Predicted values of support_thermometer
## # x = victim
## 
## # treatment = 0
## 
## x | Predicted |         95% CI
## ------------------------------
## 0 |     27.93 | [26.85, 29.00]
## 1 |     42.18 | [41.11, 43.26]
## 
## # treatment = 1
## 
## x | Predicted |         95% CI
## ------------------------------
## 0 |     35.94 | [34.86, 37.02]
## 1 |     71.97 | [70.89, 73.04]&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;div id=&#34;lets-plot-these-predictive-margins&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let’s plot these predictive margins&lt;/h4&gt;
&lt;p&gt;In this exercise we will meet a very important function from &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;dplyr::case_when()&lt;/code&gt;. &lt;strong&gt;This function allows us to vectorize multiple ifelse() statements&lt;/strong&gt;. The syntax is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::case_when(condition ~ what to do if met)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see it at play.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extracted_me &amp;lt;-  ggeffects::ggeffect(interaction_model, terms = c(&amp;quot;victim&amp;quot;,&amp;quot;treatment&amp;quot;)) %&amp;gt;%
  dplyr::mutate(group_labels = dplyr::case_when(x == 1 &amp;amp; group == 1 ~ &amp;quot;Victim (1) - Treatment (1)&amp;quot;,
                                                x == 1 &amp;amp; group == 0 ~ &amp;quot;Victim (1) - Treatment (0)&amp;quot;,
                                                x == 0 &amp;amp; group == 1 ~ &amp;quot;Victim (0) - Treatment (1)&amp;quot;,
                                                x == 0 &amp;amp; group == 0 ~ &amp;quot;Victim (0) - Treatment (0)&amp;quot;
  )) # adding labels to (x,group) combinations for the plot

extracted_me

ggplot(extracted_me, aes(x = group_labels, 
                         y= predicted, 
                         fill = x,
                         alpha = group
                         )) +
  geom_bar(stat = &amp;quot;identity&amp;quot;) + 
  geom_point(size = 1.5) +
  geom_segment(aes(x = group_labels, 
                   xend = group_labels, 
                   y = conf.high, 
                   yend = conf.low), size = 0.5) + # render whiskers from confidence intervals
  theme_minimal() +
  labs(x = &amp;quot;\nRespondent status&amp;quot;,
       y = &amp;quot;Predictive margins&amp;quot;,
       fill = &amp;quot;Treatment&amp;quot;,
       caption = &amp;quot;Note: You can utilize it to describe what the plot illustrates during your assignment.&amp;quot;) +
  theme(legend.position = &amp;quot;note&amp;quot;) +
  scale_alpha_manual(values=c(0.6, 1))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/115588514-205fa080-a2cf-11eb-8164-2be8272196d3.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;drafting-some-brief-recommedations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Drafting some brief recommedations&lt;/h2&gt;
&lt;p&gt;After conducting your experiment, you report back to the taskforce. Based on your results, you suggest that the educational videos may be a useful tool to encourage the wider public to hold a warmer opinion about the peace agreement. You also tell the taskforce that, although the videos have an average positive effect, they affect with a higher intensity victims of the conflict. You suggest to develop alternative strategies to tackle the non-victims, so that they do not fall through the cracks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/rrLt0FcGrDeBq/giphy.gif&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Regression Discontinuity Designs</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-7/07-online-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-7/07-online-tutorial/</guid>
      <description>
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;welcome&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Welcome&lt;/h2&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction!&lt;/h3&gt;
&lt;p&gt;Welcome to our seventh tutorial for the Statistics II: Statistical Modeling &amp;amp; Causal Inference (with R) course.&lt;/p&gt;
&lt;p&gt;During this week’s lecture you were introduced to Regression Discontinuity Designs (RDDs).&lt;/p&gt;
&lt;p&gt;In this lab session we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Leverage visualizations with &lt;code&gt;ggplot2&lt;/code&gt; to explore our discontinuity setups&lt;/li&gt;
&lt;li&gt;Learn how to model our discontinuity setups under different functional forms with &lt;code&gt;lm()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Learn how to model our discontinuity setups under different functional forms with &lt;code&gt;rdrobust::rdrobust()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Packages&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# These are the libraries we will use today. Make sure to install them in your console in case you have not done so previously.

library(dplyr) # for data wrangling
library(ggplot2) # for creating plots
library(rdrobust) # for rdrobust()
library(readr) # for loading the .csv data

set.seed(42) # for consistent results

mlda_df &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/seramirezruiz/stats-ii-lab/master/Session%206/data/mlda.csv&amp;quot;) # loading data from Mastering Metrics&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-1.-measuring-the-effect-of-the-minimum-legal-drinking-age-mlda-on-mortality&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1. Measuring the effect of the minimum legal drinking age (MLDA) on mortality&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In an effort to address the social and public health problems associated with underage drinking, a group of American college presidents have lobbied states to return the minimum legal drinking age (MLDA) to the Vietnam era threshold of 18. The theory behind this effort (known as the Amethyst Initiative) is that legal drinking at age 18 discourages binge drinking and promotes a culture of mature alcohol consumption. This contrasts with the traditional view that the age-21 MLDA, while a blunt and imperfect tool, reduces youth access to alcohol, thereby preventing some harm.
&lt;strong&gt;Angrist and Pischke (2014)&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You have been hired as an outside consultant by Mothers Against Drunk Driving (MADD) to study whether the over-21 drinking minimum in the US helps reduce alcohol consumption by young adults and its harms, or is it just not working.
&lt;em&gt;This example is based on data from Carpenter and Dobkin (2011).&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;checking-visually-whether-a-sharp-rdd-makes-sense-for-the-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Checking visually whether a sharp-RDD makes sense for the analysis&lt;/h3&gt;
&lt;p&gt;We want to know &lt;strong&gt;whether our threshold is in fact the cut-off for treatment&lt;/strong&gt;. In this case, the law is pretty clear: young adults in the US can legally drink at age 21.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mlda_df, aes(x = agecell, # actual age
                 y = treatment, # are they over 21 or not
                 color = factor(treatment))) +
  geom_point() + 
  labs(x = &amp;quot;Age&amp;quot;, 
       y = &amp;quot;Treatment Probability&amp;quot;) +
  scale_color_discrete(name = &amp;quot; &amp;quot;, 
                       labels = c(&amp;quot;Under legal drinking age&amp;quot;, &amp;quot;Over legal drinking age&amp;quot;)) +
  geom_vline(xintercept = 21, linetype = &amp;quot;dotted&amp;quot;) + # NEW GEOM A VERTICAL LINE!
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173018-4bfbe780-9249-11eb-9755-5c6695b9049e.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see from the graph that at the 21-years-of-age threshold, young adults can legally consume and buy alcohol in the US, which would make age a viable forcing variable for a sharp-RDD set-up.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;running-our-regression-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Running our regression models&lt;/h3&gt;
&lt;p&gt;As was pointed out in the lecture, we must decide on a model that we believe reflects the relationship of our &lt;span class=&#34;math inline&#34;&gt;\(E(Y_i|\tilde{X}_i)\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;linear, common slope&lt;/li&gt;
&lt;li&gt;linear, different slopes&lt;/li&gt;
&lt;li&gt;non-linear&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Remember that each model corresponds to a particular set of assumptions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We will show you how to visualize this with &lt;code&gt;ggplot&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LET’S LOOK AT A SCATTERPLOT TO GET AN IDEA OF WHAT WE ARE DEALING WITH&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mlda_df, 
       aes(x = agecell, # age 
           y = outcome)) + # mortality rate per 100k accidents
  geom_point() +
  geom_vline(xintercept = 21, linetype = &amp;quot;dotted&amp;quot;) +
  labs(title = &amp;quot;Exploratory plot&amp;quot;,
       x = &amp;quot;Forcing variable (Age)&amp;quot;,
       y = &amp;quot;Mortality rate from motor vehicle \naccidents (per 100,000)&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173046-51593200-9249-11eb-99d2-ae1cca7d1d4e.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE that we have the variable &lt;code&gt;forcing&lt;/code&gt; in this dataset, which is centered at the cutoff. It is nothing but the variable &lt;code&gt;age-21&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;linear-model-with-common-slopes&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Linear model with common slopes&lt;/h4&gt;
&lt;p&gt;Let’s run a linear model with common slopes and plot our results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE that the forcing variable in this case (age) is CENTERED at 0 (age 21) and is the distance from age 21 in years, while treatment is just binary over/under 21.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# running linear model with common slope
linear_common_slope &amp;lt;- lm(outcome ~ treatment + forcing, data = mlda_df)
stargazer::stargazer(linear_common_slope, type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                               outcome          
## -----------------------------------------------
## treatment                    4.534***          
##                               (0.768)          
##                                                
## forcing                      -3.149***         
##                               (0.337)          
##                                                
## Constant                     29.356***         
##                               (0.429)          
##                                                
## -----------------------------------------------
## Observations                    48             
## R2                             0.703           
## Adjusted R2                    0.689           
## Residual Std. Error       1.329 (df = 45)      
## F Statistic           53.142*** (df = 2; 45)   
## ===============================================
## Note:               *p&amp;lt;0.1; **p&amp;lt;0.05; ***p&amp;lt;0.01&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;WHAT DO THESE RESULTS TELL US?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In line with our assumptions for linear models with common slope, we consider that treatment effect &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; does not depend on the forcing &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;. We can formalize this model as:
&lt;span class=&#34;math display&#34;&gt;\[E(Y_i|X_i,D_i) = \tilde{\beta_0} + \beta_1 D_i + \beta_2\tilde{X}_i\]&lt;/span&gt;
Hence we can say, that given our &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; we can expect 4.53 more deaths from motor vehicle accidents per 100,000 for those who can legally drink. We also see that for every year of age increase, the number of expected deaths per 100,000 decreases by 3.15. (Our &lt;span class=&#34;math inline&#34;&gt;\(\beta_2 = -3.1488\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;We can graph our results with &lt;code&gt;ggplot()&lt;/code&gt; by extracting the predicted values of the model to recreate the linear fit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mlda_df$yhat_linear &amp;lt;- predict(linear_common_slope) # we create a new variable containing the predicted mortality rate

linear_plot &amp;lt;- mlda_df %&amp;gt;% # for this plot make sure to put the df outside the ggplot() and pipe it
  ggplot(aes(x = forcing,  
             y = yhat_linear, # notice here the predicted y
             col = factor(treatment))) +
  geom_point(aes(x = forcing, 
                 y = outcome, # notice here the actual outcome
                 col = factor(treatment))) +
  geom_vline(xintercept = 0, linetype = &amp;quot;dotted&amp;quot;) +
  labs(title = &amp;quot;Linear model with common slope&amp;quot;,
       x = &amp;quot;Forcing variable (Age)&amp;quot;,
       y = &amp;quot;Mortality rate from motor vehicle \naccidents (per 100,000)&amp;quot;) +
  geom_line(data = mlda_df[mlda_df$forcing &amp;gt;= 0,], 
            color = &amp;quot;#cc0055&amp;quot;, # color lines
            size = 1) +
  geom_line(data = mlda_df[mlda_df$forcing &amp;lt; 0,], 
            color = &amp;quot;#696969&amp;quot;, # color lines
            size = 1) +
  scale_color_manual(name = &amp;quot;&amp;quot;,
                     values = c(&amp;quot;#696969&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) + #change colors manually of color argument in aes()
  theme_minimal()

linear_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173059-53bb8c00-9249-11eb-8873-37f2ad0643fb.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model-with-different-slopes&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Linear model with different slopes&lt;/h4&gt;
&lt;p&gt;Let’s run the linear model to gather the slopes for both groups and plot our results. This is achieved by interacting our treatment and forcing variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linear_different_slope &amp;lt;- lm(outcome ~ treatment*forcing, data = mlda_df)
stargazer::stargazer(linear_different_slope, type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                               outcome          
## -----------------------------------------------
## treatment                    4.534***          
##                               (0.751)          
##                                                
## forcing                      -2.568***         
##                               (0.466)          
##                                                
## treatment:forcing             -1.162*          
##                               (0.659)          
##                                                
## Constant                     29.929***         
##                               (0.531)          
##                                                
## -----------------------------------------------
## Observations                    48             
## R2                             0.722           
## Adjusted R2                    0.703           
## Residual Std. Error       1.299 (df = 44)      
## F Statistic           38.125*** (df = 3; 44)   
## ===============================================
## Note:               *p&amp;lt;0.1; **p&amp;lt;0.05; ***p&amp;lt;0.01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;WHAT DO THESE RESULTS TELL US?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In line with our assumptions for linear models with different slope, we allow our treatment effect &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; to vary along the forcing &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;. We can formalize this model as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(Y_i|X_i,D_i) = \tilde{\beta_0} + \beta_1D_i+ \beta_2X_i + \tilde{\beta_3}D_i\tilde{X}_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Hence we can say, that at given our &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, we can expect 4.53 more deaths from motor vehicle accidents per 100,000 for those who can legally drink at the threshold. Now we have two different slopes for year-of-age changes. For under-21 individuals, an increase of one year of age would on average result in 2.57 less deaths from motor vehicle accidents (our &lt;span class=&#34;math inline&#34;&gt;\(\beta_2 = -2.5676\)&lt;/span&gt;). For those of legal drinking age, we would expect 3.73 less deaths per 100,000 for every one year of age increase (our &lt;span class=&#34;math inline&#34;&gt;\(\beta_2X_i + \tilde{\beta_3}D_i\tilde{X}_i = -2.5676 + (-1.1624) = - 3.73\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;We can graph our results with &lt;code&gt;ggplot&lt;/code&gt; by just adding a smooth geom. Since we have added treatment to our color aesthetic, &lt;code&gt;ggplot()&lt;/code&gt; will automatically create the regression line for each group&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diff_slopes_plot &amp;lt;- mlda_df %&amp;gt;% 
  ggplot(aes(x = forcing,  
             y = outcome, 
             col = factor(treatment))) +
  geom_point() +
  geom_vline(xintercept = 0, linetype = &amp;quot;dotted&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = F) + # NORMAL SMOOTH 
  labs(title = &amp;quot;Linear model with different slopes&amp;quot;,
       x = &amp;quot;Forcing variable (Age)&amp;quot;,
       y = &amp;quot;Mortality rate from motor vehicle \naccidents (per 100,000)&amp;quot;) +
  scale_color_manual(name = &amp;quot;&amp;quot;,
                     values = c(&amp;quot;#696969&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) + #change colors manually of color argument in aes()
  theme_minimal()

diff_slopes_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173084-58804000-9249-11eb-9f9a-4bd110c5fc78.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Where can you see our &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; in the previous plot?&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;non-linear-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Non-linear model&lt;/h4&gt;
&lt;p&gt;Let’s run a quadratic model and plot our results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;THIS IS HOW WE WOULD FORMALIZE A QUADRATIC MODEL&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(Y_i∣X_i, D_i) = \gamma_0 + + \tau_1D_i + \gamma_2\tilde{X_i} + \gamma_3\tilde{X^2_i} + \alpha_1\tilde{X_i}D_i + \alpha_2\tilde{X^2_i}D_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can input this in our regression model as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quadratic &amp;lt;- lm(outcome ~ forcing + 
                  I(forcing^2) + # I tells R to interpret &amp;quot;as is&amp;quot;
                  treatment + 
                  I(forcing * treatment) + 
                  I((forcing^2) * treatment),
                data = mlda_df)

stargazer::stargazer(quadratic, type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## =====================================================
##                               Dependent variable:    
##                           ---------------------------
##                                     outcome          
## -----------------------------------------------------
## forcing                             -2.933           
##                                     (1.914)          
##                                                      
## I(forcing2)                         -0.185           
##                                     (0.940)          
##                                                      
## treatment                          4.663***          
##                                     (1.155)          
##                                                      
## I(forcing * treatment)              -0.823           
##                                     (2.706)          
##                                                      
## I((forcing2) * treatment)            0.198           
##                                     (1.329)          
##                                                      
## Constant                           29.809***         
##                                     (0.817)          
##                                                      
## -----------------------------------------------------
## Observations                          48             
## R2                                   0.722           
## Adjusted R2                          0.689           
## Residual Std. Error             1.329 (df = 42)      
## F Statistic                 21.864*** (df = 5; 42)   
## =====================================================
## Note:                     *p&amp;lt;0.1; **p&amp;lt;0.05; ***p&amp;lt;0.01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;WHAT DO THESE RESULTS TELL US?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In line with our assumptions for non-linear models, we allow our treatment effect &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; to vary along the forcing &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;. In this case with quadratic interactions. We can formalize this model as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(Y_i∣X_i, D_i) = \gamma_0 + + \tau_1D_i + \gamma_2\tilde{X_i} + \gamma_3\tilde{X^2_i} + \alpha_1\tilde{X_i}D_i + \alpha_2\tilde{X^2_i}D_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Hence we can say, that at given our &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;, we can expect 4.66 more deaths from motor vehicle accidents per 100,000 for those who can legally drink at the threshold. We could also calculate the expected value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at different levels of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Say we want to know what the expected value is for 23-year-olds. Since our forcing variable is 0 at 21 years of age, we can think of 23 as 2. Additionally, 23-year-olds are above the legal drinking age minimum, therefore for them the value of &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(Y | X=2, D =1) = 29.8090 + 4.6629(1) - 2.9330(2) -0.1852(2)^2  - 0.8231 (2*1) + 0.1985(2*1)^2 = 27.01\]&lt;/span&gt;
Based on this, we would expect a mortality rate from motor vehicle accidents of 27.01 per 100,000 for 23-year-olds.&lt;/p&gt;
&lt;p&gt;We can graph our results with &lt;code&gt;ggplot&lt;/code&gt; by extracting the predicted values of our quadratic model to recreate the fit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mlda_df$yhat_quadratic &amp;lt;- predict(quadratic) 

quadratic_plot &amp;lt;- mlda_df %&amp;gt;% 
  ggplot(aes(x = forcing, 
             y = yhat_quadratic, #note predicted y
             col = factor(treatment))) +
  geom_point(aes(x = forcing, 
                 y = outcome, 
                 col = factor(treatment))) +
  geom_vline(xintercept = 0, linetype = &amp;quot;dotted&amp;quot;) +
  labs(title = &amp;quot;Quadratic plot&amp;quot;,
       x = &amp;quot;Forcing variable (Age)&amp;quot;,
       y = &amp;quot;Mortality rate from motor vehicle \naccidents (per 100,000)&amp;quot;) +
  geom_line(data = mlda_df[mlda_df$forcing &amp;gt;= 0,], 
            color = &amp;quot;#cc0055&amp;quot;, # color lines
            size = 1) +
  geom_line(data = mlda_df[mlda_df$forcing &amp;lt; 0,], 
            color = &amp;quot;#696969&amp;quot;, # color lines
            size = 1) +
  scale_color_manual(name = &amp;quot;&amp;quot;,
                     values = c(&amp;quot;#696969&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) + #change colors manually of color argument in aes()
  theme_minimal()

quadratic_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173100-5c13c700-9249-11eb-8ed3-dd90942ea297.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;calculating-the-late-with-rdrobust&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Calculating the LATE with rdrobust()&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;rdrobust()&lt;/code&gt; is part of the &lt;code&gt;rdrobust&lt;/code&gt; package. It performs local linear regressions to either side of the cutpoint using optimal bandwidth calculation. The syntax is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- rdrobust::rdrobust(x, 
                            y,
                            c = cutoffvalue,
                            kernel = &amp;quot;tri&amp;quot;, #default
                            bwselect = &amp;quot;mserd&amp;quot;) #default
                            &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have the option to set the cutpoint, kernel type, order of the local polynomial, etc.: &lt;a href=&#34;https://cran.r-project.org/web/packages/rdrobust/rdrobust.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/rdrobust/rdrobust.pdf&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;llr &amp;lt;- rdrobust::rdrobust(mlda_df$outcome, 
                          mlda_df$forcing,  
                          c = 0,
                          kernel = &amp;quot;tri&amp;quot;,
                          bwselect = &amp;quot;mserd&amp;quot;)
summary(llr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Call: rdrobust
## 
## Number of Obs.                   48
## BW type                       mserd
## Kernel                   Triangular
## VCE method                       NN
## 
## Number of Obs.                  24          24
## Eff. Number of Obs.              6           6
## Order est. (p)                   1           1
## Order bias  (q)                  2           2
## BW est. (h)                  0.487       0.487
## BW bias (b)                  0.738       0.738
## rho (h/b)                    0.660       0.660
## Unique Obs.                     24          24
## 
## =============================================================================
##         Method     Coef. Std. Err.         z     P&amp;gt;|z|      [ 95% C.I. ]       
## =============================================================================
##   Conventional     4.901     2.059     2.380     0.017     [0.864 , 8.937]     
##         Robust         -         -     1.881     0.060    [-0.198 , 9.674]     
## =============================================================================&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;WHAT DO THESE RESULTS TELL US?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The model is telling us that based on the calculation, the estimated effect would be 4.90 more deaths per 100,000 for those over-21.&lt;/p&gt;
&lt;p&gt;The most straight-forward way to graph the output of this model is through the &lt;code&gt;rdrobust::rdplot()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rdrobust::rdplot(mlda_df$outcome, 
                 mlda_df$forcing,  
                 c = 0,
                 kernel = &amp;quot;tri&amp;quot;,
                 title = &amp;quot;Motor Vehicle Accidents Death&amp;quot;,
                 x.label = &amp;quot;Age from 21&amp;quot;,
                 y.label =  &amp;quot;Mortality rate from motor vehicle \naccidents (per 100,000)&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173122-603fe480-9249-11eb-834a-88e02aec7b3d.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;quadratic-model-with-rdrobust&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Quadratic model with rdrobust()&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quadratic_rdrobust &amp;lt;- rdrobust::rdrobust(mlda_df$outcome, 
                                         mlda_df$forcing,  
                                         c = 0,
                                         kernel = &amp;quot;tri&amp;quot;,
                                         bwselect = &amp;quot;mserd&amp;quot;,
                                         p = 2) #polynomial 2
summary(quadratic_rdrobust)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Call: rdrobust
## 
## Number of Obs.                   48
## BW type                       mserd
## Kernel                   Triangular
## VCE method                       NN
## 
## Number of Obs.                  24          24
## Eff. Number of Obs.             10          10
## Order est. (p)                   2           2
## Order bias  (q)                  3           3
## BW est. (h)                  0.821       0.821
## BW bias (b)                  1.074       1.074
## rho (h/b)                    0.764       0.764
## Unique Obs.                     24          24
## 
## =============================================================================
##         Method     Coef. Std. Err.         z     P&amp;gt;|z|      [ 95% C.I. ]       
## =============================================================================
##   Conventional     4.778     2.337     2.044     0.041     [0.197 , 9.360]     
##         Robust         -         -     1.627     0.104    [-0.911 , 9.811]     
## =============================================================================&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rdrobust::rdplot(mlda_df$outcome, 
                 mlda_df$forcing,  
                 c = 0,
                 kernel = &amp;quot;tri&amp;quot;,
                 p = 2,
                 title = &amp;quot;Motor Vehicle Accidents Death&amp;quot;,
                 x.label = &amp;quot;Age from 21&amp;quot;,
                 y.label =  &amp;quot;Mortality rate from motor vehicle \naccidents (per 100,000)&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173141-65049880-9249-11eb-88c2-425685d137ea.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2.-measuring-the-long-term-effects-of-a-conditional-cash-transfer-program-on-educational-achievement&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2. Measuring the long term effects of a conditional cash transfer program on educational achievement&lt;/h2&gt;
&lt;p&gt;Imagine that you work as a technical adviser for the Ministry of Education in your country. You are tasked to assess whether a Conditional Cash Transfer (CCT) program established decades before yields positive results on the beneficiaries’ educational attainment. There is a large amount of evidence which suggests that CCTs encourage households to increase the use of educational services.&lt;/p&gt;
&lt;p&gt;You read the guidelines for the program. Families receive a stipend per child provided they keep their them in school and take them for health checks. Additionally, you note that under the rules of the program, beneficiaries are selected based on a household income threshold of €20000. You decide to dive into the data with the idea that a discontinuity is created based on the income threshold. (This example utilizes simulated data)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cct_df &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/seramirezruiz/stats-ii-lab/master/Session%206/data/cct_data.csv&amp;quot;) # loading simulated data frame of the program&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hh_income&lt;/code&gt;: household income in euros&lt;/li&gt;
&lt;li&gt;&lt;code&gt;years_of_schooling&lt;/code&gt;: years of schooling for respondent&lt;/li&gt;
&lt;li&gt;&lt;code&gt;treatment&lt;/code&gt;: binary variable indicating whether respondent was a beneficiary of the program&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;checking-visually-whether-a-sharp-rdd-makes-sense-for-the-analysis-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Checking visually whether a sharp-RDD makes sense for the analysis&lt;/h3&gt;
&lt;p&gt;What we are looking for in this case is whether our €20000 threshold is in fact the cut-off for treatment. That is to say, that only those who had a household income of equal or less than €20000 received the cash transfer.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(cct_df, 
       aes(x = hh_income, 
           y = years_of_schooling, 
           color = factor(treatment))) + 
  geom_point() + 
  labs(x = &amp;quot;Household Income&amp;quot;, 
       y = &amp;quot;Years of Schooling&amp;quot;) +
  scale_color_discrete(name = &amp;quot; &amp;quot;, 
                       labels = c(&amp;quot;No treatment&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  geom_vline(xintercept = 20000, linetype = &amp;quot;dotted&amp;quot;) +
  theme_minimal()

ggplot(cct_df, 
       aes(x = hh_income, 
           y = treatment, 
           color = factor(treatment))) + 
  geom_point() + 
  labs(x = &amp;quot;Household Income&amp;quot;, 
       y = &amp;quot;Treatment&amp;quot;) +
  scale_color_discrete(name = &amp;quot; &amp;quot;, 
                       labels = c(&amp;quot;No treatment&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  geom_vline(xintercept = 20000, linetype = &amp;quot;dotted&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173157-6930b600-9249-11eb-8b74-9aaf732171c8.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173172-6c2ba680-9249-11eb-85ef-8e4d5c5f0513.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see from the graph that our €20000 threshold is in fact cutting off the distribution of the treatment. This would make household income a viable forcing variable for a sharp-RDD set-up.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;estimating-our-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Estimating our model&lt;/h3&gt;
&lt;p&gt;We can see that the relationship is fairly linear, so we decide to run a linear model with common slope.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# running linear model with common slope
ed_achievement &amp;lt;- lm(years_of_schooling ~ treatment + hh_income, data = cct_df)
stargazer::stargazer(ed_achievement, type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ================================================
##                         Dependent variable:     
##                     ----------------------------
##                          years_of_schooling     
## ------------------------------------------------
## treatment                     2.460***          
##                               (0.038)           
##                                                 
## hh_income                     0.001***          
##                              (0.00000)          
##                                                 
## Constant                     -2.648***          
##                               (0.111)           
##                                                 
## ------------------------------------------------
## Observations                   5,000            
## R2                             0.815            
## Adjusted R2                    0.815            
## Residual Std. Error      0.817 (df = 4997)      
## F Statistic         11,008.950*** (df = 2; 4997)
## ================================================
## Note:                *p&amp;lt;0.1; **p&amp;lt;0.05; ***p&amp;lt;0.01&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;WHAT DO THESE RESULTS TELL US?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In line with our assumptions for linear models with common slope, we consider that treatment effect, &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;, does not depend on the forcing &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;. Hence, we can expect that students who received the treatment get on average 2.4 more years of schooling. We also see that for every €1,000 increase in the household income, students are expected to attain 0.6274 more years of education. (Our &lt;span class=&#34;math inline&#34;&gt;\(\beta = -6.274e-04*1000\)&lt;/span&gt;).&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Getting familiar with LOESS&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Locally weighted smoothing is a popular tool used in regression analysis that creates a smooth line through a scatter plot to help you to see relationship between variables and foresee trends. We can introduce it to our &lt;code&gt;ggplot()&lt;/code&gt; as a part of geom_smooth by calling method “loess”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(cct_df, 
       aes(x = hh_income, 
           y = years_of_schooling, 
           color = factor(treatment))) + 
  geom_point(alpha = 0.1) + 
  labs(x = &amp;quot;Household Income&amp;quot;, 
       y = &amp;quot;Years of Schooling&amp;quot;) +
  geom_smooth(method = &amp;quot;loess&amp;quot;) + # instead of lm, we use loess. See the difference? try with lm
  scale_color_discrete(name = &amp;quot; &amp;quot;, 
                       labels = c(&amp;quot;No treatment&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  geom_vline(xintercept = 20000, linetype = &amp;quot;dotted&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173183-6e8e0080-9249-11eb-85d1-7028b83ddde8.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The LOESS smoothing is not very visible in this relationship because of the way we defined the simulated data. Let’s look at how it would look in our drinking age example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mlda_df,
       aes(x = agecell,  
           y = outcome, 
           col = factor(treatment))) +
  geom_point() +
  geom_smooth(method = &amp;quot;loess&amp;quot;) +
  labs(title = &amp;quot;LOESS smoothing&amp;quot;,
       x = &amp;quot;Forcing variable (Age)&amp;quot;,
       y = &amp;quot;Mortality rate from motor vehicle \naccidents (per 100,000)&amp;quot;) +
  scale_color_manual(name = &amp;quot;&amp;quot;,
                     values = c(&amp;quot;#F8766D&amp;quot;, &amp;quot;#00BFC4&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;)) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/113173230-777ed200-9249-11eb-8fa7-07ba3d15148c.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;violations-to-the-assumptions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Violations to the assumptions&lt;/h4&gt;
&lt;p&gt;You are made aware by a tax expert from your unit that €20000 is the upper-boundary for a very well known tax concession. You are afraid that people may be sorting themselves before the household income cut-off to become beneficiaries of multiple programs. You decide to check your data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ggplot(cct_df, 
       aes(x = hh_income)) +
  geom_histogram(bins = 50, fill = &amp;quot;#cc0055&amp;quot;) +
  labs(title = &amp;quot;Income distribution&amp;quot;,
       x = &amp;quot;Household Income&amp;quot;,
       y = &amp;quot;Number of respondents&amp;quot;) +
  geom_vline(xintercept = 20000, linetype = &amp;quot;dotted&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/160796955-4104431c-0b88-4625-aa85-01038a503cda.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;This case looks a bit ambiguous. Do you think people are sorting out just before the cut-off? If sorting were to exist which assumptions would be challenged? Would the existence of other programs that have the same threshold affect a causal reading of our results?&lt;/p&gt;
&lt;p&gt;There are a couple of tests researchers can employ. We will learn two ways. First, a method by which the research chooses a window of sorting to check if the distribution could have occurred by chance and second the McCrary test you met in Cunningham (2021).&lt;/p&gt;
&lt;h4 style=&#34;color:#cc0065&#34;&gt;
Binomial test
&lt;/h4&gt;
&lt;p&gt;When we apply an exact binomial test. Our interest is to see whether the distribution around the threshold could exist by chance. In this case, let’s check ±500 and ±250 around the threshold.&lt;/p&gt;
&lt;p&gt;To gather only the units that reported household incomes from €19500 to €20500, we will use a new function &lt;code&gt;dplyr::between()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;dplyr::between()&lt;/code&gt; is a shortcut for &lt;code&gt;x &amp;gt;= left &amp;amp; x &amp;lt;= right&lt;/code&gt;. Let’s look at it at work.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cct_df %&amp;gt;% 
  dplyr::filter(dplyr::between(hh_income, 19500, 20500)) %&amp;gt;% #filter values between 19500 and 20500
  dplyr::group_by(treatment) %&amp;gt;%
  dplyr::summarize(n = n()) %&amp;gt;%
  knitr::kable() %&amp;gt;%
  kableExtra::kable_styling()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
255
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
300
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We have 300 units just below the threshold and 255 units just above. We can use this information to run our exact binomial test. We seek to understand if the observed distributions deviate from expected distribution of observations into the two categories.&lt;/p&gt;
&lt;p&gt;We can do the same for €19750 to €20250&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cct_df %&amp;gt;% 
  dplyr::filter(dplyr::between(hh_income, 19750, 20250)) %&amp;gt;% #filter values between 19750 and 20250
  dplyr::group_by(treatment) %&amp;gt;%
  dplyr::summarize(n = n()) %&amp;gt;%
  knitr::kable() %&amp;gt;%
  kableExtra::kable_styling()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
n
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
115
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
175
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;binom.test(one_of_the_n, total_n, p = probability_of_success)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;Let’s see what this would say for ±500:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;binom.test(300, 555, p = 0.5) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Exact binomial test
## 
## data:  300 and 555
## number of successes = 300, number of trials = 555, p-value = 0.06171
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4980565 0.5825909
## sample estimates:
## probability of success 
##              0.5405405&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;WHAT DO THESE RESULTS TELL US?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;According to the test, we see that the observed distributions &lt;strong&gt;do not deviate&lt;/strong&gt; from expected distribution of observations into the two categories when we expect that units just around the threshold end up on either group by chance (coin flip logic, i.e., p = 0.5). In other words, this results do not present some evidence of sorting in this window.&lt;/p&gt;
&lt;p&gt;How about ±250?:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;binom.test(115, 290, p = 0.5) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Exact binomial test
## 
## data:  115 and 290
## number of successes = 115, number of trials = 290, p-value = 0.0005095
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.3398404 0.4553997
## sample estimates:
## probability of success 
##              0.3965517&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;WHAT DO THESE RESULTS TELL US?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;According to the test, we see that the observed distributions &lt;strong&gt;deviate&lt;/strong&gt; from expected distribution of observations into the two categories when we expect that units just around the threshold end up on either group by chance (coin flip logic, i.e., p = 0.5). In other words, this results present some evidence of sorting in this window.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 style=&#34;color:#cc0065&#34;&gt;
McCrary Sorting test
&lt;/h4&gt;
&lt;p&gt;An alternative way to check for self-sorting is the McCrary Sorting test. In this test, the discretion on window selection is taken away from the researcher (at least in the defaults). The McCrary Sorting test is included in the &lt;code&gt;rdd&lt;/code&gt; package. This is the syntax of the test:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rdd::Dcdensity(runvar=running_variable, cutpoint=cutpoint)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;Let’s see it in practice:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rdd::DCdensity(cct_df$hh_income, cutpoint = 20000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/160797472-ef844573-f944-4809-8562-361cc149f305.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04168422&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;WHAT DO THESE RESULTS TELL US?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The default output is a p-value of the test. A p-value below the significance threshold indicates that the user can reject the null hypothesis of no sorting. In other words, this test would suggest that our observed distributions &lt;strong&gt;deviate&lt;/strong&gt; from the expected distribution of observations. This results present some evidence of sorting.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Backdoor Criterion and Basics of Regression in R</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-4/04-online-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-4/04-online-tutorial/</guid>
      <description>


&lt;div id=&#34;welcome&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Welcome&lt;/h2&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction!&lt;/h3&gt;
&lt;p&gt;Welcome to our fourth tutorial for the Statistics II: Statistical Modeling &amp;amp; Causal Inference (with R) course.&lt;/p&gt;
&lt;p&gt;During this week&#39;s lecture you reviewed bivariate and multiple linear regressions. You also learned how Directed Acyclic Graphs (DAGs) can be leveraged to gather causal estimates.&lt;/p&gt;
&lt;p&gt;In this lab session we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;ggdag&lt;/code&gt; and &lt;code&gt;dagitty&lt;/code&gt; packages to assess your modeling strategy&lt;/li&gt;
&lt;li&gt;Review how to run regression models using &lt;strong&gt;R&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Illustrate omitted variable and collider bias&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Packages&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# These are the libraries we will use today. Make sure to install them in your console in case you have not done so previously.
set.seed(42) #for consistent results in randomization
library(wooldridge) # To get our example&amp;#39;s dataset 
library(tidyverse) # To use dplyr functions and the pipe operator when needed
library(ggplot2) # To visualize data (this package is also loaded by library(tidyverse))
library(ggdag) # To dagify and plot our DAG objects in R
library(dagitty) # To perform analysis in our DAG objects in R
library(stargazer) # To render nicer regression output
data(&amp;quot;wage1&amp;quot;) # calls the wage1 dataset from the woorldridge package&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;working-with-dags-in-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Working with DAGs in R&lt;/h2&gt;
&lt;p&gt;Last week we learned about the general syntax of the &lt;code&gt;ggdag&lt;/code&gt; package:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We created &lt;strong&gt;dagified&lt;/strong&gt; objects with &lt;code&gt;ggdag::dagify()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;We plotted our DAGs with &lt;code&gt;ggdag::ggdag()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;We discussed how to specify the coordinates of our nodes with a coordinate list&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Today, we will learn how the &lt;code&gt;ggdag&lt;/code&gt; and &lt;code&gt;dagitty&lt;/code&gt; packages can help us illustrate our paths and adjustment sets to fulfill the &lt;strong&gt;backdoor criterion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let&#39;s take one of the DAGs from our review slides:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coord_dag &amp;lt;- list(
  x = c(d = 0, p = 0, b = 1, a = 1 , c = 2, y = 2),
  y = c(d = 0, p = 2, b = 1, a = -1, c = 2, y = 0)
)

our_dag &amp;lt;- ggdag::dagify(d ~ p + a, # p and a pointing at d
                         b ~ p + c, # p and c pointing at b
                         y ~ d + a + c, # d, a, and c pointing at y
                         coords = coord_dag, # our coordinates from the list up there
                         exposure = &amp;quot;d&amp;quot;, # we declare out exposure variable
                         outcome = &amp;quot;y&amp;quot;) # we declare out outcome variable

ggdag::ggdag(our_dag) + 
  theme_dag() # equivalent to theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109506958-85043900-7a9e-11eb-8183-50a985ca1195.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;learning-about-our-paths-and-what-adjustments-we-need&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Learning about our paths and what adjustments we need&lt;/h3&gt;
&lt;p&gt;As you have seen, when we &lt;strong&gt;dagify&lt;/strong&gt; a DAG in &lt;strong&gt;R&lt;/strong&gt; a &lt;em&gt;dagitty&lt;/em&gt; object is created. These objects tell &lt;strong&gt;R&lt;/strong&gt; that we are dealing with DAGs.&lt;/p&gt;
&lt;p&gt;This is very important because in addition to plotting them, &lt;strong&gt;we can do analyses on the DAG objects&lt;/strong&gt;. A package that complements &lt;code&gt;ggdag&lt;/code&gt; is the &lt;code&gt;dagitty&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Today, we will focus on two functions from the &lt;code&gt;dagitty&lt;/code&gt; package:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dagitty::paths()&lt;/code&gt;: Returns a list with two components: &lt;strong&gt;paths&lt;/strong&gt;, which gives the actual paths, and &lt;strong&gt;open&lt;/strong&gt;, which shows whether each path is open (d-connected) or closed (d-separated).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dagitty::adjustmentSets()&lt;/code&gt;: Lists the sets of covariates that would allow for unbiased estimation of causal effects, &lt;strong&gt;assuming that the causal graph is correct&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We just need to input our DAG object.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;paths&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Paths&lt;/h4&gt;
&lt;p&gt;Let&#39;s see how the output of the &lt;code&gt;dagitty::paths&lt;/code&gt; function looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dagitty::paths(our_dag)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $paths
## [1] &amp;quot;d -&amp;gt; y&amp;quot;                &amp;quot;d &amp;lt;- a -&amp;gt; y&amp;quot;           &amp;quot;d &amp;lt;- p -&amp;gt; b &amp;lt;- c -&amp;gt; y&amp;quot;
## 
## $open
## [1]  TRUE  TRUE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see under &lt;code&gt;$paths&lt;/code&gt; the three paths we declared during the manual exercise:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;d -&amp;gt; y&lt;/li&gt;
&lt;li&gt;d &amp;lt;- a -&amp;gt; y&lt;/li&gt;
&lt;li&gt;d &amp;lt;- p -&amp;gt; b &amp;lt;- c -&amp;gt; y&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additionally, &lt;code&gt;$open&lt;/code&gt; tells us whether each path is open. In this case, we see that the second path is the only open non-causal path, so we would need to condition on &lt;strong&gt;a&lt;/strong&gt; to close it.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;We can also use &lt;code&gt;ggdag&lt;/code&gt; to present the open paths visually with the &lt;code&gt;ggdag_paths()&lt;/code&gt; function, as such:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggdag::ggdag_paths(our_dag) +
  theme_dag()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109506962-86356600-7a9e-11eb-8207-df83d670a43e.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;covariate-adjustment&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Covariate adjustment&lt;/h4&gt;
&lt;p&gt;In addition to listing all the paths and sorting the backdoors manually, we can use the &lt;code&gt;dagitty::adjustmentSets()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;With this function, we just need to input our DAG object and it will return the different sets of adjustments.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dagitty::adjustmentSets(our_dag)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## { a }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, in this DAG there is only one option. We need to control for &lt;strong&gt;a&lt;/strong&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;We can also use &lt;code&gt;ggdag&lt;/code&gt; to present the open paths visually with the &lt;code&gt;ggdag_adjustment_set()&lt;/code&gt; function, as such:&lt;/p&gt;
&lt;p&gt;Also, do not forget to set the argument &lt;code&gt;shadow = TRUE&lt;/code&gt;, so that the arrows from the adjusted nodes are included.&lt;/p&gt;
&lt;pre class=&#34;3&#34;&gt;&lt;code&gt;ggdag::ggdag_adjustment_set(our_dag, shadow = T) +
  theme_dag()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109506965-87669300-7a9e-11eb-8d6c-ed01a9e3aa41.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&#34;&gt;If you want to learn more about DAGs in R
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ggdag&lt;/code&gt; documentation: &lt;a href=&#34;https://ggdag.malco.io/&#34; class=&#34;uri&#34;&gt;https://ggdag.malco.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dagitty&lt;/code&gt; vignette: &lt;a href=&#34;https://cran.r-project.org/web/packages/dagitty/dagitty.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/dagitty/dagitty.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;What is `dagitty: &lt;a href=&#34;https://cran.r-project.org/web/packages/dagitty/vignettes/dagitty4semusers.html&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/dagitty/vignettes/dagitty4semusers.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;NOW LET&#39;S MOVE TO REGRESSION&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction-to-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction to Regression&lt;/h2&gt;
&lt;p&gt;Linear regression is largely used to predict the value of an outcome variable based on one or more input explanatory variables. As we previously discussed, regression addresses a simple mechanical problem, namely, &lt;strong&gt;what is our best guess of y given an observed x&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Regression can be utilized without thinking about causes as a &lt;em&gt;predictive&lt;/em&gt; or &lt;em&gt;summarizing&lt;/em&gt; tool&lt;/li&gt;
&lt;li&gt;It would not be appropiate to give causal interpretations to any &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;, unless we establish the fulfilment of centain assumptions&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;bivariate-regression&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bivariate regression&lt;/h3&gt;
&lt;p&gt;In bivariate regression, we are modeling a variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a mathematical function of one variable &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We can generalize this in a mathematical equation as such:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = \beta_{0} + \beta{1}x + ϵ\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-linear-regression&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple linear regression&lt;/h3&gt;
&lt;p&gt;In multiple linear regression, we are modeling a variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a mathematical function of multiple variables &lt;span class=&#34;math inline&#34;&gt;\((x, z, m)\)&lt;/span&gt;. We can generalize this in a mathematical equation as such:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = \beta_{0} + \beta_{1}x + \beta_{2}z + \beta_{3}m + ϵ\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-questions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory questions&lt;/h2&gt;
&lt;p&gt;Let&#39;s illustrate this with an example&lt;/p&gt;
&lt;p&gt;We will use the &lt;code&gt;wage1&lt;/code&gt; dataset from the &lt;code&gt;wooldridge&lt;/code&gt; package. These are data from the 1976 Current Population Survey used by Jeffrey M. Wooldridge with pedagogical purposes in his book on Introductory Econometrics.&lt;/p&gt;
&lt;p&gt;If you want to check the contents of the &lt;code&gt;wage1&lt;/code&gt; data frame, you can type &lt;code&gt;?wage1&lt;/code&gt; in your console&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;visualizing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualizing&lt;/h3&gt;
&lt;h4 style=&#34;color:#800080;&#34;&gt;
With regression we can answer &lt;strong&gt;EXPLORATORY QUESTIONS&lt;/strong&gt;. For example:
&lt;/h4&gt;
&lt;h5&gt;
What is the relationship between education and respondents&#39; salaries?
&lt;/h5&gt;
&lt;p&gt;We can start by exploring the relationship visually with our newly attained &lt;code&gt;ggplot2&lt;/code&gt; skills:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(wage1, aes(x = educ, y = wage)) +
  geom_point(color = &amp;quot;grey60&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = F, color = &amp;quot;#CC0055&amp;quot;) +
  theme_minimal() +
  labs(x = &amp;quot;Years of education&amp;quot;,
       y = &amp;quot;Hourly wage (USD)&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109506967-87ff2980-7a9e-11eb-8cca-36756b8c502e.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;the-lm-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;lm()&lt;/code&gt; function&lt;/h3&gt;
&lt;p&gt;This question can be formalized mathematically as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Hourly\ wage = \beta_0 + \beta_1Years\ of\ education + ϵ\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Our interest here would be to build a model that predicts the hourly wage of a respondent (&lt;strong&gt;our outcome variable&lt;/strong&gt;) using the years of education (&lt;strong&gt;our explanatory variable&lt;/strong&gt;). Fortunately for us, &lt;strong&gt;R&lt;/strong&gt; provides us with a very intuitive syntax to model regressions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The general syntax for running a regression model in R is the following:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;your_model_biv &amp;lt;- lm(outcome_variable ~ explanarory_variable, data = your_dataset) #for a bivariate regression
your_model_mult &amp;lt;- lm(outcome_variable ~ explanarory_variable_1 + explanarory_variable_2, data = your_dataset) #for multiple regression&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&#39;s create our own model and save it into the &lt;code&gt;model_1&lt;/code&gt; object, based on the bivariate regression we specified above in which &lt;code&gt;wage&lt;/code&gt; is our outcome variable, &lt;code&gt;educ&lt;/code&gt; is our explanatory variable, and our data come from the &lt;code&gt;wage1&lt;/code&gt; object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_1 &amp;lt;- lm(wage ~ educ, data = wage1)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-and-broomtidy&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;summary()&lt;/code&gt; and &lt;code&gt;broom::tidy()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;We have created an object that contains the coefficients, standard errors and further information from your model. In order to see the estimates, you could use the base R function &lt;code&gt;summary()&lt;/code&gt;. &lt;strong&gt;This function is very useful when you want to print your results in your console.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alternatively, you can use the &lt;code&gt;tidy()&lt;/code&gt; function from the &lt;code&gt;broom&lt;/code&gt; package. The function constructs a data frame that summarizes the model’s statistical findings. You can see what else you can do with broom by running: vignette(“broom”). &lt;strong&gt;The &lt;code&gt;broom::tidy()&lt;/code&gt; function is useful when you want to store the values for future use (e.g., visualizing them)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let&#39;s try both options in the console up there. You just need to copy this code below the &lt;code&gt;model_1&lt;/code&gt; code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model_1)
broom::tidy(model_1)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Hourly\ wage = \beta_0 + \beta_1Years\ of\ education + ϵ\]&lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
&lt;table style=&#34;text-align:center&#34;&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;Dependent variable:&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td colspan=&#34;1&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
Hourly wage
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Years of education
&lt;/td&gt;
&lt;td&gt;
0.541&lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.053)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Constant
&lt;/td&gt;
&lt;td&gt;
-0.905
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.685)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Observations
&lt;/td&gt;
&lt;td&gt;
526
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
R&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
&lt;td&gt;
0.165
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Adjusted R&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
&lt;td&gt;
0.163
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Residual Std. Error
&lt;/td&gt;
&lt;td&gt;
3.378 (df = 524)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
F Statistic
&lt;/td&gt;
&lt;td&gt;
103.363&lt;sup&gt;***&lt;/sup&gt; (df = 1; 524)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;em&gt;Note:&lt;/em&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;
&lt;sup&gt;&lt;em&gt;&lt;/sup&gt;p&amp;lt;0.1; &lt;sup&gt;&lt;strong&gt;&lt;/sup&gt;p&amp;lt;0.05; &lt;sup&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/sup&gt;p&amp;lt;0.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p style=&#34;color:#CC0055;&#34;&gt;
How would you interpret the results of our &lt;code&gt;model_1&lt;/code&gt;?
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What does the constant mean?&lt;/li&gt;
&lt;li&gt;What does the &lt;code&gt;educ&lt;/code&gt; coefficient mean?&lt;/li&gt;
&lt;li&gt;Do these coefficient carry any causal meaning?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-more-nuance-to-our-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Adding more nuance to our models&lt;/h2&gt;
&lt;p&gt;As we have discussed in previous sessions we live in a very complex world. It is very likely that our exploration of the relationship between education and respondents&#39; salaries is open to multiple sources of bias.&lt;/p&gt;
&lt;p&gt;Looking back at 1976 US, can you think of possible variables inside the mix?&lt;/p&gt;
&lt;p&gt;
How about the &lt;span style=&#34;color:#CC0055;&#34;&gt;sex&lt;/span&gt; or the &lt;span style=&#34;color:#800080;&#34;&gt;ethnicity&lt;/span&gt; of a worker?
&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;lets-explore-this-visually&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Let&#39;s explore this visually&lt;/h3&gt;
&lt;h5&gt;
What is the relationship between education and respondents&#39; salaries &lt;span style=&#34;color:#CC0055;&#34;&gt;conditional on the sex of the worker&lt;/span&gt;?
&lt;/h5&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(wage1, aes(x = educ, y = wage, color = as.factor(female))) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = F) +
  theme_minimal() +
  labs(x = &amp;quot;Years of education&amp;quot;,
       y = &amp;quot;Hourly wage (USD)&amp;quot;,
       color = &amp;quot;Female&amp;quot;) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109506969-87ff2980-7a9e-11eb-80b9-ce388816ecc0.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Check what happens when we replace the &lt;code&gt;color = as.factor(female)&lt;/code&gt; for &lt;code&gt;color = female&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What insights can we gather from this graph?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-linear-regression-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple linear regression&lt;/h3&gt;
&lt;p&gt;This question can be formalized mathematically as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Hourly\ wage = \beta_0 + \beta_1Years\ of\ education + \beta_2Female + ϵ\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Our interest here would be to build a model that predicts the hourly wage of a respondent (&lt;strong&gt;our outcome variable&lt;/strong&gt;) using the years of education and their sex (&lt;strong&gt;our explanatory variables&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Let&#39;s remember the syntax for running a regression model in R:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;your_model_biv &amp;lt;- lm(outcome_variable ~ explanarory_variable, data = your_dataset) #for a bivariate regression
your_model_mult &amp;lt;- lm(outcome_variable ~ explanarory_variable_1 + explanarory_variable_2, data = your_dataset) #for multiple regression&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&#39;s create our own model, save it into the &lt;code&gt;model_2&lt;/code&gt; object, and print the results based on the formula regression we specified above in which &lt;code&gt;wage&lt;/code&gt; is our outcome variable, &lt;code&gt;educ&lt;/code&gt; and &lt;code&gt;female&lt;/code&gt; are our explanatory variables, and our data come from the &lt;code&gt;wage1&lt;/code&gt; object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_2 &amp;lt;- lm(wage ~ educ + female, data = wage1)
summary(model_2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = wage ~ educ + female, data = wage1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.9890 -1.8702 -0.6651  1.0447 15.4998 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  0.62282    0.67253   0.926    0.355    
## educ         0.50645    0.05039  10.051  &amp;lt; 2e-16 ***
## female      -2.27336    0.27904  -8.147 2.76e-15 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 3.186 on 523 degrees of freedom
## Multiple R-squared:  0.2588, Adjusted R-squared:  0.256 
## F-statistic: 91.32 on 2 and 523 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;exercise-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Hourly\ wage = \beta_0 + \beta_1Years\ of\ education + \beta_2Female + ϵ\]&lt;/span&gt;&lt;/p&gt;
&lt;table style=&#34;text-align:center&#34;&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;em&gt;Dependent variable:&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td colspan=&#34;1&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
Hourly wage
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Years of education
&lt;/td&gt;
&lt;td&gt;
0.506&lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.050)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Female
&lt;/td&gt;
&lt;td&gt;
-2.273&lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.279)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Constant
&lt;/td&gt;
&lt;td&gt;
0.623
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
(0.673)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Observations
&lt;/td&gt;
&lt;td&gt;
526
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
R&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
&lt;td&gt;
0.259
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Adjusted R&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
&lt;td&gt;
0.256
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
Residual Std. Error
&lt;/td&gt;
&lt;td&gt;
3.186 (df = 523)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
F Statistic
&lt;/td&gt;
&lt;td&gt;
91.315&lt;sup&gt;***&lt;/sup&gt; (df = 2; 523)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&#34;2&#34; style=&#34;border-bottom: 1px solid black&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;
&lt;em&gt;Note:&lt;/em&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;
&lt;sup&gt;&lt;em&gt;&lt;/sup&gt;p&amp;lt;0.1; &lt;sup&gt;&lt;strong&gt;&lt;/sup&gt;p&amp;lt;0.05; &lt;sup&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/sup&gt;p&amp;lt;0.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p style=&#34;color:#CC0055;&#34;&gt;
How would you interpret the results of our &lt;code&gt;model_2&lt;/code&gt;?
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What does the constant mean?&lt;/li&gt;
&lt;li&gt;What does the &lt;code&gt;educ&lt;/code&gt; coefficient mean?&lt;/li&gt;
&lt;li&gt;What does the &lt;code&gt;female&lt;/code&gt; coefficient mean?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;predicting-from-our-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Predicting from our models&lt;/h3&gt;
&lt;p&gt;As we discussed previously, when we do not have our &lt;strong&gt;causal inference&lt;/strong&gt; hats on, the main goal of linear regression is to predict an outcome value on the basis of one or multiple predictor variables.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; has a generic function &lt;code&gt;predict()&lt;/code&gt; that helps us arrive at the predicted values on the basis of our explanatory variables.&lt;/p&gt;
&lt;p&gt;The syntax of &lt;code&gt;predict()&lt;/code&gt; is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(name_of_the_model, newdata = data.frame(explanatory1 = value, explanatory2 = value))&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Say that based on our &lt;code&gt;model_2&lt;/code&gt;, we are interested in the expected average hourly wage of a woman with 15 years of education.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(model_2, newdata = data.frame(educ = 15, female = 1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1 
## 5.946237&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;What does this result tell us?&lt;/li&gt;
&lt;li&gt;What happens when you change &lt;code&gt;female&lt;/code&gt; to 0? What does the result mean?&lt;/li&gt;
&lt;li&gt;Can you think of a way to find the difference in the expected hourly wage between a male with 16 years of education and a female with 17?&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(model_2, newdata = data.frame(educ = 16, female = 0)) - predict(model_2, newdata = data.frame(educ = 15, female =0))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         1 
## 0.5064521&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;quiz&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quiz&lt;/h2&gt;
&lt;p&gt;Here are some questions for you. Note that there are multiple ways to reach the same answer:&lt;/p&gt;
&lt;p&gt;What is the expected hourly wage of a male with 15 years of education?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;$8.22&lt;/li&gt;
&lt;li&gt;$9.50&lt;/li&gt;
&lt;li&gt;5.34&lt;/li&gt;
&lt;li&gt;$3&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;p&gt;How much more on average does a male worker earn than a female counterpart?&amp;quot;,&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;$2.27&lt;/li&gt;
&lt;li&gt;In our data, males on average earn less than females&lt;/li&gt;
&lt;li&gt;$1.20&lt;/li&gt;
&lt;li&gt;$4.50&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;p&gt;How much more is a worker expected to earn for every additional year of education, keeping sex constant?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;$0.90&lt;/li&gt;
&lt;li&gt;$1.20&lt;/li&gt;
&lt;li&gt;$0.5&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;dags-and-modeling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;DAGs and modeling&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/94547573-b8bd0780-024f-11eb-9565-03b1d1109c3b.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As we can remember from our slides, we were introduced to a set of &lt;strong&gt;key&lt;/strong&gt; rules in understanding how to employ DAGs to guide our modeling strategy.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A path is open or unblocked at non-colliders (confounders or mediators)&lt;/li&gt;
&lt;li&gt;A path is (naturally) blocked at colliders&lt;/li&gt;
&lt;li&gt;An open path induces statistical association between two variables&lt;/li&gt;
&lt;li&gt;Absence of an open path implies statistical independence&lt;/li&gt;
&lt;li&gt;Two variables are d-connected if there is an open path between them&lt;/li&gt;
&lt;li&gt;Two variables are d-separated if the path between them is blocked&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this portion of the tutorial we will demonstrate how different bias come to work when we model our relationships of interest.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;what-happens-when-we-control-for-a-collider&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What happens when we control for a collider?&lt;/h2&gt;
&lt;h4 style=&#34;color:#CC5500&#34;&gt;
The case for beauty, talent, and celebrity (What happens when we control for a collider?)
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/94370219-0706c500-00ef-11eb-814b-05ab715ee2e0.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As it is showcased from our DAG, we assume that earning celebrity status is a function of an individuals beauty and talent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We will simulate data that reflects this assumptions&lt;/strong&gt;. In our world, someone gains celebrity status if the sum of units of beauty and celebrity are greater than 8.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# beauty - 1000 observations with mean 5 units of beauty and sd 1.5 (arbitrary scale)
beauty &amp;lt;- rnorm(1000, 5, 1.5)

# talent - 1000 observations with mean 3 units of talent and sd 1 (arbitrary scale)
talent &amp;lt;- rnorm(1000, 3, 1)

# celebrity - binary
celebrity_status &amp;lt;-  ifelse(beauty + talent &amp;gt; 8, &amp;quot;Celebrity&amp;quot; , &amp;quot;Not Celebrity&amp;quot;) # celebrity if the sum of units  are greater than 8

celebrity_df &amp;lt;- dplyr::tibble(beauty, talent, celebrity_status) # we make a df with our values

head(celebrity_df, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
##    beauty talent celebrity_status
##     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           
##  1   7.06 5.33   Celebrity       
##  2   4.15 3.52   Not Celebrity   
##  3   5.54 3.97   Celebrity       
##  4   5.95 3.38   Celebrity       
##  5   5.61 2.00   Not Celebrity   
##  6   4.84 2.40   Not Celebrity   
##  7   7.27 3.17   Celebrity       
##  8   4.86 0.0715 Not Celebrity   
##  9   8.03 2.15   Celebrity       
## 10   4.91 3.80   Celebrity&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;In this case, as our simulation suggest, we have a &lt;strong&gt;collider structure&lt;/strong&gt;. We can see that celebrity can be a function of beauty or talent. Also, we can infer from the way we defined the variables that &lt;strong&gt;beauty and talent are d-separated (ie. the path between them is closed because celebrity is a collider)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Say you are interested in researching the relationship between &lt;strong&gt;beauty&lt;/strong&gt; and &lt;strong&gt;talent&lt;/strong&gt; for your Master&#39;s thesis, while doing your literature review you encounter a series of papers that find a negative relationship between the two and state that more beautiful people tend to be less talented. The model that these teams of the researchers used was the following:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{Talent} = \beta_0 + \beta_1Beauty + \beta_2Celebrity\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Your scientific hunch makes you believe that celebrity is a collider and that by controlling for it in their models, the researchers are inducing &lt;strong&gt;collider bias&lt;/strong&gt;, or &lt;strong&gt;endogenous bias&lt;/strong&gt;. You decide to move forward with your thesis by laying out a criticism to previous work on the field, given that you consider the formalization of their models is erroneous. You utilize the same data previous papers used, but based on your logic, you do not control for celebrity status. This is what you find:&lt;/p&gt;
&lt;div id=&#34;true-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;True model&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;true_model_celebrity &amp;lt;- lm(talent ~ beauty, data = celebrity_df)
summary(true_model_celebrity)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = talent ~ beauty, data = celebrity_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.9225 -0.6588 -0.0083  0.6628  3.5877 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 2.962209   0.107595  27.531   &amp;lt;2e-16 ***
## beauty      0.006545   0.020755   0.315    0.753    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.9865 on 998 degrees of freedom
## Multiple R-squared:  9.964e-05,  Adjusted R-squared:  -0.0009023 
## F-statistic: 0.09945 on 1 and 998 DF,  p-value: 0.7526&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(celebrity_df, aes(x=beauty, 
                         y=talent)) +
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = F) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(x = &amp;quot;Beauty&amp;quot;,
       y = &amp;quot;Talent&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109508058-b6313900-7a9f-11eb-92c6-16551885f993.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;biased-model-from-previous-literature&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Biased model from previous literature&lt;/h4&gt;
&lt;p&gt;Let&#39;s see:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;biased_model_celibrity &amp;lt;- lm(talent ~ beauty + celebrity_status, data = celebrity_df)
summary(biased_model_celibrity)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = talent ~ beauty + celebrity_status, data = celebrity_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.4244 -0.5394  0.0110  0.5064  2.9429 
## 
## Coefficients:
##                               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                    5.37834    0.13983   38.46   &amp;lt;2e-16 ***
## beauty                        -0.32668    0.02265  -14.43   &amp;lt;2e-16 ***
## celebrity_statusNot Celebrity -1.51375    0.06808  -22.24   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.807 on 997 degrees of freedom
## Multiple R-squared:  0.3316, Adjusted R-squared:  0.3302 
## F-statistic: 247.3 on 2 and 997 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(celebrity_df, aes(x=beauty, y=talent, color = celebrity_status)) +
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = F) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(x = &amp;quot;Beauty&amp;quot;,
       y = &amp;quot;Talent&amp;quot;,
       color = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109508067-b8939300-7a9f-11eb-8f48-dd090d63234c.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As we can see, by controlling for a collider, the previous literature was inducing to a non-existent association between beauty and talent, also known as &lt;strong&gt;collider&lt;/strong&gt; or &lt;strong&gt;endogenous bias&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;what-happens-when-we-fail-to-control-for-a-confounder&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What happens when we fail to control for a confounder?&lt;/h2&gt;
&lt;h4 style=&#34;color:#32CD32;&#34;&gt;
Shoe size and salary (What happens when we fail to control for a confounder?)
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/94558922-cd55cb80-0260-11eb-9b03-ff54416014a7.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sex - replicate male and female 500 times each
sex &amp;lt;- rep(c(&amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;), each = 500) 

# shoe size - random number with mean 38 and sd 4, plus 4 if the observation is male
shoesize &amp;lt;- rnorm(1000, 38, 2) +  (4 * as.numeric(sex == &amp;quot;Male&amp;quot;))

# salary - a random number with mean 25 and sd 2, plus 5 if the observation is male
salary &amp;lt;- rnorm(1000, 25, 2) + (5 * as.numeric(sex == &amp;quot;Male&amp;quot;))

salary_df &amp;lt;- dplyr::tibble(sex, shoesize, salary)

head(salary_df, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
##    sex   shoesize salary
##    &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1 Male      42.5   28.6
##  2 Male      41.4   28.4
##  3 Male      38.6   29.2
##  4 Male      38.0   27.7
##  5 Male      39.4   32.2
##  6 Male      42.7   28.2
##  7 Male      41.7   32.6
##  8 Male      40.5   27.1
##  9 Male      40.4   31.7
## 10 Male      43.1   28.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Say now one of your peers tells you about this new study that suggests that &lt;strong&gt;shoe size&lt;/strong&gt; has an effect on an individuals&#39; &lt;strong&gt;salary&lt;/strong&gt;. You are a bit skeptic and read it. The model that these researchers apply is the following:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{Salary} = \beta_0 + \beta_1ShoeSize\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Your scientific hunch makes you believe that this relationship could be confounded by the &lt;strong&gt;sex&lt;/strong&gt; of the respondent. You think that by failing to control for sex in their models, the researchers are inducing &lt;strong&gt;omitted variable bias&lt;/strong&gt;. You decide to open their replication files and control for sex. This is what you find:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{Salary} = \beta_0 + \beta_1ShoeSize + \beta_2Sex\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;true-model-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;True model&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;true_model_salary &amp;lt;- lm(salary ~ shoesize + sex, data = salary_df)
summary(true_model_salary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = salary ~ shoesize + sex, data = salary_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.2341 -1.3698 -0.0501  1.3595  6.4303 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 25.73879    1.15886  22.210   &amp;lt;2e-16 ***
## shoesize    -0.02030    0.03044  -0.667    0.505    
## sexMale      5.05924    0.17616  28.720   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.981 on 997 degrees of freedom
## Multiple R-squared:  0.6129, Adjusted R-squared:  0.6121 
## F-statistic: 789.2 on 2 and 997 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(salary_df, aes(x=shoesize, y=salary, color = sex)) +
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = F) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  labs(x = &amp;quot;Shoe size&amp;quot;,
       y = &amp;quot;Salary&amp;quot;,
       color = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109508071-b9c4c000-7a9f-11eb-9790-f67e51100516.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;biased-model-from-previous-literature-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Biased model from previous literature&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;biased_model_salary &amp;lt;- lm(salary ~ shoesize, data = salary_df)
summary(biased_model_salary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = salary ~ shoesize, data = salary_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.8777 -1.9101 -0.0511  1.8496  7.9774 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  3.68865    1.17280   3.145  0.00171 ** 
## shoesize     0.59429    0.02925  20.319  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.676 on 998 degrees of freedom
## Multiple R-squared:  0.2926, Adjusted R-squared:  0.2919 
## F-statistic: 412.9 on 1 and 998 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(salary_df, aes(x=shoesize, y=salary)) +
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = F) +
  theme_minimal() +
  labs(x = &amp;quot;Shoe size&amp;quot;,
       y = &amp;quot;Salary&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/109508075-ba5d5680-7a9f-11eb-92e2-2f845bb5c5ec.png&#34; width=&#34;85%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As we can see, by failing to control for a confounder, the previous literature was creating a non-existent association between shoe size and salary, incurring in &lt;strong&gt;ommited variable bias&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Potential Outcomes Framework</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-2/pof/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-2/pof/</guid>
      <description>
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2021-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-pof-in-practice&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The POF in practice&lt;/h1&gt;
&lt;p&gt;Let&#39;s revisit the example from our slides once again.&lt;/p&gt;
&lt;p&gt;Say we are interested in assessing the premise of Allport&#39;s hypothesis about interpersonal contact being conducive to reducing intergroup prejudice.&lt;/p&gt;
&lt;p&gt;We are studying a set of (&lt;span class=&#34;math inline&#34;&gt;\(n=8\)&lt;/span&gt;) students assigned to a dorm room with a person from their own ethnic group &lt;strong&gt;(contact=0)&lt;/strong&gt; and from a different group &lt;strong&gt;(contact=1)&lt;/strong&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Student (i)&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Prejudice (C=0)&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Prejudice (C=1)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;div id=&#34;data-set&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data set&lt;/h2&gt;
&lt;p&gt;Today we will work with the &lt;code&gt;prejudice_df&lt;/code&gt; object. The data frame contains the following four variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;student_id&lt;/code&gt;: numeric student identification&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prej_0&lt;/code&gt;: prejudice level under &lt;span class=&#34;math inline&#34;&gt;\(Y_{0i}\)&lt;/span&gt; (Contact=0)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prej_1&lt;/code&gt;: prejudice level under &lt;span class=&#34;math inline&#34;&gt;\(Y_{1i}\)&lt;/span&gt; (Contact=1)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dorm_type&lt;/code&gt;: binary for actual treatment state&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 4
##   student_id prej_0 prej_1 dorm_type
##        &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1          1      6      5         0
## 2          2      4      2         1
## 3          3      4      4         0
## 4          4      6      7         0
## 5          5      3      1         1
## 6          6      2      2         1
## 7          7      8      7         0
## 8          8      4      5         0&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;treatment-effects&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Treatment Effects&lt;/h1&gt;
&lt;div id=&#34;a-individual-treatment-effect-ite&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;a) Individual Treatment Effect (ITE)&lt;/h2&gt;
&lt;p&gt;We assume from the &lt;em&gt;potential outcomes framework&lt;/em&gt; that each subject has a &lt;strong&gt;potential outcome&lt;/strong&gt; under both treatment states. Let&#39;s take the first student in the list as an example.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/92996733-20641a80-f50e-11ea-8b55-a17da3d8b36f.png&#34; width=&#34;65%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The figure illustrates the &lt;strong&gt;potential outcomes&lt;/strong&gt; for &lt;em&gt;Student 1&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We see that in a reality where &lt;em&gt;Student 1&lt;/em&gt; is assigned to in-group dorm &lt;strong&gt;(contact=0)&lt;/strong&gt; their levels of prejudice are &lt;em&gt;6&lt;/em&gt;. On the contrary, in a reality where &lt;em&gt;Student 1&lt;/em&gt; is assigned to co-ethnic dorm &lt;strong&gt;(contact=1)&lt;/strong&gt; their levels of prejudice are &lt;em&gt;5&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;From this illustration, we can gather the &lt;strong&gt;individual treatment effect (ITE)&lt;/strong&gt; for student one. The &lt;strong&gt;ITE&lt;/strong&gt; is equal to the values under treatment &lt;em&gt;(contact=1)&lt;/em&gt; minus to the values without treatment &lt;em&gt;(contact=0)&lt;/em&gt; or &lt;span class=&#34;math inline&#34;&gt;\(ITE = y_{1i} - y_{0i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ITE = 5 - 6 = -1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;As it was put in Cunningham&amp;rsquo;s book:&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;The ITE is a “comparison of two states of the world” (Cunningham, 2021): individuals are exposed to contact, and not exposed to it.&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Evidently, each subject can only be observed in one treatment state at any point in time in real life. This is known as the &lt;strong&gt;fundamental problem&lt;/strong&gt; (Holland, 1986) of causal inference. &lt;strong&gt;The Individual Treatment Effect (ITE) in reality is unattainable.&lt;/strong&gt; Still, it provides us with a conceptual foundation for causal estimation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; &lt;em&gt;Our data are coming from a world with perfect information. In that sense, we have both potential outcomes &lt;code&gt;prej_0&lt;/code&gt; and &lt;code&gt;prej_1&lt;/code&gt;. Can you think of a way to calculate the&lt;/em&gt; &lt;strong&gt;ITE&lt;/strong&gt; &lt;em&gt;for the eight students with one of the &lt;code&gt;dplyr&lt;/code&gt; verbs we learned in the previous section?&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Hint&lt;/summary&gt;
  &lt;p&gt;Can you think of a way we can use the verb &lt;code&gt;mutate()&lt;/code&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#you can employ dplyr::mutate() to create the new variable ite
prejudice_df %&amp;gt;% 
  dplyr::mutate(ite = prej_1 - prej_0)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
student_id
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
prej_0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
prej_1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
dorm_type
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ite
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;average-treatment-effect-ate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Average Treatment Effect (ATE)&lt;/h2&gt;
&lt;p&gt;Normally, we are not interested in the estimates of individual subjects, but rather a population. The &lt;strong&gt;Average Treatment Effect (ATE)&lt;/strong&gt; is the difference in the average potential outcomes of the population.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ATE = E(Y_{1i}) - E(Y_{0i})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In other words, the &lt;strong&gt;ATE&lt;/strong&gt; is the average &lt;strong&gt;ITE&lt;/strong&gt; of all the subjects in the population. As you can see, &lt;strong&gt;the ATE as defined in the formula is also not attainable&lt;/strong&gt;. Can you think why?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; &lt;em&gt;Since our data are coming from a world with perfect information. Can you think of a way to calculate the&lt;/em&gt; &lt;strong&gt;ATE&lt;/strong&gt; &lt;em&gt;for the eight students based on what we learned last week?&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Hint&lt;/summary&gt;
  &lt;p&gt;We have already extracted the ite with &lt;code&gt;mutate()&lt;/code&gt;. We know that the the ATE is the averge of every subject&#39;s ITE. Do you remember &lt;code&gt;summarize()&lt;/code&gt;?&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we know that the ATE is the averge of every subject&amp;#39;s ITE. Do you remember dplyr::summarize()?
#how can we use the verbs from last week to get the average treatment effect?

prejudice_df %&amp;gt;%
  dplyr::mutate(ite = prej_1 - prej_0) %&amp;gt;%
  dplyr::summarize(ate=mean(ite))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ate
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;the-average-treatment-effect-among-the-treated-and-control-att-and-atc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Average Treatment Effect Among the Treated and Control (ATT) and (ATC)&lt;/h2&gt;
&lt;p&gt;The names for these two estimates are very self-explanatory. These two estimates are simply the average treatment effects conditional on the group subjects are assigned to.&lt;/p&gt;
&lt;p&gt;The average treatment effect on the treated &lt;strong&gt;ATT&lt;/strong&gt; is defined as the difference in the average potential outcomes for those subjects who were treated: &lt;span class=&#34;math display&#34;&gt;\[ATT = E(Y_{1i}-Y_{0i} | D = 1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The average treatment effect under control &lt;strong&gt;ATC&lt;/strong&gt; is defined as the difference in the average potential outcomes for those subjects who were not treated: &lt;span class=&#34;math display&#34;&gt;\[ATC = E(Y_{1i}-Y_{0i} | D = 0)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; &lt;em&gt;Since our data are coming from a world with perfect information. Can you think of a way to calculate the&lt;/em&gt; &lt;strong&gt;ATT&lt;/strong&gt; &lt;em&gt;and&lt;/em&gt; &lt;strong&gt;ATC&lt;/strong&gt; &lt;em&gt;for the eight students based on what we learned last week?&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Hint&lt;/summary&gt;
  &lt;p&gt;We have already extracted the ite with &lt;code&gt;mutate()&lt;/code&gt;. We know that the ATT and ATC are the average of every subject&#39;s ITE grouped by their treatment status. Do you remember how the combination of &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;summarize()&lt;/code&gt; worked?&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we know that the ATT and ATC are the average of every subject&amp;#39;s ITE grouped by their treatment status. Do you remember how the combination of dplyr::group_by() and dplyr::summarize() worked?
#how can we use the verbs from last week to get the average treatment effect on the treated and untreated?

prejudice_df %&amp;gt;%
  dplyr::mutate(ite = prej_1 - prej_0) %&amp;gt;%
  dplyr::group_by(dorm_type) %&amp;gt;%
  dplyr::summarize(treatment_effects=mean(ite))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
dorm_type
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
treatment_effects
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.333333
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;the-naive-average-treatment-effect-nate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Naive Average Treatment Effect (NATE)&lt;/h2&gt;
&lt;p&gt;So far, we have worked with perfect information. Still, we know that in reality we can only observe subjects in one treatment state. This is the information we &lt;strong&gt;do&lt;/strong&gt; have.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/93014681-527b8800-f5b3-11ea-98f2-200e42f49bd4.png&#34; width=&#34;65%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The &lt;strong&gt;Naive Average Treatment Effect (NATE)&lt;/strong&gt; is the calculation we can compute based on the observed outcomes.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[NATE = E(Y_{1i}|D{i}=1) - E(Y_{0i}|D{i}=0)\]&lt;/span&gt; *&lt;em&gt;reads in English as: &amp;quot;The expected average outcome under treatment for those treated minus the expected average outcome under control for those not treated&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; &lt;em&gt;Can you think of a way to calculate the&lt;/em&gt; &lt;strong&gt;NATE&lt;/strong&gt; &lt;em&gt;for the eight students employing the new &lt;code&gt;observed_prej&lt;/code&gt; variable?&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prejudice_df %&amp;gt;%
  dplyr::mutate(observed_prej = ifelse(dorm_type == 1, prej_1, prej_0))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
student_id
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
prej_0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
prej_1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
dorm_type
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
observed_prej
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;Hint&lt;/summary&gt;
  &lt;p&gt;We have already extracted the average observed outcomes depending on the treatment status with &lt;code&gt;mutate()&lt;/code&gt;. We know that the NATE is the difference in average observed outcomes grouped by their treatment status. Do you remember how the combination of &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;summarize()&lt;/code&gt; worked?&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-9&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#we know that the NATE is the difference in average observed outcomes grouped by their treatment status. Do you remember how the combination of dplyr::group_by() and dplyr::summarize() worked?

prejudice_df %&amp;gt;%
  dplyr::mutate(observed_prej = ifelse(dorm_type == 1, prej_1, prej_0)) %&amp;gt;%
  dplyr::group_by(dorm_type) %&amp;gt;%
  dplyr::summarize(mean(observed_prej))
  
#You can just substract the values&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
dorm_type
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
mean(observed_prej)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.600000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.666667
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;You can just substract the values&lt;/strong&gt;&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;Note.&lt;/em&gt; The ìfelse() function is a very handy tool to have. It allows us to generate conditional statements. The syntax is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ifelse(condition_to_meet, what_to_do_if_met, what_to_do_if_not_met)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;In the case of &lt;code&gt;observed_prej&lt;/code&gt;, we ask&lt;/em&gt; &lt;strong&gt;R&lt;/strong&gt; &lt;em&gt;to create a new variable, where if the subject is in a co-ethnic dorm, we print the prejudice value under treatment. If that condition is not met, we print the prejudice value under control.&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bias&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bias&lt;/h1&gt;
&lt;div id=&#34;bias-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bias&lt;/h2&gt;
&lt;p&gt;During the lecture, we met two sources of bias:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/93015117-13e7cc80-f5b7-11ea-8281-dde25922a883.png&#34; width=&#34;65%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;baseline-bias&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Baseline bias&lt;/h2&gt;
&lt;p&gt;Baseline bias—also known as selection bias— is difference in expected outcomes in the absence of treatment for the actual treatment and control group. In other words, these are the underlying differences that individuals in either group start off with.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;differential-treatment-effect-bias&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Differential treatment effect bias&lt;/h2&gt;
&lt;p&gt;Differential treatment effect bias — also known as Heterogeneous Treatment Effect (HTE) bias — is the difference in returns to treatment (the treatment effect) between the treatment and control group, multiplied by the share of the population in control. In other words, this type of bias relates to the dissimilarities stemming for ways in which individuals in either group are affected differently by the treatment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We will let you think about these for the mock assignment&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; &lt;em&gt;Since our data are coming from a world with perfect information. Can you think of a way to explore the existence&lt;/em&gt; &lt;strong&gt;baseline bias&lt;/strong&gt; &lt;em&gt;in our data?&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-10&#34;&gt;
  &lt;summary&gt;Hint&lt;/summary&gt;
  &lt;p&gt;We know that the baseline bias is the difference in average observed outcomes under control grouped by their treatment status. Do you remember how the combination of dplyr::group_by() and dplyr::summarize() worked?&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; &lt;em&gt;Since our data are coming from a world with perfect information. Can you think of a way to explore the existence&lt;/em&gt; &lt;strong&gt;differential treatment effect bias&lt;/strong&gt; &lt;em&gt;in our data?&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-11&#34;&gt;
  &lt;summary&gt;Hint&lt;/summary&gt;
  &lt;p&gt;We know that the differential treatment effect bias is the difference in difference in the average of every subject&#39;s ITE grouped by their treatment status (or the difference between ATT and ATCs). Maybe you can go back an check how to get the average treatment effect on the treated and untreated.&lt;/p&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Panel Data and Fixed Effects</title>
      <link>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-9/09-online-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seramirezruiz.github.io/2022-spring-stats2/materials/session-9/09-online-tutorial/</guid>
      <description>
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://seramirezruiz.github.io/2022-spring-stats2/2022-spring-stats2rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;welcome&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Welcome&lt;/h2&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction!&lt;/h3&gt;
&lt;p&gt;Welcome to our ninth tutorial for the Statistics II: Statistical Modeling &amp;amp; Causal Inference (with R) course.&lt;/p&gt;
&lt;p&gt;During this week’s lecture you were introduced to Panel Data and Fixed Effects.&lt;/p&gt;
&lt;p&gt;In this lab session we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create three-way tables with &lt;code&gt;janitor::tabyl()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Visualize trends across time with &lt;code&gt;ggplot2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Learn how to extract our pooled, unit-fixed, and unit- and time-fixed effects estimates with Least Squares Dummy Variables (LSDV) estimation (with &lt;code&gt;lm()&lt;/code&gt; and the de-meaning approach with &lt;code&gt;plm()&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;measuring-the-effect-of-a-carbon-tax-on-national-carbon-dioxide-emissions-per-capita&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Measuring the effect of a carbon tax on national carbon dioxide emissions per capita&lt;/h2&gt;
&lt;p&gt;After all the very valuable output you have generated in the past weeks, you have become a sensation within the policy analysis world. You are hired as an outside consultant by the Organization of Economic Non-Cooperation for Development (OENCD), they are interested in studying the effect of a carbon tax on national carbon dioxide emissions per capita. You are provided with data for the twenty-members of the organization from 2009 to 2019. &lt;em&gt;The data can be called a balanced panel based on the description given in the lecture (i.e. each panel member is observed every year)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/201804/MIT-Carbon-Pricing_0.jpg?itok=KsqzQi8F&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Packages&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# These are the libraries we will use today. Make sure to install them in your console in case you have not done so previously.

set.seed(42) #for consistent results

library(dplyr) # to wrangle our data
library(tidyr) # to wrangle our data - pivot_longer()
library(lubridate) # for working with dates-times in a more intuitive manner
library(ggplot2) # to render our graphs
library(readr) # for loading the .csv data
library(kableExtra) # to render better formatted tables
library(stargazer) # for formatting your model output
library(janitor) # for data management and tabyl()
library(lmtest) # to gather our clustered standard errors - coeftest()
library(plm)  # to gather our clustered standard errors - vcovHC() and plm()&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;our-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Our data&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;carbon_tax_df &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/seramirezruiz/stats-ii-lab/master/Session%207/data/carbon_tax_df.csv&amp;quot;) # simulated data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our dataset &lt;em&gt;carbon_tax_df&lt;/em&gt;, contains the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;country_name&lt;/code&gt;: Name of the country&lt;/li&gt;
&lt;li&gt;&lt;code&gt;country_code&lt;/code&gt;: Three-letter country code&lt;/li&gt;
&lt;li&gt;&lt;code&gt;year&lt;/code&gt;: Year&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tax&lt;/code&gt;: Dummy for whether the carbon tax was in place&lt;/li&gt;
&lt;li&gt;&lt;code&gt;income_class&lt;/code&gt;: Categorical variable with income label (Low to High)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;co2_per_capita&lt;/code&gt;: carbon dioxide emissions per capita in metric tons (T)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory analysis&lt;/h2&gt;
&lt;div id=&#34;let-explore-who-had-the-tax-in-place-at-what-point&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let’ explore who had the tax in place at what point&lt;/h4&gt;
&lt;p&gt;We can use what we have learned about the &lt;code&gt;janitor::tabyl()&lt;/code&gt; function to check how many observations we have for each of the countries:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One-way table:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;carbon_tax_df %&amp;gt;%
  janitor::tabyl(country_name) %&amp;gt;%
  janitor::adorn_pct_formatting(digits = 1) %&amp;gt;%
  knitr::kable(col.names = c(&amp;quot;Country&amp;quot;, &amp;quot;N&amp;quot;, &amp;quot;Percent, %&amp;quot;)) %&amp;gt;%
  kableExtra::kable_styling()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Country
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
N
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Percent, %
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adjikistan
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Borovia
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Carpania
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Corinthia
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Freedonia
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Glenraven
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Khemed
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Laurania
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Parano
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Ron
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rumekistan
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Transia
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
8.3%
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can also explore how many countries had a &lt;code&gt;tax&lt;/code&gt; in place every year.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Two-way table:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;carbon_tax_df %&amp;gt;%
  janitor::tabyl(tax, year) %&amp;gt;%
  janitor::adorn_totals(&amp;quot;row&amp;quot;) %&amp;gt;%
  janitor::adorn_percentages(&amp;quot;col&amp;quot;) %&amp;gt;%
  janitor::adorn_pct_formatting(digits = 1) %&amp;gt;%
  janitor::adorn_ns() %&amp;gt;% 
  knitr::kable() %&amp;gt;%
  kableExtra::kable_styling() %&amp;gt;%
  kableExtra::add_header_above(c(&amp;quot;&amp;quot;, &amp;quot;Year&amp;quot; = 11))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;11&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Year
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
tax
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2009
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2010
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2011
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2012
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2013
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2014
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2015
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2016
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2017
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2018
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2019
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
83.3% (10)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
75.0% (9)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
41.7% (5)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
41.7% (5)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
25.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (4)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
58.3% (7)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (8)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
58.3% (7)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Total
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (12)
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can further explore how many countries had a &lt;code&gt;tax&lt;/code&gt; in place every year at the &lt;code&gt;income_class&lt;/code&gt; cluster:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Three-way table:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;carbon_tax_df %&amp;gt;%
  janitor::tabyl(tax, year, income_class) %&amp;gt;%
  janitor::adorn_percentages(&amp;quot;col&amp;quot;) %&amp;gt;%
  janitor::adorn_pct_formatting(digits = 1) %&amp;gt;%
  janitor::adorn_ns() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $High
##  tax       2009       2010      2011      2012      2013      2014      2015
##    0 100.0% (3) 100.0% (3) 66.7% (2) 66.7% (2) 33.3% (1) 33.3% (1) 33.3% (1)
##    1   0.0% (0)   0.0% (0) 33.3% (1) 33.3% (1) 66.7% (2) 66.7% (2) 66.7% (2)
##       2016      2017      2018      2019
##  33.3% (1) 33.3% (1) 33.3% (1) 33.3% (1)
##  66.7% (2) 66.7% (2) 66.7% (2) 66.7% (2)
## 
## $`High-Middle`
##  tax       2009       2010      2011      2012      2013      2014       2015
##    0 100.0% (3) 100.0% (3) 66.7% (2) 66.7% (2) 66.7% (2) 66.7% (2)   0.0% (0)
##    1   0.0% (0)   0.0% (0) 33.3% (1) 33.3% (1) 33.3% (1) 33.3% (1) 100.0% (3)
##        2016       2017       2018      2019
##    0.0% (0)   0.0% (0)   0.0% (0) 33.3% (1)
##  100.0% (3) 100.0% (3) 100.0% (3) 66.7% (2)
## 
## $Low
##  tax       2009       2010       2011       2012       2013       2014
##    0 100.0% (3) 100.0% (3) 100.0% (3) 100.0% (3) 100.0% (3) 100.0% (3)
##    1   0.0% (0)   0.0% (0)   0.0% (0)   0.0% (0)   0.0% (0)   0.0% (0)
##        2015      2016      2017      2018      2019
##  100.0% (3) 66.7% (2) 66.7% (2) 66.7% (2) 66.7% (2)
##    0.0% (0) 33.3% (1) 33.3% (1) 33.3% (1) 33.3% (1)
## 
## $`Low-Middle`
##  tax       2009       2010       2011      2012      2013      2014      2015
##    0 100.0% (3) 100.0% (3) 100.0% (3) 66.7% (2) 66.7% (2) 66.7% (2) 33.3% (1)
##    1   0.0% (0)   0.0% (0)   0.0% (0) 33.3% (1) 33.3% (1) 33.3% (1) 66.7% (2)
##       2016      2017      2018      2019
##  33.3% (1) 33.3% (1) 33.3% (1) 33.3% (1)
##  66.7% (2) 66.7% (2) 66.7% (2) 66.7% (2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, the three-way table creates a list containing the different combinations which are accesible with the &lt;code&gt;$&lt;/code&gt; operator. We can do a little bit of code gymnastics to generate our nicely formated output by saving the &lt;code&gt;janitor::tabyl()&lt;/code&gt; output into an object and printing each of the tables individually.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;three_way_tab &amp;lt;- carbon_tax_df %&amp;gt;%
  janitor::tabyl(tax, year, income_class) %&amp;gt;%
  janitor::adorn_percentages(&amp;quot;col&amp;quot;) %&amp;gt;%
  janitor::adorn_pct_formatting(digits = 1) %&amp;gt;%
  janitor::adorn_ns() &lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;12&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
High
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;11&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Year
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
tax
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2009
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2010
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2011
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2012
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2013
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2014
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2015
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2016
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2017
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2018
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2019
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;12&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
High-Middle
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;11&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Year
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
tax
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2009
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2010
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2011
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2012
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2013
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2014
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2015
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2016
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2017
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2018
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2019
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;12&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Low-Middle
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;11&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Year
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
tax
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2009
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2010
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2011
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2012
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2013
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2014
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2015
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2016
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2017
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2018
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2019
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;12&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Low
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;11&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
Year
&lt;/div&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
tax
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2009
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2010
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2011
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2012
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2013
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2014
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2015
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2016
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2017
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2018
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
2019
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
100.0% (3)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
66.7% (2)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0% (0)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33.3% (1)
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-explore-visually-the-levels-of-carbon-dioxide-emmissions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Let’s explore visually the levels of carbon dioxide emmissions&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(carbon_tax_df, aes(x = factor(year),
                          y= co2_per_capita, 
                          color = factor(tax))) +
  geom_point() + #create scatterplot
  labs(title = &amp;quot;Exploratory plot of CO2 emissions per capita&amp;quot;,
       x = &amp;quot;Year&amp;quot;,
       y = &amp;quot;CO2 emissions in metric tons (T)&amp;quot;,
       color = &amp;quot;Carbon tax&amp;quot;) +
  theme_minimal() +
  theme(legend.position=&amp;quot;bottom&amp;quot;) + #move legend to the bottom
  scale_color_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/114688414-f6c5d880-9d14-11eb-8763-a71f2fc85d8d.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What do we see here?&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;carbon_tax_df %&amp;gt;%
  dplyr::mutate(year_as_date = lubridate::ymd(year, truncated = 2L), #turning numeric to date format
                income_class = factor(carbon_tax_df$income_class, 
                                      levels = c(&amp;quot;High&amp;quot;, &amp;quot;High-Middle&amp;quot;,
                                                 &amp;quot;Low-Middle&amp;quot;, &amp;quot;Low&amp;quot;))) %&amp;gt;% #reordering the factors
  ggplot(., aes(x = year_as_date, 
                y= co2_per_capita, 
                color = factor(tax))) +
  geom_point() + #create scatterplot
  geom_path(aes(group = 1)) + #to render consecutive lines disregarding the tax (you will likely use geom_line() for the assignment)
  facet_wrap(country_name~income_class) + #to split plot into panels based on this dimension
  scale_x_date(date_labels = &amp;quot;%Y&amp;quot;) + #telling ggplot that we want the ticks to be the years in the dates
  labs(title = &amp;quot;Exploratory plot of CO2 emissions per capita&amp;quot;,
       x = &amp;quot;Year&amp;quot;,
       y = &amp;quot;CO2 emissions in metric tons (T)&amp;quot;,
       color = &amp;quot;Carbon tax&amp;quot;) +
  theme_bw() + 
  scale_color_manual(name = &amp;quot; &amp;quot;, # changes to fill dimension
                     values = c(&amp;quot;#a7a8aa&amp;quot;, &amp;quot;#cc0055&amp;quot;),
                     labels = c(&amp;quot;Control&amp;quot;, &amp;quot;Treatment&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/54796579/114688423-f88f9c00-9d14-11eb-855e-8f9d2131bad7.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What do we see here?&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;Note: The exploratory data analysis portions of our scripts will not transfer directly to this week’s assignment; however, they will be very useful for your future endevours. Summarizing, graphing, and exploring your data will be critical to discover patterns, to spot anomalies, and to check assumptions&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-and-estimating&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling and estimating&lt;/h2&gt;
&lt;p&gt;We have seen during the lecture that balanced panel data can help us decompose the error term. With a balanced panel we can capture all unobserved, unit- and time-specific factors.&lt;/p&gt;
&lt;p&gt;In the example at hand, we can think of unit-specific factors as characteristics of individual countries that are constant over time (e.g. a country that just loves big pick-up trucks). We can also think about time-specific factors that affect all countries (e.g. global economic shocks).&lt;/p&gt;
&lt;p&gt;We can formulate this as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{it} = β_0 + β_1D_{it} + \theta_{i} + \delta_t + \upsilon_{it}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt; reflects the time-invariant traits of the units, &lt;span class=&#34;math inline&#34;&gt;\(\delta_t\)&lt;/span&gt; reflects the time-specific factors that affect everyone and &lt;span class=&#34;math inline&#34;&gt;\(\upsilon_{it}\)&lt;/span&gt; is the &lt;strong&gt;idiosyncratic error&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;We will move forward by creating three models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;naive model&lt;/strong&gt; (also known as a &lt;em&gt;pooled model&lt;/em&gt;), where we will regress &lt;code&gt;co2_per_capita&lt;/code&gt; on &lt;code&gt;tax&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;model with unit-fixed effects&lt;/strong&gt;, where we will capture the &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; portion of our error&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;model with time- and unit-fixed effects&lt;/strong&gt;, where we will capture our &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; portions of our error term&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;div id=&#34;naive-modeling&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Naive modeling&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;naive_carbon &amp;lt;- lm(co2_per_capita ~ tax, data = carbon_tax_df)
pooled_naive_carbon &amp;lt;- plm(co2_per_capita ~ tax, 
                           data = carbon_tax_df, 
                           model = &amp;quot;pooling&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;naive-model-with-lm&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Naive model with lm()&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelsummary::modelsummary(naive_carbon, 
                           fmt = 2,
                           gof_omit = &amp;quot;AIC|BIC|Log.Lik.&amp;quot;,
                           statistic = &amp;quot;conf.int&amp;quot;,
                           stars = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
10.63***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[9.93, 11.32]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tax
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-6.26***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[-7.38, -5.14]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
132
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.485
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.481
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
122.394
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border:0;&#34; colspan=&#34;100%&#34;&gt;
&lt;sup&gt;&lt;/sup&gt; + p &amp;lt; 0.1, * p &amp;lt; 0.05, ** p &amp;lt; 0.01, *** p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;naive-model-with-plm&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Naive model with plm()&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelsummary::modelsummary(pooled_naive_carbon, 
                           fmt = 2,
                           gof_omit = &amp;quot;AIC|BIC|Log.Lik.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
10.63
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
(0.35)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tax
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-6.26
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
(0.57)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
132
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.485
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.481
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What do we see here?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This model is telling us that on average, the &lt;span class=&#34;math inline&#34;&gt;\(CO_2\)&lt;/span&gt; emissions per capita are reduced by 6.2 metric tons when a carbon tax is put in place. Still, after all the work we have done throughout the semester, we understand that there may be a plethora of factors that could be skewing the results of this bivariate regression.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;unit-fixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Unit-fixed effects&lt;/h3&gt;
&lt;p&gt;We will learn two ways of gathering unit- and time-fixed effects in R:&lt;/p&gt;
&lt;p&gt;First, we will perform &lt;strong&gt;Least Squares Dummy Variables (LSDV) estimation&lt;/strong&gt; with &lt;em&gt;lm()&lt;/em&gt;, where we essentially get an individual estimate for each unit.&lt;/p&gt;
&lt;p&gt;Second, we will run our model with &lt;em&gt;plm()&lt;/em&gt;, which will do the same mechanics, yet it will not estimate each of the units intercepts (because it relies on the “de-meaning” approach).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lsdv_unit_fe &amp;lt;- lm(co2_per_capita ~ tax + country_name, data = carbon_tax_df)

unit_fe &amp;lt;- plm(co2_per_capita ~ tax, 
               data = carbon_tax_df, 
               index = c(&amp;quot;country_name&amp;quot;), # unit 
               effect = &amp;quot;individual&amp;quot;,
               model = &amp;quot;within&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;unit-fixed-effects-with-lm-least-squares-dummy-variables-lsdv-estimation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Unit-fixed effects with lm() — Least Squares Dummy Variables (LSDV) estimation&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelsummary::modelsummary(lsdv_unit_fe, 
                           fmt = 2,
                           gof_omit = &amp;quot;AIC|BIC|Log.Lik.&amp;quot;,
                           statistic = &amp;quot;conf.int&amp;quot;,
                           stars = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.91***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[5.67, 8.15]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tax
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-4.44***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-5.37, -3.50]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameBorovia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.51
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-0.30, 3.31]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameCarpania
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5.11***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[3.30, 6.91]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameCorinthia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.43***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[4.68, 8.19]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameFreedonia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.12***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[4.33, 7.91]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameGlenraven
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.37
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-1.51, 2.26]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameKhemed
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.67
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-2.56, 1.21]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameLaurania
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-0.32, 3.39]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameParano
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.69***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[1.94, 5.45]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameRon
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.71**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[0.91, 4.52]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameRumekistan
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.43***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[5.68, 9.19]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameTransia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.88+
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[-0.03, 3.80]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
132
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.797
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.776
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
38.844
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border:0;&#34; colspan=&#34;100%&#34;&gt;
&lt;sup&gt;&lt;/sup&gt; + p &amp;lt; 0.1, * p &amp;lt; 0.05, ** p &amp;lt; 0.01, *** p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;unit-fixed-effects-with-plm&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Unit-fixed effects with plm()&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelsummary::modelsummary(unit_fe, 
                           fmt = 2,
                           gof_omit = &amp;quot;AIC|BIC|Log.Lik.&amp;quot;,
                           statistic = &amp;quot;conf.int&amp;quot;,
                           stars = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tax
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-4.44***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[-5.36, -3.51]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
132
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.424
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.366
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border:0;&#34; colspan=&#34;100%&#34;&gt;
&lt;sup&gt;&lt;/sup&gt; + p &amp;lt; 0.1, * p &amp;lt; 0.05, ** p &amp;lt; 0.01, *** p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What do we see here?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Adding unit-level fixed effects to the model, i.e. accounting for unobserved, time-invariant characteristics of countries and only focusing on within-state variation, the imposition of a carbon tax reduces &lt;span class=&#34;math inline&#34;&gt;\(CO_2\)&lt;/span&gt; per capita emissions by &lt;strong&gt;4.44 metric tons&lt;/strong&gt;. Once we have captured the variation between countries, we can see that our results from the naive model were substantially biased. We can still try to capture the time-specific portion of the error.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The results from the Least Squares Dummy Variables (LSDV) estimation are read in reference to a baseline. In this case, the constant is representing the intercept for Adjikistan. We can utilize the individual slopes for each country to say that Freedonians emit on average 6.12 more metric tons of &lt;span class=&#34;math inline&#34;&gt;\(CO_2\)&lt;/span&gt; per capita than Adjikistanians.&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;unit--and-time-fixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Unit- and time-fixed effects&lt;/h3&gt;
&lt;p&gt;We will perform our regressions with &lt;strong&gt;Least Squares Dummy Variables (LSDV) estimation&lt;/strong&gt; with &lt;em&gt;lm()&lt;/em&gt; and our simplified way with &lt;em&gt;plm()&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lsdv_unit_time_fe &amp;lt;- lm(co2_per_capita ~ tax + country_name + factor(year), 
                        data = carbon_tax_df)

unit_time_fe &amp;lt;- plm(co2_per_capita ~ tax, 
                    data = carbon_tax_df, 
                    index = c(&amp;quot;country_name&amp;quot;, &amp;quot;year&amp;quot;), # unit and time
                    model = &amp;quot;within&amp;quot;, 
                    effect = &amp;quot;twoways&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;unit--and-time-fixed-effects-with-lm-least-squares-dummy-variables-lsdv-estimation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Unit- and time-fixed effects with lm() — Least Squares Dummy Variables (LSDV) estimation&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelsummary::modelsummary(lsdv_unit_time_fe, 
                           fmt = 2,
                           gof_omit = &amp;quot;AIC|BIC|Log.Lik.&amp;quot;,
                           statistic = &amp;quot;conf.int&amp;quot;,
                           stars = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8.62***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[7.84, 9.41]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tax
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-3.91***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-4.46, -3.35]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameBorovia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.27**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[0.44, 2.09]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameCarpania
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4.87***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[4.04, 5.69]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameCorinthia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.43***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[5.65, 7.22]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameFreedonia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5.93***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[5.11, 6.74]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameGlenraven
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-0.90, 0.87]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameKhemed
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-1.06*
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-1.94, -0.17]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameLaurania
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.20**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[0.33, 2.06]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameParano
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.69***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[2.90, 4.48]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameRon
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.47***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[1.65, 3.30]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameRumekistan
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7.43***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[6.64, 8.22]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
country_nameTransia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.45**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[0.54, 2.36]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2010
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-4.70***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-5.45, -3.94]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2011
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.89***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[1.13, 2.65]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2012
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-3.06***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-3.83, -2.29]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2013
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.11
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-0.67, 0.88]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2014
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-1.88***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-2.65, -1.10]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2015
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-3.02***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-3.84, -2.20]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2016
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-3.29***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-4.13, -2.45]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2017
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.96*
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-1.80, -0.12]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2018
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-2.49***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
[-3.33, -1.65]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
factor(year)2019
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-1.40**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[-2.22, -0.58]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
132
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.963
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.955
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
127.305
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border:0;&#34; colspan=&#34;100%&#34;&gt;
&lt;sup&gt;&lt;/sup&gt; + p &amp;lt; 0.1, * p &amp;lt; 0.05, ** p &amp;lt; 0.01, *** p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;unit-fixed-effects-with-plm-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Unit-fixed effects with plm()&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modelsummary::modelsummary(unit_time_fe, 
                           fmt = 2,
                           gof_omit = &amp;quot;AIC|BIC|Log.Lik.&amp;quot;,
                           statistic = &amp;quot;conf.int&amp;quot;,
                           stars = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Model 1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
tax
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-3.91***
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[-4.46, -3.36]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
132
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.641
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.568
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border:0;&#34; colspan=&#34;100%&#34;&gt;
&lt;sup&gt;&lt;/sup&gt; + p &amp;lt; 0.1, * p &amp;lt; 0.05, ** p &amp;lt; 0.01, *** p &amp;lt; 0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:#4B0082;&#34;&gt;What do we see here?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now in addition to adding unit-level fixed effects to the model, we control for time-specific factors that affect the global per capita &lt;span class=&#34;math inline&#34;&gt;\(CO_2\)&lt;/span&gt; emissions. The results suggest that the effect of a carbon-tax leads to a decrease &lt;span class=&#34;math inline&#34;&gt;\(CO_2\)&lt;/span&gt; emissions of 3.91 metric tons per capita.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;test-of-serial-correlation-for-the-idiosyncratic-component-of-the-errors-in-panel-models&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Test of serial correlation for the idiosyncratic component of the errors in panel models&lt;/h4&gt;
&lt;p&gt;In our models our assumption for the errors is &lt;span class=&#34;math inline&#34;&gt;\(υ_{it} ∼ iid(0, σ_υ^{2})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;With longer panels, serial correlation between errors is a problem:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cor(υ_{it}, υ_i(t−1))≠0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We can test for serial correlation in our time and unit FE specification model, as such:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbgtest(unit_time_fe, order = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Breusch-Godfrey/Wooldridge test for serial correlation in panel models
## 
## data:  co2_per_capita ~ tax
## chisq = 0.25101, df = 2, p-value = 0.8821
## alternative hypothesis: serial correlation in idiosyncratic errors&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In here, the null hypothesis is there is serial correlation of any order up to 2 (i.e., first- and second-order). In this case, we do not find any serial correlation, so we do not need to correct our standard errors manually. If we were to find serial correlation, we could introduce robust standard errors with a similar syntax to the one used last week for clustered standard errors:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_with_robust_se &amp;lt;- coeftest(unit_time_fe, vcov=vcovHC(unit_time_fe, type = &amp;quot;sss&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;drafting-some-brief-recommedations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Drafting some brief recommedations&lt;/h2&gt;
&lt;p&gt;You report back to the Organization of Economic Non-Cooperation for Development (OENCD). Based on your analysis of the data at hand, you suggest that the implementation of a carbon tax does have an effect on national carbon dioxide emissions per capita. Your results show that a carbon tax reduces &lt;span class=&#34;math inline&#34;&gt;\(CO_2\)&lt;/span&gt; emissions by 3.91 metric tons per capita.&lt;/p&gt;
&lt;p&gt;Your results are welcomed internationally and all states move forward with the measure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://thumbs.gfycat.com/GreedyMiserableArrowcrab-size_restricted.gif&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
